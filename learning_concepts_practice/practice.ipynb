{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xzVEmWP8mMu"
   },
   "source": [
    "# fundamental concepts of tensors usig tensorflow\n",
    "* intro to tensors\n",
    "* information from tensors\n",
    "* manipulating tensors\n",
    "* tensors and numpy\n",
    "* using @tf.function ( a way to speed up regular python functions)\n",
    "* using gpus with tensorflow (or tpus) for faster numerical computaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej9c3PGR-1b7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5hNDTWY9SCw"
   },
   "source": [
    "*italicized text*# intro to tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fee2jBYS_-Eb"
   },
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__) # for checking the version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5M96xDSBA0EX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create tensors with tf.constant()\n",
    "import tensorflow as tf\n",
    "scalar  = tf.constant(7)\n",
    "scalar\n",
    "\n",
    "# commands - ctrl + MM  - markdown cell, ctrl + my - code cell\n",
    "#            ctrl + MB - new cell\n",
    "#            ctrl + shift + space - info about a command\n",
    "\n",
    "## tensorflow has inbuilt modules which are able to read in data sorces such as how many diiferent images \n",
    "## and automatically convert them into tensors and later on the neural network model \n",
    "## will process these tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfYgV62UEL_O",
    "outputId": "415ab951-9c48-4b8f-86e3-df44edc84dc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check no of dimensions of a tensor ( ndim stands for no of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxdhoVJ6EXxD",
    "outputId": "db48ae64-ac59-4ec7-986c-e735f95bac95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a vector\n",
    "vector = tf.constant([10, 10])\n",
    "vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPI1f-yzErMe",
    "outputId": "8812990b-cd23-4135-d464-4bb3aa90692d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimensions of a vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUzPAe6sEzgr",
    "outputId": "f568ced0-2949-4ff3-9e30-66d9ded7d2be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[11,  7],\n",
       "       [ 7, 11]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a matrix ( has more than 1 dimension)\n",
    "import tensorflow as tf\n",
    "matrix = tf.constant([[11, 7],\n",
    "                      [7, 11]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VgBcJ8xfFK4k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in f:\\saicharan\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in f:\\saicharan\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in f:\\saicharan\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in f:\\saicharan\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in f:\\saicharan\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: gast==0.4.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in f:\\saicharan\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras~=2.6 in f:\\saicharan\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six~=1.15.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in f:\\saicharan\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in f:\\saicharan\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in f:\\saicharan\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in f:\\saicharan\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in f:\\saicharan\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in f:\\saicharan\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in f:\\saicharan\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in f:\\saicharan\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in f:\\saicharan\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\saicharan\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\saicharan\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in f:\\saicharan\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[11,  7],\n",
       "       [ 7, 11]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a matrix ( has more than 1 dimension)\n",
    "import tensorflow as tf\n",
    "matrix = tf.constant([[11, 7],\n",
    "                      [7, 11]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f2cc0e3c08ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflw\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_version_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflw'"
     ]
    }
   ],
   "source": [
    "import tensorflw as tf\n",
    "print(tf._version_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors with tf.constant()\n",
    "scalar = tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of dimnsions of a tensor ( ndim stands for number of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a vector\n",
    "vector = tf.constant([10, 10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimnsion of our vector\n",
    "vector.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a matrix(has more tahn 1 dimension)\n",
    "matrix = tf.constant([[10, 7],\n",
    "                    [7, 10]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[10.,  7.],\n",
       "       [ 3.,  2.],\n",
       "       [ 8.,  9.]], dtype=float16)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create anothe rmatrix\n",
    "another_matrix = tf.constant([[10., 7.],\n",
    "                             [3., 2.],\n",
    "                             [8., 9.]], dtype=tf.float16)  # specify the data type with the dytpe parameter\n",
    "another_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-4ed3bdee1d9a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-4ed3bdee1d9a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    total no of dimensions = no of elements in shape\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "total no of dimensions = no of elements in shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to increase the number ofdiensions\n",
    "# lets create a tensor\n",
    "# a tensor\n",
    "tensor = tf.constant([[[1, 2, 3],\n",
    "                     [4, 5, 6]],\n",
    "                     [[7, 8, 9],\n",
    "                    [10, 11, 12]],\n",
    "                     [[13, 14, 15],\n",
    "                     [16, 17, 18]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what we've created so far\n",
    "\n",
    "* Scalar : a single number\n",
    "* Vector : a number with direction (eg wind speed and direction)\n",
    "* matrix : a 2-dimensional array of numbers\n",
    "* Tenso : an n-dimensional array of numbers ( when n can be any number, a 0-dimensional tensor is a scalar, a 1-dimensional tensor is a vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7])>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7])>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating tensors with tf.variable\n",
    "changeable_tensor = tf.Variable([10, 7])\n",
    "unchangeable_tensor = tf.constant([10, 7])\n",
    "changeable_tensor, unchangeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-df74dc611499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#lets try change one of the elements in our changeable vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mchangeable_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mchangeable_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "#lets try change one of the elements in our changeable vector\n",
    "changeable_tensor[0] = 7\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying .assign()\n",
    "changeable_tensor[0].assign(7)\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try to change unchangeable tensor\n",
    "unchangeable_tensor[0].assign(7)\n",
    "unchangeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating random tensors\n",
    "random tensors are tensors of some arbitrary size which contains random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create two random tensors\n",
    "random_1= tf.random.Generator.from_seed(4) # set seed for reproducibility\n",
    "random_1 = random_1.normal(shape=(3,2))\n",
    "random_1\n",
    "random_2 = tf.random.Generator.from_seed(4)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "random_1, random_2, random_1 == random_2\n",
    "\n",
    "# they have come from a normal distrbution\n",
    "\n",
    "# they are pseudo random numbers\n",
    "# settig the seed -> create randm numbers but flavour them with x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  shuffle the order of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle a tensor ( valuable for when you  want to shuffle your data so that inherent order does not affect learning)\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                          [3, 4],\n",
    "                          [2, 5]])\n",
    "not_shuffled.ndim\n",
    "\n",
    "# shuffle our non-shffled tensor\n",
    "tf.random.shuffle(not_shuffled)  # shuffles elements along its first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle our non-shffled tensor\n",
    "tf.random.shuffle(not_shuffled)  # shuffles elements along its first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [ 3,  4],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using seed\n",
    "# shuffle our non-shffled tensor\n",
    "tf.random.shuffle(not_shuffled, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [ 3,  4],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.shuffle(not_shuffled, seed = 42)  # gives differen result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "tf.random.shuffle(not_shuffled, seed = 42)  # gives same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read through tensorflow documentation on random seed generator\n",
    "# write 5 random tansors and shuffle them\\\n",
    "\n",
    "# operational and global level random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main aim to shuffle the order of tensors is --> for classification neural networks -> any kind of images first may learn only one type of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-b66b7616e12f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-35-b66b7616e12f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    tf.random.shuffle(not_shuffled, seed = 42)  3 we get a different order each time\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tf.random.shuffle(not_shuffled, seed = 42)  3 we get a different order each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using global radom seed \n",
    "tf.random.set_seed(42) # --> gives same order\n",
    "tf.random.shuffle(not_shuffled, seed = 42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if we want our shuffled tensors to be in the same order , we have to use the global level random seed as well as the operational level random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other ways to make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all ones\n",
    "tf.ones([10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all zeroes\n",
    "tf.zeros(shape=(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-7d4003424638>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-39-7d4003424638>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    main differencce NumPy arrays and TensorFlow tensors is that tensors can be run on a GPU ( must faster for numerical computing)\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### turn numpy arrays into tensors\n",
    "\n",
    "main differencce NumPy arrays and TensorFlow tensors is that tensors can be run on a GPU ( must faster for numerical computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also turn NumPy arrays into tensors\n",
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype = np.int32) # create a NumPy array between 1 and 25\n",
    "numpy_A\n",
    "\n",
    "# X = tf.constant(some_matrix) # capital for matrix or tensor\n",
    "# y = tf.constant(vector)  # non-capital for vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.constant(numpy_A)\n",
    "A\n",
    "\n",
    "# converted NumPy rray into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
       " array([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
       "        [17, 18, 19, 20, 21, 22, 23, 24]])>,\n",
       " <tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24])>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing shape --> its shape is 24 if we want it into a 3-dimensional tensor\n",
    "2*3*4\n",
    "A = tf.constant(numpy_A, shape = (3, 8))  # 3 rows and 8 elements in one column\n",
    "A  # this would be a tensor becoz it has got more than 1 dimension \n",
    "B= tf.constant(numpy_A)  # this is a vector\n",
    "A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting informatin from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_A.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays are a very common form of representing numerical data --> can be converted into tensors\n",
    "\n",
    "basic difference beteween numpy array and tensorflow tensor --> although they may store the same information here \n",
    "a tensor formmat can run on a gpu and finding pattrens in numerial data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### want to get attribute s of tensors\n",
    "\n",
    "When dealing with tensors want to be aware of the following attributes ->\n",
    "* Shape - the length of each of the dimensions of a tensor\n",
    "* Rank - the number of tensor dimensions . A scalar has rank 0, a vector has rank 1, a matrix has rank 2 , a tensor has rank n\n",
    "* Axis or dimension - a particular dimension of a tensor --> tensor[0], tensor[:, 1]...\n",
    "* Size - the total number of items in a tensor tf.size(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 4 matrix --> 4 dimensions\n",
    "rank_4_tensor = tf.zeros(shape = [2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# when you pass a tensor into a neural network --> has to be in a certain shape and output also has to be in a certain shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 5), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[0][1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_4_tensor[0][1][4] -->gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype of every element <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (2, 3, 4, 5)\n",
      "elemnts along the 0 axis: 2\n",
      "elements along the last axis: 5\n",
      "Total number of elemnts in our tensor: tf.Tensor(120, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# fget various attributes of our tensors\n",
    "print(\"datatype of every element\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"elemnts along the 0 axis:\",rank_4_tensor.shape[0])\n",
    "print(\"elements along the last axis:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elemnts in our tensor:\", tf.size(rank_4_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype of every element <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (2, 3, 4, 5)\n",
      "elemnts along the 0 axis: 2\n",
      "elements along the last axis: 5\n",
      "Total number of elemnts in our tensor: tf.Tensor(120, shape=(), dtype=int32)\n",
      "Total number of elemnts in our tensor: 120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"datatype of every element\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"elemnts along the 0 axis:\",rank_4_tensor.shape[0])\n",
    "print(\"elements along the last axis:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elemnts in our tensor:\", tf.size(rank_4_tensor))\n",
    "print(\"Total number of elemnts in our tensor:\", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing tensors\n",
    "\n",
    "Tensors can be indexed like python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = [1, 2, 3, 4]\n",
    "some_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 2 elements of each dimension\n",
    "rank_4_tensor[:2, :2, :2, :2] # we seaparate the dimensions by commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first element from each dimension frome each index except for the final one\n",
    "rank_4_tensor[:1, :1, :1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:1, :1, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 4, 1), dtype=float32, numpy=\n",
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:1, :1, :, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1, 1), dtype=float32, numpy=\n",
       "array([[[[0.]]],\n",
       "\n",
       "\n",
       "       [[[0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:, :1, :1, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 2]), 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a rank 2 tensor (2 dimensions)\n",
    "rank_2_tensor = tf.constant([[10, 7],\n",
    "                           [3, 4]])\n",
    "rank_2_tensor\n",
    "rank_2_tensor.shape, rank_2_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4], 4, [1, 2, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list, some_list[-1], some_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the last item of eah row of rank_2_matrix\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
       "array([[10],\n",
       "       [ 3]])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to add an extra dimension to this tensor\n",
    "# we may need to alter the size of our tensors so that their shape line up\n",
    "\n",
    "# add in extra dimension to our rank 2 tensor but information should be same\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis]\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_3_tensor = rank_2_tensor[:, :, tf.newaxis]\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative to tf.newaxis\n",
    "tf.expand_dims(rank_2_tensor, axis=-1) # \"-1\" means expand the final axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 2), dtype=int32, numpy=\n",
       "array([[[10,  7]],\n",
       "\n",
       "       [[ 3,  4]]])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=1) #extra dimension u=in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[10,  7],\n",
       "        [ 3,  4]]])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=0) # expand the 0-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how the numbers are stored changes just in changing dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulating tensors (tensor operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[20, 17],\n",
       "        [13, 14]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[10,  7],\n",
       "        [ 3,  4]])>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can add values to a tensor using the addition operator\n",
    "tensor = tf.constant([[10, 7], [3,4]])\n",
    "tensor + 10, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor+=20\n",
    "tensor\n",
    "tensor-=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-7, -6]])>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use the tensorflow built-in function too\n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Matrix Multiplication\n",
    "In machine learning, matrix multiplication is one of the most common tensor operations\n",
    "1. the inner dimnsions must match\n",
    "2. the resulting matrix has shape of the outer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication in tensorflow\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  49],\n",
       "       [  9,  16]])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor  # it is element wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-79-4b7b1ef36c31>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-79-4b7b1ef36c31>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    tensor @ tensor  used for matricx multiplication\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# matricx multiplication with python operator \"@\"\n",
    "tensor @ tensor  used for matricx multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 7, 16],\n",
       "       [27, 40],\n",
       "       [55, 72]])>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with different shapes\n",
    "# create a tensor (3, 2) tensor\n",
    "X = tf.constant([[1, 2],\n",
    "                 [3, 4],\n",
    "                [5, 6]])\n",
    "Y = tf.constant([[7, 8],\n",
    "                 [9, 10],\n",
    "                [11, 12]])\n",
    "X*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[0] mismatch In[1] shape: 2 vs. 3: [3,2] [3,2] 0 0 [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-603b9dc11460>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Matrix multilpy tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul_wrapper\u001b[1;34m(a, b, name)\u001b[0m\n\u001b[0;32m   3761\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_style_type_promotion\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3762\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3763\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3764\u001b[0m \u001b[0mmatmul_wrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3765\u001b[0m \u001b[0m_OverrideBinaryOperatorHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatmul_wrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"matmul\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3652\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[0;32m   3653\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3654\u001b[1;33m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[0;32m   3655\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0;32m   3656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5693\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5694\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5695\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5696\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5697\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: In[0] mismatch In[1] shape: 2 vs. 3: [3,2] [3,2] 0 0 [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "#Matrix multilpy tensors\n",
    "X @ Y\n",
    "tf.multiply(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to change the shape of either matrix\n",
    "# or cretae new matrice sof same shape\n",
    "\n",
    "# lets change the shape of y\n",
    "tf.reshape(Y, shape = (2,3)), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, tf.reshape(Y, shape = (2, 3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]])>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to multiply X by reshaped y\n",
    "X @ tf.reshape(Y, shape = (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]])>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, tf.reshape(Y, shape = (2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 2]),\n",
       " TensorShape([3, 2]),\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[ 58,  64],\n",
       "        [139, 154]])>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping X\n",
    "X.shape, Y.shape, tf.matmul(tf.reshape(X, shape=(2, 3)), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 3, 5],\n",
       "        [2, 4, 6]])>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [4, 5, 6]])>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can do the same wwith transpose\n",
    "X, tf.transpose(X), tf.reshape(X ,shape=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose --> flips the axes rather than shuffling elements of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try matricx mult with transpose rather than reshape\n",
    "tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the dot product\n",
    "matricx multis also referred to as the dot product\n",
    "can perform mat mult using -->\n",
    "* tf.matmul()\n",
    "* tf.tensordot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[ 89,  98],\n",
       "        [116, 128]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[ 89,  98],\n",
       "        [116, 128]])>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform the dot product on X and Y ( requires X or Y to be transposed)\n",
    "# transposiing( flipping the axis) results in different outputs rather than reshaping ( reshuffling)\n",
    "\n",
    "tf.tensordot(tf.transpose(X), Y, axes = 1), tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]])>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perfor mat mult bet x and y(transposed)\n",
    "tf.matmul(X, tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform mat ult bet x and y (reshaped)\n",
    "tf.matmul(X, tf.reshape(Y, shape=(2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norml Y\n",
      " tf.Tensor(\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]], shape=(3, 2), dtype=int32)\n",
      "Y reshaped to (2, 3) : \n",
      "tf.Tensor(\n",
      "[[ 7  8  9]\n",
      " [10 11 12]], shape=(2, 3), dtype=int32) \n",
      "\n",
      "Y transposed\n",
      "tf.Tensor(\n",
      "[[ 7  9 11]\n",
      " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# check the values of y, reshape Y, transposed Y\n",
    "print(\"Norml Y\\n\", Y)\n",
    "print(\"Y reshaped to (2, 3) : \")\n",
    "print(tf.reshape(Y, (2, 3)), \"\\n\")\n",
    "print(\"Y transposed\")\n",
    "print(tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which one to use - transpose or reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally , when performing matrix mltiplication on two tensors , and one of the axes does'nt line up, use transpose, rather than reshape to satisfy multiplication rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### changing the dataype of a tensor\n",
    "# generally default datatpe of tensors will be int32\n",
    "\n",
    "# create a tensor with dafault datatype ( float 32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "B.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = tf.constant(([7, 10]))\n",
    "C.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>,\n",
       " tf.float16)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change from float 32 to float 16\n",
    "D = tf.cast(B, dtype = tf.float16)\n",
    "D, D.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 7., 10.], dtype=float32)>,\n",
       " tf.float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change fro int32 to float32\n",
    "E = tf.cast(C , dtype = tf.float32)\n",
    "E, E.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([ 7., 10.], dtype=float16)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_float16  = tf.cast(E, dtype = tf.float16)\n",
    "E_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors Aggregating\n",
    "\n",
    "Aggregating tensors means condensing them from multiple values down to a smaller amount of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ -7, -10])>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---> get the absolute values\n",
    "D = tf.constant([-7, -10])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10])>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.abs(D) # for getting absolute values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other forms of aggregation\n",
    "\n",
    "* get the minimm\n",
    "* get the maximum\n",
    "* get the mean ofa tensor\n",
    "* get the sum of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([25, 86, 62, 12, 98, 40, 57, 95, 16, 74,  2, 56,  0, 30,  1, 63, 36,\n",
       "       13,  2, 15, 70, 40, 43, 97, 90, 73,  6, 67, 19, 66, 78, 10, 22, 86,\n",
       "       18, 28,  7, 64, 77,  5, 94, 40, 53, 50, 38, 78, 20, 31, 59,  8])>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a radom tensor with values between 0 and 100 of size 50\n",
    "E = tf.constant(np.random.randint(0, 100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=50>, 1, TensorShape([50]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(E), E.ndim, E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimum of a tensor\n",
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in numPy\n",
    "np.min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=98>, 98)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maximum \n",
    "tf.reduce_max(E), np.max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=44>, 44.4)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean\n",
    "tf.reduce_mean(E), np.mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=2220>, 2220)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(E), np.sum(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorlflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=924.68>, 924.68)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tfp means tensorflow probability\n",
    "## import tensorflow_probability as tfp\n",
    "\n",
    "## variance and stadard deviation only work with real or complex input\n",
    "# --> hence convert E to real type\n",
    "# or\n",
    "# to find variance of tensor , we need access to tensorflow_probability\n",
    "#import tensorflow_probability as tfp\n",
    "# tfp.stats.variance(E)\n",
    "\n",
    "tf.math.reduce_variance(tf.cast(E, dtype = tf.float32)), np.var(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input must be either real or complex",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-a08a9643d051>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_std\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_std\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2693\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m     \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m     \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_variance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_variance\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2633\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2634\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2635\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input must be either real or complex\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2636\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2637\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input must be either real or complex"
     ]
    }
   ],
   "source": [
    "tf.math.reduce_std(E), np.std(E), E.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the positional maximum and minimum\n",
    "\n",
    "#### used in neural network output prediction probabilities\n",
    "#### representtion outputs are referred to as prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensor for finding poitional min and max\n",
    "tf.random.set_seed(42)\n",
    "F = tf.random.uniform(shape=[50])\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=42>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at which position max elemnt occurs --> find the positional maximum\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the largest value using the index\n",
    "F[tf.argmax(F)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the max value value of\n",
    "tf.reduce_max(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for equality\n",
    "F[tf.argmax(F)] == tf.reduce_max(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=16>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.009463668>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[tf.argmin(F)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(F) == F[tf.argmin(F)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## squeezing our tensor --> removing all single dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=float32, numpy=\n",
       "array([[[[[0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "           0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "           0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "           0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "           0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "           0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "           0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "           0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "           0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "           0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043]]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "G = tf.constant(tf.random.uniform(shape=[50]), shape=(1, 1, 1, 1, 50))\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 1, 50])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 1, 1, 1, 50]), TensorShape([50]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.squeezed = tf.squeeze(G)  # removes dimensions of size 1 from shape of  atensor\n",
    "G.shape, G.squeezed.shape ## gets rid of extra dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see ml mastery for this \n",
    "# it is a form of numerical encoding\n",
    "# can one hot encode words and pass those as tensors to neural networks\n",
    "\n",
    "# create a list of indices\n",
    "some_list = [0, 1, 2, 3] # could be red, green, blue, purple\n",
    "\n",
    "\n",
    "\n",
    "# one hot encode this list of indices ---->\n",
    "tf.one_hot(some_list, depth = 4)  # depth --> usually no of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b'Y', b'N', b'N', b'N'],\n",
       "       [b'N', b'Y', b'N', b'N'],\n",
       "       [b'N', b'N', b'Y', b'N'],\n",
       "       [b'N', b'N', b'N', b'Y']], dtype=object)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using custom values for one-hot encoding\n",
    "tf.one_hot(some_list, depth = 4, on_value = 'Y', off_value = 'N')   # using on_value and of_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### more math operations \n",
    "##### squaring, log, square root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = tf.range(1, 10)\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81])>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(H) ## squaring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.sqrt(H) --> gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.99999994, 1.4142134 , 1.7320508 , 1.9999999 , 2.236068  ,\n",
       "       2.4494896 , 2.6457512 , 2.8284268 , 3.        ], dtype=float32)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(tf.cast(H, dtype = tf.float32)) # find root \n",
    "# sqrt requires non-int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.cast(H, dtype = tf.float32))  #finding log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy(fundamental package for scientific computing with python) and tensorflow\n",
    "\n",
    "**  tensorflow interacts beautifully with NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>,\n",
       " tensorflow.python.framework.ops.EagerTensor)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor directly from a NumPy array\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J, type(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from tensor to NumPy array\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor J to  anumpy array\n",
    "J.numpy(), type(J.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## useful in some of the functionalities\n",
    "J = tf.constant([3.])\n",
    "J.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## default types of each are slightly different\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.]))\n",
    "tensor_J = tf.constant([3., 7., 10.])  \n",
    "numpy_J.dtype, tensor_J.dtype\n",
    "\n",
    "# for tensor --> default type is float 32\n",
    "# for numpy array --> default type is float 64\n",
    "# NumPy - fundamental pav=ckage for scientific computing in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression --> predicting a number\n",
    "# other -> trying to predict the corners in a object detection problem\n",
    "\n",
    "\n",
    "# Regression inputs and outputs\n",
    "# some neural networks may have 1000 hidden layers\n",
    "\n",
    "# architecture of a regression model - \n",
    "# hyperparameter -> a setting that you can change as a data analyst\n",
    "\n",
    "# define our loss function --> how wrong our neural network predictions are, how wrong the relationships are \n",
    "# optimizer -> infrms neuralnetwork how to improve patterns bet input and output variables , to reduce the loss function\n",
    "# fit model -> telling model to look at bunch ofdifferent examples in the training datat for 100 laps of the data --> that's what epochs variablee stands for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# regression with neural networls in tensorflow\n",
    "\n",
    "# predicting a numerical variable based on some other combination of variables\n",
    "\n",
    "# Importing tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22f25e67dc0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to view and fit\n",
    "# regression model is red line throgh the middle , blue dots are the data points\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# features --> usually denoted by X\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# labels--> usually denoted by y\n",
    "y = np.array([3.0, 6.0, 9.0, 12.00, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# visualize the relationship\n",
    "plt.scatter(X, y)\n",
    "\n",
    "# can take X as independent varible, Y as dependent variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10 # --> this is the relationship or function bet input features(ind) and our labels(dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input and output shapes\n",
    "\n",
    "# create a demo tensor for housing price prediction tensor\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,), array([ 3.,  6.,  9., 12., 15., 18., 21., 24.]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in thiis cas we want to use X to predict y\n",
    "input_shape = X.shape\n",
    "output_shape = y.shape\n",
    "input_shape, output_shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to use one input feature of X to predict one y value\n",
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model the reltionship between X and y\n",
    "\n",
    "# turn NumPy arrays into tensorswith dtype float 32\n",
    "X = tf.cast(tf.constant(X), dtype = tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype = tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to build a model to find the realtionship\n",
    "# modelling with Tensorflow\n",
    "\n",
    "# 1- create model --> definr the input and output layers, as awell as the hidden layers of a deep learning model\n",
    "# 2 -> compiling a model -> define the loss function -> which tells our model how wrong it is , and opyimizer --> tellu our model to improve the patterns its learning\n",
    "#  and evaluation metrics --> what we can use to interpret the performnce of our model\n",
    "# 3 -> fitting a model -> lettin the model try to find patterns between X and y( features and labels)\n",
    "\n",
    "\n",
    "# building or picking a model often involves step 1 and 2 -> always have to compile it\n",
    "# step 3 - fitting the model, epochs - look at the training data 5 times\n",
    "# step 4 - evaluate our model -> on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2824a580>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed -> for reproducability\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1 create a model using the sequential API\n",
    "\n",
    "# --> telling to tensorflow --> wnat yo cretae a model and want you to sequentially go throgh the following\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    " # make with 1 layer  , used 1 - becausse in this case we want a model which takes input 1 no and predict one no.  \n",
    "    # tf.keras.layers.Dense(1)  # add them to ypur layer\n",
    "    # tf.keras.layers.Dense(1) --> no of diiferenrr hidden layers\n",
    "    #(1) -- no of ddifefrent hidden neurons in each of those layers\n",
    "\n",
    "# or\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(1))\n",
    "# model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "# can put layers, can use .add etod to add them to the sequential model\n",
    "# or can put them into a list as done above and them to your layer\n",
    "\n",
    "\n",
    "# 2 compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,          \n",
    "            optimizer=tf.keras.optimizers.SGD(),     \n",
    "            metrics = [\"mae\"])\n",
    "\n",
    "# mae is shrt for mean absolute error, computes the mean absolute error between labels and predictions, on average how wrong our prediction is\n",
    "#  sgd is short for stochstic gradient descent\n",
    "    \n",
    "# 3 . fit the model\n",
    "# fit the model on X and y for 5 laps,\n",
    "#  telling our model that lokk at X and y and try and figure out the patterns and you have 5 oppurtunities to go throgh all X and y  can set it to more\n",
    "\n",
    "model.fit(X, y, epochs=5)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss --> is our loss function --> how wrong oyr deep neural network is \n",
    "\n",
    "# because we have set our metrics same as loss function - we get same output in evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make prediction using our model\n",
    "# check out X and y\n",
    "X ,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction using our model\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.245661]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([11.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[12.716021]], dtype=float32), array([[23.71602]], dtype=float32))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.0])\n",
    "y_pred  # on average 11 points off where it should be\n",
    "y_pred, y_pred+11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve our model\n",
    "\n",
    "# can improve model by altering the steps we took to create a model\n",
    "\n",
    "# creating the model --> we migth add more layers, increase the number of hidden units ( also called neurons) within each hidden layers, \n",
    "# we might chnage the activation functions of each layer\n",
    "\n",
    "# --> compiling the model --> can change the optimization function or the laerning rate of the optiixation function\n",
    "\n",
    "# --> fitting the model --> can fit a model for more epochs ( leave it training for longer) or on more data ( give model more example sto learn from)\n",
    "\n",
    "# epochs --> no of times looking at our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger model -->now has 4 hidden layers, hidden neurons in each hidden layers is 100, in compiling change optimization to adam epochs increased to 100 \n",
    "\n",
    "# adam optimization - the optimixzer tells our model how it can improve, adam optimizer is a very comon and useful optimizer \n",
    "# lr parameter - learning rate, how much it should improve every step larger lr -> more the adam optimizer pushes the model to improve, smaller lr - smaller steps our optmizer tells our neural network to improve\n",
    "\n",
    "# in fitting, larger model takes more time to figure out patterns \n",
    "# can split dataset into subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 7.9432 - mae: 7.9432\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.8107 - mae: 7.8107\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6782 - mae: 7.6782\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5457 - mae: 7.5457\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4700 - mae: 7.4700\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4644 - mae: 7.4644\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.4587 - mae: 7.4587\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4531 - mae: 7.4531\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4475 - mae: 7.4475\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4419 - mae: 7.4419\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4363 - mae: 7.4363\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4306 - mae: 7.4306\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4250 - mae: 7.4250\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4194 - mae: 7.4194\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4081 - mae: 7.4081\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4025 - mae: 7.4025\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3969 - mae: 7.3969\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3913 - mae: 7.3913\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3856 - mae: 7.3856\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3800 - mae: 7.3800\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3744 - mae: 7.3744\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3688 - mae: 7.3688\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3631 - mae: 7.3631\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3575 - mae: 7.3575\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3519 - mae: 7.3519\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3463 - mae: 7.3463\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3406 - mae: 7.3406\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3350 - mae: 7.3350\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.3294 - mae: 7.3294\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.3238 - mae: 7.3238\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3181 - mae: 7.3181\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3125 - mae: 7.3125\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3069 - mae: 7.3069\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3012 - mae: 7.3012\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2956 - mae: 7.2956\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2900 - mae: 7.2900\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2844 - mae: 7.2844\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2787 - mae: 7.2787\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2731 - mae: 7.2731\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2675 - mae: 7.2675\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2619 - mae: 7.2619\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2563 - mae: 7.2563\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2506 - mae: 7.2506\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2450 - mae: 7.2450\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2394 - mae: 7.2394\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2338 - mae: 7.2338\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2281 - mae: 7.2281\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2225 - mae: 7.2225\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2169 - mae: 7.2169\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2113 - mae: 7.2113\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2056 - mae: 7.2056\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2000 - mae: 7.2000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1944 - mae: 7.1944\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1887 - mae: 7.1887\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1831 - mae: 7.1831\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1775 - mae: 7.1775\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1719 - mae: 7.1719\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1663 - mae: 7.1663\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1606 - mae: 7.1606\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1550 - mae: 7.1550\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1494 - mae: 7.1494\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1438 - mae: 7.1438\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1381 - mae: 7.1381\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1325 - mae: 7.1325\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1269 - mae: 7.1269\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1213 - mae: 7.1213\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1156 - mae: 7.1156\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1100 - mae: 7.1100\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1044 - mae: 7.1044\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0988 - mae: 7.0988\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0931 - mae: 7.0931\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0875 - mae: 7.0875\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0819 - mae: 7.0819\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0763 - mae: 7.0763\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0706 - mae: 7.0706\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0650 - mae: 7.0650\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0594 - mae: 7.0594\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0538 - mae: 7.0538\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0481 - mae: 7.0481\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0425 - mae: 7.0425\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0369 - mae: 7.0369\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0312 - mae: 7.0312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0256 - mae: 7.0256\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0200 - mae: 7.0200\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0144 - mae: 7.0144\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0088 - mae: 7.0088\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0031 - mae: 7.0031\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9975 - mae: 6.9975\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9919 - mae: 6.991 - 0s 5ms/step - loss: 6.9919 - mae: 6.9919\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9862 - mae: 6.9862\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9806 - mae: 6.9806\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9750 - mae: 6.9750\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9694 - mae: 6.9694\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9638 - mae: 6.9638\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9581 - mae: 6.9581\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9525 - mae: 6.9525\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9469 - mae: 6.9469\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9413 - mae: 6.9413\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9356 - mae: 6.9356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2854be80>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by increasing the number of epochs --> looking the training data 100 times\n",
    "\n",
    "# create model  --> its a sequential model --> meaning it will run from bottom to top, pass throgh this one layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile model\n",
    "# defined our loss function as mean absolute error \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer =tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model ( train for longer)\n",
    "model.fit(X, y, epochs = 100)\n",
    "\n",
    "# the final loss and mae \n",
    "#trying to get this lower (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.833738]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.081117]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[189.622]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([111\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so just by altering one hyperparameter of our model -- no of epochs -- decreased our loss and mae from 11 to 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022F299B49D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.955261]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 10.5874 - mae: 10.5874\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5869 - mae: 10.5869\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5865 - mae: 10.5865\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5860 - mae: 10.5860\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5856 - mae: 10.5856\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5851 - mae: 10.5851\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5847 - mae: 10.5847\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5842 - mae: 10.5842\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5838 - mae: 10.5838\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5833 - mae: 10.5833\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5829 - mae: 10.5829\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5824 - mae: 10.5824\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5820 - mae: 10.5820\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5815 - mae: 10.5815\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5811 - mae: 10.5811\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.5806 - mae: 10.5806\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5802 - mae: 10.5802\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5797 - mae: 10.5797\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5793 - mae: 10.5793\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5788 - mae: 10.5788\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5784 - mae: 10.5784\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5779 - mae: 10.5779\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.5775 - mae: 10.5775\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5770 - mae: 10.5770\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5766 - mae: 10.5766\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5761 - mae: 10.5761\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5757 - mae: 10.5757\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5752 - mae: 10.5752\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5748 - mae: 10.5748\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5743 - mae: 10.5743\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5739 - mae: 10.5739\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.5734 - mae: 10.5734\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.5730 - mae: 10.5730\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5725 - mae: 10.5725\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5721 - mae: 10.5721\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5712 - mae: 10.5712\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5707 - mae: 10.5707\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5703 - mae: 10.5703\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5698 - mae: 10.5698\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5694 - mae: 10.5694\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5689 - mae: 10.5689\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5685 - mae: 10.5685\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5680 - mae: 10.5680\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5676 - mae: 10.5676\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5671 - mae: 10.5671\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.5667 - mae: 10.5667\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5662 - mae: 10.5662\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5658 - mae: 10.5658\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5653 - mae: 10.5653\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5649 - mae: 10.5649\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5644 - mae: 10.5644\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5640 - mae: 10.5640\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5635 - mae: 10.5635\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5631 - mae: 10.5631\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5626 - mae: 10.5626\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5622 - mae: 10.5622\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5617 - mae: 10.5617\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5613 - mae: 10.5613\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.5608 - mae: 10.5608\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5604 - mae: 10.5604\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5599 - mae: 10.5599\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5595 - mae: 10.5595\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5590 - mae: 10.5590\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5586 - mae: 10.5586\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5581 - mae: 10.5581\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5577 - mae: 10.5577\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5572 - mae: 10.5572\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.5568 - mae: 10.5568\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5563 - mae: 10.5563\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5559 - mae: 10.5559\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5554 - mae: 10.5554\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5550 - mae: 10.5550\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5545 - mae: 10.5545\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5541 - mae: 10.5541\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5536 - mae: 10.5536\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5532 - mae: 10.5532\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5527 - mae: 10.5527\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5523 - mae: 10.5523\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5518 - mae: 10.5518\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5514 - mae: 10.5514\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5509 - mae: 10.5509\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5505 - mae: 10.5505\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5500 - mae: 10.5500\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5496 - mae: 10.5496\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5491 - mae: 10.5491\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5487 - mae: 10.5487\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5482 - mae: 10.5482\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5478 - mae: 10.5478\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5473 - mae: 10.5473\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5469 - mae: 10.5469\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5464 - mae: 10.5464\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5460 - mae: 10.5460\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5455 - mae: 10.5455\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5451 - mae: 10.5451\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5446 - mae: 10.5446\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5442 - mae: 10.5442\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5437 - mae: 10.5437\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5433 - mae: 10.5433\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5428 - mae: 10.5428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f299025e0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also can change the optimizer, can add one hidden layer, can increase the number of neurons in each hidden layer\n",
    "\n",
    "# creating the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022F2AABF0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30.130241]], dtype=float32)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 12.1815 - mae: 12.1815\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6749 - mae: 11.6749\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.1534 - mae: 11.1534\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.6492 - mae: 10.6492\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1213 - mae: 10.1213\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5802 - mae: 9.5802\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.0121 - mae: 9.0121\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4049 - mae: 8.4049\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.7530 - mae: 7.7530\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0502 - mae: 7.0502\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.2911 - mae: 6.2911\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4690 - mae: 5.4690\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5768 - mae: 4.5768\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0327 - mae: 4.0327\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9158 - mae: 3.9158\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9665 - mae: 3.9665\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9010 - mae: 3.9010\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9615 - mae: 3.9615\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9098 - mae: 3.9098\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9442 - mae: 3.9442\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9219 - mae: 3.9219\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9190 - mae: 3.9190\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9283 - mae: 3.9283\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8937 - mae: 3.8937\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9348 - mae: 3.9348\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8698 - mae: 3.8698\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9397 - mae: 3.9397\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8845 - mae: 3.8845\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9214 - mae: 3.9214\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8910 - mae: 3.8910\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8960 - mae: 3.8960\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8976 - mae: 3.8976\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8704 - mae: 3.8704\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9044 - mae: 3.9044\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8446 - mae: 3.8446\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9170 - mae: 3.9170\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8546 - mae: 3.8546\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8973 - mae: 3.8973\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8613 - mae: 3.8613\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8716 - mae: 3.8716\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8681 - mae: 3.8681\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8458 - mae: 3.8458\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8750 - mae: 3.8750\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8234 - mae: 3.8234\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8905 - mae: 3.8905\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.8258 - mae: 3.8258\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8719 - mae: 3.8719\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8326 - mae: 3.8326\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8460 - mae: 3.8460\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8397 - mae: 3.8397\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8198 - mae: 3.8198\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8482 - mae: 3.8482\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8013 - mae: 3.8013\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8623 - mae: 3.8623\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7981 - mae: 3.7981\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8452 - mae: 3.8452\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8051 - mae: 3.8051\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8190 - mae: 3.8190\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8123 - mae: 3.8123\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7926 - mae: 3.7926\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8271 - mae: 3.8271\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7737 - mae: 3.7737\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8354 - mae: 3.8354\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7714 - mae: 3.7714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8173 - mae: 3.8173\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7786 - mae: 3.7786\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7907 - mae: 3.7907\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7860 - mae: 3.7860\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7697 - mae: 3.7697\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8019 - mae: 3.8019\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7448 - mae: 3.7448\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8094 - mae: 3.8094\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7457 - mae: 3.7457\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7880 - mae: 3.7880\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7532 - mae: 3.753 - 0s 6ms/step - loss: 3.7532 - mae: 3.7532\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7611 - mae: 3.7611\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7641 - mae: 3.7641\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7418 - mae: 3.7418\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7768 - mae: 3.7768\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7145 - mae: 3.7145\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7845 - mae: 3.7845\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7211 - mae: 3.7211\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7574 - mae: 3.7574\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7288 - mae: 3.7288\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7317 - mae: 3.7317\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7105 - mae: 3.7105\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7527 - mae: 3.7527\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6898 - mae: 3.6898\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7528 - mae: 3.7528\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6975 - mae: 3.6975\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7255 - mae: 3.7255\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7054 - mae: 3.7054\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7051 - mae: 3.7051\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7217 - mae: 3.7217\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6779 - mae: 3.6779\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7297 - mae: 3.7297\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6669 - mae: 3.6669\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7198 - mae: 3.719 - 0s 6ms/step - loss: 3.7198 - mae: 3.7198\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6749 - mae: 3.6749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2bbb2430>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making another change to improve our model --> increase one layer\n",
    "## \n",
    "# creating the model with an extra hidden layer (with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation = \"relu\"),  # relu activation  can also take --> # can take activation function = None\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,   # or can write loss = \"mae\",  \n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, y, epochs = 100)  # first features come(X) , then comes labels(Y) \n",
    "\n",
    "# mae - on an average , how wrong our model prediction is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.425943]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction\n",
    "model.predict([17])\n",
    "\n",
    "# in this case it gives even more error but mae is slower\n",
    "# --->  implies that our model may be overfitting --> it might be learning the training data too well\n",
    "\n",
    "# learning patterns bet X and y too well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9976897]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting --> means during training\n",
    "\n",
    "# main thing is how our model performs on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 13.3616 - mae: 13.3616\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.2981 - mae: 13.2981\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.2346 - mae: 13.2346\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.1711 - mae: 13.1711\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 13.1077 - mae: 13.1077\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.0442 - mae: 13.0442\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.9807 - mae: 12.9807\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.9172 - mae: 12.9172\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8536 - mae: 12.8536\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.7900 - mae: 12.7900\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.7264 - mae: 12.7264\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.6627 - mae: 12.6627\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5989 - mae: 12.5989\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.5351 - mae: 12.5351\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.4712 - mae: 12.4712\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.4071 - mae: 12.4071\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.3430 - mae: 12.3430\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2788 - mae: 12.2788\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2144 - mae: 12.2144\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1500 - mae: 12.1500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.0853 - mae: 12.0853\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0206 - mae: 12.0206\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.9556 - mae: 11.9556\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8905 - mae: 11.8905\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.8253 - mae: 11.8253\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7598 - mae: 11.7598\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6942 - mae: 11.6942\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.6283 - mae: 11.6283\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5623 - mae: 11.5623\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.4960 - mae: 11.4960\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4295 - mae: 11.4295\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3628 - mae: 11.3628\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2958 - mae: 11.2958\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2286 - mae: 11.2286\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.1611 - mae: 11.1611\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.0933 - mae: 11.0933\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.0253 - mae: 11.0253\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9570 - mae: 10.9570\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8884 - mae: 10.8884\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8195 - mae: 10.8195\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.7503 - mae: 10.7503\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6807 - mae: 10.6807\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6109 - mae: 10.6109\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5407 - mae: 10.5407\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4702 - mae: 10.4702\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.3993 - mae: 10.3993\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3281 - mae: 10.3281\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.2566 - mae: 10.2566\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1846 - mae: 10.1846\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1123 - mae: 10.1123\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0397 - mae: 10.0397\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9666 - mae: 9.9666\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8932 - mae: 9.8932\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.8193 - mae: 9.8193\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.7450 - mae: 9.7450\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6704 - mae: 9.6704\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5953 - mae: 9.5953\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5198 - mae: 9.5198\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4438 - mae: 9.4438\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3674 - mae: 9.3674\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2906 - mae: 9.2906\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2133 - mae: 9.2133\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.1356 - mae: 9.1356\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0574 - mae: 9.0574\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9787 - mae: 8.9787\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.8996 - mae: 8.8996\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8200 - mae: 8.8200\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7399 - mae: 8.7399\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6593 - mae: 8.6593\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5782 - mae: 8.5782\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4966 - mae: 8.4966\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4145 - mae: 8.4145\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3319 - mae: 8.3319\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2487 - mae: 8.2487\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.1650 - mae: 8.1650\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.0808 - mae: 8.0808\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9961 - mae: 7.9961\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9108 - mae: 7.9108\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.8250 - mae: 7.8250\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7386 - mae: 7.7386\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.6516 - mae: 7.6516\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5641 - mae: 7.5641\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4761 - mae: 7.4761\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3874 - mae: 7.3874\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2982 - mae: 7.2982\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2083 - mae: 7.2083\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1179 - mae: 7.1179\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0269 - mae: 7.0269\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9353 - mae: 6.9353\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8431 - mae: 6.8431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7503 - mae: 6.7503\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7062 - mae: 6.7062\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6943 - mae: 6.6943\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6827 - mae: 6.6827\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6714 - mae: 6.6714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6603 - mae: 6.6603\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6495 - mae: 6.6495\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6388 - mae: 6.6388\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6283 - mae: 6.6283\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6180 - mae: 6.6180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2bc22220>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making another change to improve our model --> increase one layer\n",
    "## \n",
    "# creating the model with an extra hidden layer (with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation = None),  # relu activation  can also take --> # can take activation function = None\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,   # or can write loss = \"mae\",  \n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, y, epochs = 100)  # first features come(X) , then comes labels(Y) \n",
    "\n",
    "# mae - on an average , how wrong our model prediction is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.484047]], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new sample \n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 14.4889 - mae: 14.4889\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.7204 - mae: 13.7204\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9558 - mae: 12.9558\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.1943 - mae: 12.1943\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4335 - mae: 11.4335\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.6713 - mae: 10.6713\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9055 - mae: 9.9055\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.1344 - mae: 9.1344\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3556 - mae: 8.3556\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5670 - mae: 7.5670\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7662 - mae: 6.7662\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.6955 - mae: 6.6955\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0553 - mae: 7.0553\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3170 - mae: 7.3170\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5321 - mae: 7.5321\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5373 - mae: 7.5373\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3799 - mae: 7.3799\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0961 - mae: 7.0961\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8115 - mae: 6.8115\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.5498 - mae: 6.5498\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2733 - mae: 6.2733\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0405 - mae: 6.0405\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9927 - mae: 5.9927\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.9806 - mae: 5.9806\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0575 - mae: 6.0575\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0368 - mae: 6.0368\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9300 - mae: 5.9300\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7459 - mae: 5.7459\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5496 - mae: 5.5496\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4525 - mae: 5.4525\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3527 - mae: 5.3527\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.2715 - mae: 5.2715\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.2437 - mae: 5.2437\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1738 - mae: 5.1738\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.0653 - mae: 5.0653\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.9213 - mae: 4.9213\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7861 - mae: 4.7861\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6932 - mae: 4.6932\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5946 - mae: 4.5946\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4900 - mae: 4.4900\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3793 - mae: 4.3793\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.2625 - mae: 4.2625\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1394 - mae: 4.1394\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0259 - mae: 4.0259\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8644 - mae: 3.8644\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7127 - mae: 3.7127\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.5546 - mae: 3.5546\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4137 - mae: 3.4137\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2781 - mae: 3.2781\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0887 - mae: 3.0887\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9112 - mae: 2.9112\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7441 - mae: 2.7441\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5669 - mae: 2.5669\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4430 - mae: 2.4430\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.1712 - mae: 2.1712\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9534 - mae: 1.9534\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7315 - mae: 1.7315\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5116 - mae: 1.5116\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2754 - mae: 1.2754\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0746 - mae: 1.0746\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7776 - mae: 0.7776\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5647 - mae: 0.5647\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3138 - mae: 0.3138\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2068 - mae: 0.2068\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2753 - mae: 0.2753\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - mae: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5904 - mae: 0.5904\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6596 - mae: 0.6596\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7348 - mae: 0.7348\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6845 - mae: 0.6845\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6698 - mae: 0.6698\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5823 - mae: 0.5823\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5082 - mae: 0.5082\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3435 - mae: 0.3435\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2407 - mae: 0.2407\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0927 - mae: 0.0927\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1227 - mae: 0.1227\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2664 - mae: 0.2664\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3580 - mae: 0.3580\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3578 - mae: 0.3578\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4553 - mae: 0.4553\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4116 - mae: 0.4116\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3394 - mae: 0.3394\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2711 - mae: 0.2711\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2318 - mae: 0.2318\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1627 - mae: 0.1627\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1842 - mae: 0.1842\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2410 - mae: 0.2410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1765 - mae: 0.1765\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2222 - mae: 0.2222\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1781 - mae: 0.1781\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0933 - mae: 0.0933\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0846 - mae: 0.0846\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2120 - mae: 0.2120\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1663 - mae: 0.1663\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2844 - mae: 0.2844\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3299 - mae: 0.3299\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2170 - mae: 0.2170\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1968 - mae: 0.1968\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1727 - mae: 0.1727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2ce331f0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the learning rate  --> optimizer tells our model how it should improve, lr tells it by how much it should\n",
    "\n",
    "# making another change to improve our model --> increase one layer\n",
    "## \n",
    "# creating the model with an extra hidden layer (with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation = None),  # relu activation  can also take --> # can take activation function = None\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,   # or can write loss = \"mae\",  \n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),   # adam lr = 0.001 by default -> increase it by 10  = 0.1\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, y, epochs = 100)  # first features come(X) , then comes labels(Y) \n",
    "\n",
    "# mae - on an average , how wrong our model prediction is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.587706]], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])   # best model sso far as we see from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can see that in this case, adjusting the lr of optimizer yields best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp --> learning rate is most imp hyperparameter can change on all neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a larger data set\n",
    "\n",
    "# common ways to improve a model -\n",
    "# adding layers\n",
    "# increase no of hidden units\n",
    "# change the activation function\n",
    "# change the learning rate\n",
    "# fitting on more data \n",
    "# fitting for longer --> increase no of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating a model -- how exactly  do we tell how good ourr model predictions are, how good the patterns it has laerned bet X and y are\n",
    "\n",
    "## normally, a workflow for building neural networks is -->\n",
    "\n",
    "# build a model, fit it, evaluate it, tweak a model, fit it, evaluate it, tweak a model, fit it, evaluate it, ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter -> like  a dial n your neurakl network you can adjust to see how it improves\n",
    "\n",
    "# parameter --> usually the patterns that neural network learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation --> visualize, .....\n",
    "\n",
    "# we should visualize \n",
    "# visualize the data -> what data are we working eith, how does it look like\n",
    "# model itself, how does it look klike\n",
    "# training of a model --> how does a model perform while it learns\n",
    "# predictions of the model - how do the predictions of a model line up against the ground truth (original labels)\n",
    "\n",
    "# for building --> experiment, ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a bigger data set \n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels for the data set\n",
    "y = X+10;  # formual we wnat our model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22f2df3ddc0>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visulaize the data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22f2ccda970>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 3 sets... split X and y into training and test set\n",
    "# not going to fit and evaluate om the same set\n",
    "\n",
    "# actually --> 3 different set sof data \n",
    "# 1 --> training set -> the model learns from this data, which is typically 70-80% of the total data you have available\n",
    "\n",
    "# 2 --> validation set -> the model gets tuned on this data\n",
    "#   this is where you tweak different things --> changing no of hidden layers, optimization function, will test how hese tweaks affected your model's performance on the validation set\n",
    "#    typically 10-15% of the data available\n",
    "\n",
    "\n",
    "# 3 --> the model gets evaluated on this data to test what it has learn, has typically 10-15% of the total data available\n",
    "\n",
    "\n",
    "# check the length of how many samples we have \n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train and test sets\n",
    "\n",
    "X_train = X[:40] # first 40 are training samples ( 80 % of the data) --> training features\n",
    "# train_data =\n",
    "y_train = y[:40] # testing features\n",
    "\n",
    "X_test = X[40:] # last 10 are testing samples (20% of the data) --> training labels\n",
    "y_test = y[40:]  # test labels\n",
    "# test_data =  \n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the data\n",
    "# training and test set - visualize it\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7)) # setting figure beccause we have to plot two samples of data\n",
    "# plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label = \"Training data\")  # our model will learn on this\n",
    "\n",
    "#plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label = \"Tesing data\")  # want our model to be able to predict this(given x, what's y)\n",
    "\n",
    "#shw a legend\n",
    "plt.legend();\n",
    "\n",
    "# to visualize your data, or model easier to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a neural network to take training data to leran the relationships, so that it can oredict our test data\n",
    "\n",
    "# creating model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)  # one hidden layer --> has one hidden unit because we are using 1 X value to predict one Y value therfore dense layer has one unit \n",
    "])\n",
    "\n",
    "# compile model\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics =[\"mae\"])\n",
    "\n",
    "# fit\n",
    "\n",
    "# model.fit(X_train, y_train, epochs = 100)  # fit on training data only -> blue line in the graph -> want our model to learn patterns in training data to predict patterns  in the test data  \n",
    "\n",
    "\n",
    "# 1, 2--> instantiates the model here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-229-a16bb951c384>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# visualizing the model --> how model looks like before running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2519\u001b[0m     \"\"\"\n\u001b[0;32m   2520\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2521\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2522\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2523\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "# visualizing the model --> how model looks like before running it\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide an `input_shape` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-230-2f52417d930d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You must provide an `input_shape` argument.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_graph_network_for_inferred_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You must provide an `input_shape` argument."
     ]
    }
   ],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([50]), TensorShape([]))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X[0].shape  # ---> we want only one sample of X so did X[0].shape --> scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model which builds automatically by defining the input shape arguement in the first layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create model --> Sequential model runs from top to bottom\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1])  # one hidden layer --> has one hidden unit because we are using 1 X value to predict one Y value therfore dense layer has one unit \n",
    "])\n",
    "\n",
    "\n",
    "# input_shape = 1 because we are passing one no to predict another no\n",
    "\n",
    "\n",
    "# compile model\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics =[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summmary shows us the layers that it contains , the output shape, and the no of parameters of each layer\n",
    "\n",
    "# in above model --> layer is type dense\n",
    "# dense means fully connected --> all neurons in one layer are connected to all neurons in next layer\n",
    "\n",
    "# param --> parameters no \n",
    "\n",
    "\n",
    "# neural network creates tensors of diffferent values, patterns \n",
    "# total no of parameters -> is the different no of patterns our model is going to try and learn, relation bet X and y data\n",
    "\n",
    "# total params -->> total no of paramaters in the model -> these are the parameters that our model is going to learn\n",
    "# Trainable parameters --> these are the parameters(patterns) the model can update as it trains.\n",
    "# Non-trainabe parameters --> these parameters are'nt updated during training ( this is typical when we bring in already learned parameters or patterns from other models during transfer learning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to see actual parameters in a dense layer -->\n",
    "\n",
    "# will find weights matrix and a bias vector\n",
    "\n",
    "# within hidden layer --> we have a bunch of different parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more about trainable parametres within a layer, check out MIT'S intro to deep learning module \n",
    "\n",
    "# Imp --> no of hidden units in the dense layer and see how it affects the no of parametrs -> total and trainable by using model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get a summary of our model\n",
    "model.summary()  # here sequential_22 shows that we have created 22 sequential models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shpws that there are 2 trainable params per hidden unit in our dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2f2d2580>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit our model to the training data\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "\n",
    "# verbose --> 0 --> will not get any output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4494 - mae: 7.4494\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2391 - mae: 9.2391\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6116 - mae: 9.6116\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7602 - mae: 8.7602\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7251 - mae: 9.7251\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9002 - mae: 8.9002\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0002 - mae: 8.0002\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1138 - mae: 8.1138\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.0986 - mae: 19.0986\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3698 - mae: 9.3698\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5493 - mae: 7.5493\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8866 - mae: 9.8866\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9273 - mae: 8.9273\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.9891 - mae: 10.9891\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6094 - mae: 12.6094\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.4175 - mae: 6.4175\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6479 - mae: 7.6479\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2152 - mae: 10.2152\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.3227 - mae: 18.3227\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0241 - mae: 15.0241\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5285 - mae: 10.5285\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.0450 - mae: 7.0450\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7253 - mae: 8.7253\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5994 - mae: 7.5994\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1121 - mae: 10.1121\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3869 - mae: 16.3869\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5856 - mae: 12.5856\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7632 - mae: 13.7632\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.0995 - mae: 9.0995\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4324 - mae: 15.4324\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.7275 - mae: 23.7275\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.6583 - mae: 6.6583\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3521 - mae: 9.3521\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9275 - mae: 8.9275\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0428 - mae: 7.0428\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9966 - mae: 8.9966\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7731 - mae: 8.7731\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5648 - mae: 9.5648\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0424 - mae: 15.0424\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.7918 - mae: 12.7918\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5636 - mae: 8.5636\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4069 - mae: 10.4069\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9575 - mae: 10.9575\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4550 - mae: 15.4550\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1913 - mae: 11.1913\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3175 - mae: 6.3175\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4750 - mae: 8.4750\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0104 - mae: 8.0104\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8868 - mae: 6.8868\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6688 - mae: 8.6688\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6195 - mae: 8.6195\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3668 - mae: 10.3668\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7298 - mae: 11.7298\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4147 - mae: 17.4147\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.1775 - mae: 15.1775\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3830 - mae: 10.3830\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7312 - mae: 8.7312\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0396 - mae: 8.0396\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2555 - mae: 9.2555\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4949 - mae: 7.4949\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3574 - mae: 8.3574\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3038 - mae: 6.3038\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2954 - mae: 7.2954\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.0381 - mae: 12.0381\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1088 - mae: 9.1088\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5762 - mae: 15.5762\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4988 - mae: 9.4988\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3459 - mae: 7.3459\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3723 - mae: 13.3723\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1456 - mae: 6.1456\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7084 - mae: 12.7084\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6625 - mae: 8.6625\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7664 - mae: 10.7664\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6373 - mae: 11.6373\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3771 - mae: 6.3771\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1117 - mae: 10.1117\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0869 - mae: 10.0869\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7024 - mae: 11.7024\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6771 - mae: 14.6771\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0129 - mae: 11.0129\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1555 - mae: 10.1555\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1339 - mae: 7.1339\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0773 - mae: 8.0773\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7051 - mae: 6.7051\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.1770 - mae: 16.1770\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5961 - mae: 11.5961\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4826 - mae: 11.4826\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5591 - mae: 9.5591\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.0280 - mae: 6.0280\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.9257 - mae: 12.9257\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8810 - mae: 6.8810\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1209 - mae: 7.1209\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5510 - mae: 8.5510\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8979 - mae: 7.8979\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3865 - mae: 11.3865\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4120 - mae: 8.4120\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1666 - mae: 12.1666\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4770 - mae: 7.4770\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2216 - mae: 8.2216\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6944 - mae: 9.6944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2f713700>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 100, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model=model, show_shapes=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model which builds automatically by defining the input shape arguement in the first layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create model --> Sequential model runs from top to bottom\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"Input_layer\"),  # one hidden layer --> has one hidden unit because we are using 1 X value to predict one Y value therfore dense layer has one unit \n",
    "    tf.keras.layers.Dense(1, name=\"Output_layer\")\n",
    "], name =\"model_1\")\n",
    "\n",
    "\n",
    "# input_shape = 1 because we are passing one no to predict another no\n",
    "\n",
    "\n",
    "# compile model\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics =[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "Output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2f364e50>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.552185],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72764 ],\n",
       "       [ 84.315346],\n",
       "       [ 88.90308 ],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07852 ],\n",
       "       [102.666245],\n",
       "       [107.253975],\n",
       "       [111.84169 ]], dtype=float32)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize model predictions\n",
    "\n",
    "# to visualize predictions, its a agood idea to plot them against the ground truth labels.\n",
    "# often we see this in form of y_test or y_true versus y_pred (ground truth versus your model predictions)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the comparison\n",
    "# if fwant to use a fuctionality in the future --> can use it in a function\n",
    "# creating a plotting function\n",
    "\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=y_pred):\n",
    "    # plots training data, tetst data, and compares predictions to ground truth labels\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    #training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "    #test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
    "    #model's prredictions in red and want to compare  them to the test data \n",
    "    plt.scatter(test_data, predictions, c=\"r\", label = \"Predictions\")\n",
    "    # show legend\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(train_data =X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distance between the red and green dots could be a fairly large erroor depending on the scale\n",
    "# can figure this out by some regression evaluation metrics\n",
    "\n",
    "# Depending on the problem we work , there are different evaluation metrics to evaluate your model's performance\n",
    "# Since we work on a gregression problem, two main metrics are mae--mean absolute error--> on average, how wrong is each pf our model's predictions is\n",
    "# mse - mean square error --> square the average errors and then find the average  -> used when larger errors are more significant than smaller errors\n",
    "\n",
    "# abs(labels - predictions)\n",
    "# y with hat ---> is y_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 230ms/step - loss: 3.1969 - mae: 3.1969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1969382762908936, 3.1969382762908936]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on test set\n",
    "\n",
    "model.evaluate(X_test, y_test)  # in doc string --> return s the loss value and metrics values for the model in the test mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.558252 , 14.1160555, 11.708944 , 10.336931 , 10.       ,\n",
       "       10.698161 , 12.447113 , 15.332995 , 19.253975 , 23.84169  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean absolute error\n",
    "# tf.keras.losses.MAE(y_test, y_pred)\n",
    "\n",
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred = tf.constant(y_pred))\n",
    "mae\n",
    "# this gives us metric for each of the test labels and predictions --> maybe because y_pred is not a tensor --> turn y_pred into a rensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 70.552185],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72764 ],\n",
       "       [ 84.315346],\n",
       "       [ 88.90308 ],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07852 ],\n",
       "       [102.666245],\n",
       "       [107.253975],\n",
       "       [111.84169 ]], dtype=float32)>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>,\n",
       " array([[ 70.552185],\n",
       "        [ 75.13991 ],\n",
       "        [ 79.72764 ],\n",
       "        [ 84.315346],\n",
       "        [ 88.90308 ],\n",
       "        [ 93.49081 ],\n",
       "        [ 98.07852 ],\n",
       "        [102.666245],\n",
       "        [107.253975],\n",
       "        [111.84169 ]], dtype=float32))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but y_pred and y_test are not in same shape\n",
    "# in comparison we have to the reshape the tensors for same format\n",
    "\n",
    "#y_pred = tf.reshape(tf.constant(y_pred), shape=(10))\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.metrics.mean_absolute_error(y_true=y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 70.552185,  75.13991 ,  79.72764 ,  84.315346,  88.90308 ,\n",
       "         93.49081 ,  98.07852 , 102.666245, 107.253975, 111.84169 ],\n",
       "       dtype=float32)>,\n",
       " array([[ 70.552185],\n",
       "        [ 75.13991 ],\n",
       "        [ 79.72764 ],\n",
       "        [ 84.315346],\n",
       "        [ 88.90308 ],\n",
       "        [ 93.49081 ],\n",
       "        [ 98.07852 ],\n",
       "        [102.666245],\n",
       "        [107.253975],\n",
       "        [111.84169 ]], dtype=float32))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or can use the squueze method --> remove one dimension of y_pred tensor\n",
    "tf.squeeze(y_pred), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.19694>"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean absolute error\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=tf.squeeze(y_pred))\n",
    "mae  # gives same result as evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.070127>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcullate the mean squared error\n",
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=tf.squeeze(y_pred))  # tf.squeeze removes the single dimension from the y_pred \n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making function for mean_squared_error and mean_absolute_error\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred=tf.squeeze(y_pred))\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_true, y_pred=tf.squeeze(y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to lower difference bet predictions and test labels\n",
    "# improve model --> build , fit, evaluate it, tweak it, fit, evaluate it, tweak it\n",
    "\n",
    "# some ways to improve --> 1 get some more data - get more examples for model to train on(more oppurtunities to learn patterns or relationships between labels and features)\n",
    "#2 . make your model lareger ( using a more complex model) - can add ore layers or more hidden units in each layer\n",
    "#3. train for longer - give model more chance to find patterns in the data\n",
    "\n",
    "# 1. model_1 - same as original model, 1 layer, trained for 100 epochs\n",
    "# 2. model_2 - 2 layers, trianed for 100 epochs\n",
    "# 3. model_3 - 2 layers, trianed for 500 epochs\n",
    "# build model 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 3s 4ms/step - loss: 15.9024 - mae: 15.9024\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2837 - mae: 11.2837\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1075 - mae: 11.1075\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.2990 - mae: 9.2990\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1677 - mae: 10.1677\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4303 - mae: 9.4303\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.5704 - mae: 8.5704\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0442 - mae: 9.0442\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.7517 - mae: 18.7517\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1142 - mae: 10.1142\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3980 - mae: 8.3980\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6639 - mae: 10.6639\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7977 - mae: 9.7977\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.0103 - mae: 16.0103\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - ETA: 0s - loss: 11.5474 - mae: 11.547 - 0s 8ms/step - loss: 11.4068 - mae: 11.4068\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5393 - mae: 8.5393\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6348 - mae: 13.6348\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4629 - mae: 11.4629\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9148 - mae: 17.9148\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 15.0494 - mae: 15.0494\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0216 - mae: 11.0216\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1558 - mae: 8.1558\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5138 - mae: 9.5138\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6617 - mae: 7.6617\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.1859 - mae: 13.1859\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4211 - mae: 16.4211\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.1660 - mae: 13.1660\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2559 - mae: 14.2559\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0670 - mae: 10.0670\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.3409 - mae: 16.3409\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.6444 - mae: 23.6444\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.6215 - mae: 7.6215\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3221 - mae: 9.3221\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7313 - mae: 13.7313\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1276 - mae: 11.1276\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3222 - mae: 13.3222\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.4763 - mae: 9.4763\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1381 - mae: 10.1381\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1793 - mae: 10.1793\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9137 - mae: 10.9137\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9063 - mae: 7.9063\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0914 - mae: 10.0914\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7006 - mae: 8.7006\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2046 - mae: 12.2046\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7970 - mae: 13.7970\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4687 - mae: 8.4687\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.1330 - mae: 9.1330\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6190 - mae: 10.6190\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.7503 - mae: 7.7503\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.5407 - mae: 9.5407\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.1584 - mae: 9.1584\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.3630 - mae: 16.3630\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.1299 - mae: 14.1299\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.1247 - mae: 21.1247\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3961 - mae: 16.3961\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9806 - mae: 9.9806\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.9606 - mae: 9.9606\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 9.2209 - mae: 9.2209\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4239 - mae: 8.4239\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4869 - mae: 9.4869\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4354 - mae: 11.4354\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6887 - mae: 11.6887\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0838 - mae: 7.0838\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.9675 - mae: 16.9675\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4599 - mae: 12.4599\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.0184 - mae: 13.0184\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.0600 - mae: 8.0600\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1888 - mae: 10.1888\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.3633 - mae: 12.3633\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.0516 - mae: 9.0516\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.0378 - mae: 10.0378\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0516 - mae: 10.0516\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.6151 - mae: 12.6151\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3819 - mae: 10.3819\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7229 - mae: 9.7229\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2252 - mae: 11.2252\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3642 - mae: 8.3642\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1274 - mae: 9.1274\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.5039 - mae: 19.5039\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8945 - mae: 14.8945\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.0034 - mae: 9.0034\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0206 - mae: 13.0206\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.9299 - mae: 7.9299\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6872 - mae: 7.6872\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.0328 - mae: 10.0328\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2433 - mae: 9.2433\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0209 - mae: 12.0209\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.6389 - mae: 10.6389\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2667 - mae: 7.2667\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7786 - mae: 12.7786\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.3481 - mae: 7.3481\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 7.7175 - mae: 7.7175\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1263 - mae: 7.1263\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6190 - mae: 12.6190\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0912 - mae: 10.0912\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3558 - mae: 9.3558\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6834 - mae: 12.6834\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6762 - mae: 8.6762\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4693 - mae: 9.4693\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7067 - mae: 8.7067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f30d57040>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42) # for reproducability as much as possible\n",
    "model_1 = tf.keras.Sequential([\n",
    "tf.keras.layers.Dense(1)  # sinle layer\n",
    "])\n",
    "\n",
    "model_1.compile(loss=tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "               metrics=[\"mae\"])\n",
    "\n",
    "model_1.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make and plot predictions for model 1\n",
    "y_pred_1 = model_1.predict(X_test)  # X_test is data model has never seen, y_test are the actual values\n",
    "plot_predictions(predictions=y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       " array([[53.57109 ],\n",
       "        [57.05633 ],\n",
       "        [60.541573],\n",
       "        [64.02681 ],\n",
       "        [67.512054],\n",
       "        [70.99729 ],\n",
       "        [74.48254 ],\n",
       "        [77.96777 ],\n",
       "        [81.45301 ],\n",
       "        [84.938255]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([53.57109 , 57.05633 , 60.541573, 64.02681 , 67.512054, 70.99729 ,\n",
       "        74.48254 , 77.96777 , 81.45301 , 84.938255], dtype=float32)>)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_pred_1), tf.squeeze(y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=18.745327>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=353.57336>)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do evaluation metrics for model_1\n",
    "#mae_1 = mae(y_test, tf.squeeze(y_pred_1))\n",
    "#mse_1 = mse(y_test, tf.squeeze(y_pred_1))\n",
    "\n",
    "mae_1 = mae(y_test, (y_pred_1))\n",
    "mse_1 = mse(y_test, (y_pred_1))\n",
    "mae_1, mse_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 1s 5ms/step - loss: 27.4058 - mse: 1084.1482\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.6339 - mse: 777.9203\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.8935 - mse: 1334.8953\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.4055 - mse: 1106.8035\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9463 - mse: 281.1076\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.8819 - mse: 168.6621\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1988 - mse: 151.3508\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0910 - mse: 160.3745\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 40.4763 - mse: 2586.0085\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 27.8687 - mse: 1094.4380\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.2473 - mse: 147.9359\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.2803 - mse: 890.3867\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.9897 - mse: 399.9677\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.9217 - mse: 1049.5515\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9948 - mse: 450.2581\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3510 - mse: 80.6206\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.8636 - mse: 174.7868\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.5304 - mse: 565.8052\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3469 - mse: 167.7749\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.6985 - mse: 455.7096\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8985 - mse: 347.1929\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 14.1991 - mse: 285.1767\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7720 - mse: 91.7852\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0570 - mse: 153.7430\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.6838 - mse: 233.2950\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.1877 - mse: 1024.6094\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7432 - mse: 194.8453\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.8730 - mse: 835.6069\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2459 - mse: 96.7787\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.2641 - mse: 1535.1335\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 53.0224 - mse: 5030.2954\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9951 - mse: 211.7023\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.6357 - mse: 337.3664\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6925 - mse: 214.4822\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2398 - mse: 92.9126\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.6497 - mse: 403.6569\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.0382 - mse: 192.3919\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.1634 - mse: 433.6718\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.1013 - mse: 529.6440\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.4324 - mse: 610.1325\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9102 - mse: 279.6182\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2809 - mse: 186.6180\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7333 - mse: 167.0952\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.0260 - mse: 830.4245\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3897 - mse: 128.9549\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7904 - mse: 181.9211\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6438 - mse: 153.8708\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.2335 - mse: 402.8495\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5729 - mse: 99.8336\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8185 - mse: 260.3669\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5958 - mse: 154.7956\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.5538 - mse: 1613.0883\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.3541 - mse: 302.5291\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 23.9713 - mse: 859.3983\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1938 - mse: 805.5450\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8837 - mse: 170.9834\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7445 - mse: 198.7015\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 9.5995 - mse: 102.5890\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5172 - mse: 216.3367\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.3200 - mse: 208.6370\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.4604 - mse: 428.6392\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6052 - mse: 136.9776\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4893 - mse: 152.4554\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 33ms/step - loss: 24.8450 - mse: 911.7509\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6761 - mse: 142.7374\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.7809 - mse: 704.4487\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7136 - mse: 136.0194\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.6397 - mse: 149.2299\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.6914 - mse: 742.1758\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3316 - mse: 166.1627\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4355 - mse: 323.0844\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.7437 - mse: 67.0210\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 11.6891 - mse: 183.7296\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.0400 - mse: 908.8988\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5896 - mse: 149.3948\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4371 - mse: 188.3310\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 16.6488 - mse: 429.2705\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.0614 - mse: 95.4869\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.9675 - mse: 864.0859\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.7463 - mse: 1104.4030\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6714 - mse: 170.7055\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.0228 - mse: 211.9191\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.4218 - mse: 395.5590\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.2629 - mse: 73.0935\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9650 - mse: 312.8361\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2862 - mse: 315.3606\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.1086 - mse: 521.2535\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.8228 - mse: 1287.1902\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.1742 - mse: 124.1342\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5240 - mse: 663.8608\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5716 - mse: 161.7467\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3977 - mse: 464.1323\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4138 - mse: 81.9820\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.7380 - mse: 445.7377\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1144 - mse: 164.0820\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.4346 - mse: 510.5842\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1593 - mse: 209.9755\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5653 - mse: 169.4052\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.8827 - mse: 265.4630\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.2277 - mse: 608.8219\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f323f63a0>"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build model_2  --> 2 dense layers or fully connected layers trained for 100 epochs\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10),\n",
    "            tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_2.compile(loss = tf.keras.losses.mae,\n",
    "               optimizer=tf.keras.optimizers.SGD(),\n",
    "                metrics=[\"mse\"])\n",
    "\n",
    "\n",
    "model_2.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([60, 64, 68, 72, 76, 80, 84, 88, 92, 96])>,\n",
       " array([[ 70.552185],\n",
       "        [ 75.13991 ],\n",
       "        [ 79.72764 ],\n",
       "        [ 84.315346],\n",
       "        [ 88.90308 ],\n",
       "        [ 93.49081 ],\n",
       "        [ 98.07852 ],\n",
       "        [102.666245],\n",
       "        [107.253975],\n",
       "        [111.84169 ]], dtype=float32))"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test, model_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting predictions\n",
    "y_pred_2 = (model_2.predict(X_test))\n",
    "plot_predictions(predictions=y_pred_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=3.19694>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=13.070127>)"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_2 = mae(y_test, y_pred_2)\n",
    "mse_2 = mse(y_test, y_pred_2)\n",
    "mae_2, mse_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "2/2 [==============================] - 1s 4ms/step - loss: 27.4058 - mae: 27.4058\n",
      "Epoch 2/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 24.6339 - mae: 24.6339\n",
      "Epoch 3/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.8935 - mae: 29.8935\n",
      "Epoch 4/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 27.4055 - mae: 27.4055\n",
      "Epoch 5/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9463 - mae: 14.9463\n",
      "Epoch 6/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 11.8819 - mae: 11.8819\n",
      "Epoch 7/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1988 - mae: 11.1988\n",
      "Epoch 8/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0910 - mae: 11.0910\n",
      "Epoch 9/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 40.4763 - mae: 40.4763\n",
      "Epoch 10/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 27.8687 - mae: 27.8687\n",
      "Epoch 11/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2473 - mae: 10.2473\n",
      "Epoch 12/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.2803 - mae: 25.2803\n",
      "Epoch 13/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.9897 - mae: 16.9897\n",
      "Epoch 14/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.9217 - mae: 25.9217\n",
      "Epoch 15/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9948 - mae: 17.9948\n",
      "Epoch 16/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.3510 - mae: 7.3510\n",
      "Epoch 17/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.8636 - mae: 10.8636\n",
      "Epoch 18/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.5304 - mae: 19.5304\n",
      "Epoch 19/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.3469 - mae: 10.3469\n",
      "Epoch 20/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.6985 - mae: 17.6985\n",
      "Epoch 21/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 15.8985 - mae: 15.8985\n",
      "Epoch 22/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.1991 - mae: 14.1991\n",
      "Epoch 23/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7720 - mae: 8.7720\n",
      "Epoch 24/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0570 - mae: 11.0570\n",
      "Epoch 25/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6838 - mae: 12.6838\n",
      "Epoch 26/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.1877 - mae: 26.1877\n",
      "Epoch 27/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7432 - mae: 11.7432\n",
      "Epoch 28/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.8730 - mae: 22.8730\n",
      "Epoch 29/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2459 - mae: 9.2459\n",
      "Epoch 30/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.2641 - mae: 29.2641\n",
      "Epoch 31/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 53.0224 - mae: 53.0224\n",
      "Epoch 32/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.8826 - mae: 12.882 - 0s 5ms/step - loss: 11.9951 - mae: 11.9951\n",
      "Epoch 33/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.6357 - mae: 15.6357\n",
      "Epoch 34/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6925 - mae: 12.6925\n",
      "Epoch 35/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2398 - mae: 9.2398\n",
      "Epoch 36/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6497 - mae: 16.6497\n",
      "Epoch 37/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.0382 - mae: 11.0382\n",
      "Epoch 38/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.1634 - mae: 18.1634\n",
      "Epoch 39/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 22.1568 - mae: 22.156 - 0s 4ms/step - loss: 19.1013 - mae: 19.1013\n",
      "Epoch 40/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.4324 - mae: 20.4324\n",
      "Epoch 41/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.9102 - mae: 14.9102\n",
      "Epoch 42/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.2809 - mae: 12.2809\n",
      "Epoch 43/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7333 - mae: 10.7333\n",
      "Epoch 44/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.0260 - mae: 23.0260\n",
      "Epoch 45/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3897 - mae: 10.3897\n",
      "Epoch 46/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7904 - mae: 11.7904\n",
      "Epoch 47/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6438 - mae: 9.6438\n",
      "Epoch 48/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.2335 - mae: 17.2335\n",
      "Epoch 49/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5729 - mae: 9.5729\n",
      "Epoch 50/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8185 - mae: 13.8185\n",
      "Epoch 51/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.5958 - mae: 11.5958\n",
      "Epoch 52/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.5538 - mae: 30.5538\n",
      "Epoch 53/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.3541 - mae: 14.3541\n",
      "Epoch 54/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.9713 - mae: 23.9713\n",
      "Epoch 55/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1938 - mae: 23.1938\n",
      "Epoch 56/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.8837 - mae: 10.8837\n",
      "Epoch 57/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7445 - mae: 12.7445\n",
      "Epoch 58/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5995 - mae: 9.5995\n",
      "Epoch 59/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5172 - mae: 12.5172\n",
      "Epoch 60/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.3200 - mae: 12.3200\n",
      "Epoch 61/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.4604 - mae: 17.4604\n",
      "Epoch 62/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6052 - mae: 10.6052\n",
      "Epoch 63/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4893 - mae: 10.4893\n",
      "Epoch 64/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.8450 - mae: 24.8450\n",
      "Epoch 65/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6761 - mae: 10.6761\n",
      "Epoch 66/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 21.7809 - mae: 21.7809\n",
      "Epoch 67/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7136 - mae: 10.7136\n",
      "Epoch 68/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.6397 - mae: 10.6397\n",
      "Epoch 69/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.6914 - mae: 22.6914\n",
      "Epoch 70/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3316 - mae: 9.3316\n",
      "Epoch 71/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4355 - mae: 15.4355\n",
      "Epoch 72/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.7437 - mae: 6.7437\n",
      "Epoch 73/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.6891 - mae: 11.6891\n",
      "Epoch 74/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.0400 - mae: 24.0400\n",
      "Epoch 75/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 9.5896 - mae: 9.5896\n",
      "Epoch 76/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4371 - mae: 12.4371\n",
      "Epoch 77/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.6488 - mae: 16.6488\n",
      "Epoch 78/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0614 - mae: 9.0614\n",
      "Epoch 79/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.9675 - mae: 23.9675\n",
      "Epoch 80/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.7463 - mae: 26.7463\n",
      "Epoch 81/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.6714 - mae: 11.6714\n",
      "Epoch 82/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.0228 - mae: 12.0228\n",
      "Epoch 83/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4218 - mae: 17.4218\n",
      "Epoch 84/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.2629 - mae: 7.2629\n",
      "Epoch 85/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.9650 - mae: 14.9650\n",
      "Epoch 86/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2862 - mae: 15.2862\n",
      "Epoch 87/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.1086 - mae: 19.1086\n",
      "Epoch 88/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.8228 - mae: 29.8228\n",
      "Epoch 89/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.1742 - mae: 10.1742\n",
      "Epoch 90/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.5240 - mae: 21.5240\n",
      "Epoch 91/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 92/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.3977 - mae: 18.3977\n",
      "Epoch 93/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 94/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.7380 - mae: 17.7380\n",
      "Epoch 95/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.1144 - mae: 11.1144\n",
      "Epoch 96/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 19.4346 - mae: 19.4346\n",
      "Epoch 97/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1593 - mae: 12.1593\n",
      "Epoch 98/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5653 - mae: 11.5653\n",
      "Epoch 99/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8827 - mae: 13.8827\n",
      "Epoch 100/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.2277 - mae: 20.2277\n",
      "Epoch 101/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4479 - mae: 11.4479\n",
      "Epoch 102/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.4842 - mae: 17.4842\n",
      "Epoch 103/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0217 - mae: 7.0217\n",
      "Epoch 104/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.5789 - mae: 23.5789\n",
      "Epoch 105/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 16.8932 - mae: 16.8932\n",
      "Epoch 106/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2954 - mae: 9.2954\n",
      "Epoch 107/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.3749 - mae: 25.3749\n",
      "Epoch 108/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.4621 - mae: 13.4621\n",
      "Epoch 109/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.5238 - mae: 9.5238\n",
      "Epoch 110/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 111/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 12.9674 - mae: 12.967 - 0s 4ms/step - loss: 14.5987 - mae: 14.5987\n",
      "Epoch 112/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5670 - mae: 9.5670\n",
      "Epoch 113/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.8092 - mae: 17.8092\n",
      "Epoch 114/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.1782 - mae: 17.1782\n",
      "Epoch 115/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.1182 - mae: 11.1182\n",
      "Epoch 116/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.3071 - mae: 23.3071\n",
      "Epoch 117/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6144 - mae: 9.6144\n",
      "Epoch 118/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.6899 - mae: 10.6899\n",
      "Epoch 119/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0355 - mae: 8.0355\n",
      "Epoch 120/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 29.6859 - mae: 29.6859\n",
      "Epoch 121/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0714 - mae: 8.0714\n",
      "Epoch 122/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.3086 - mae: 28.3086\n",
      "Epoch 123/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 32.9014 - mae: 32.9014\n",
      "Epoch 124/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 19.6291 - mae: 19.6291\n",
      "Epoch 125/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0095 - mae: 7.0095\n",
      "Epoch 126/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.8056 - mae: 21.8056\n",
      "Epoch 127/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9812 - mae: 7.9812\n",
      "Epoch 128/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.0585 - mae: 21.0585\n",
      "Epoch 129/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.0107 - mae: 9.0107\n",
      "Epoch 130/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.0502 - mae: 24.0502\n",
      "Epoch 131/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7537 - mae: 9.7537\n",
      "Epoch 132/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3052 - mae: 18.3052\n",
      "Epoch 133/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5833 - mae: 7.5833\n",
      "Epoch 134/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.5755 - mae: 18.5755\n",
      "Epoch 135/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5360 - mae: 10.5360\n",
      "Epoch 136/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.2694 - mae: 18.2694\n",
      "Epoch 137/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.1658 - mae: 23.1658\n",
      "Epoch 138/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1362 - mae: 9.1362\n",
      "Epoch 139/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9181 - mae: 8.9181\n",
      "Epoch 140/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.4732 - mae: 16.4732\n",
      "Epoch 141/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4208 - mae: 8.4208\n",
      "Epoch 142/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.9540 - mae: 36.9540\n",
      "Epoch 143/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 26.7157 - mae: 26.715 - 0s 5ms/step - loss: 25.5820 - mae: 25.5820\n",
      "Epoch 144/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5392 - mae: 9.5392\n",
      "Epoch 145/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.6058 - mae: 26.6058\n",
      "Epoch 146/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7248 - mae: 8.7248\n",
      "Epoch 147/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 15.6172 - mae: 15.6172\n",
      "Epoch 148/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 18.3065 - mae: 18.3065\n",
      "Epoch 149/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1994 - mae: 8.1994\n",
      "Epoch 150/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.4964 - mae: 7.4964\n",
      "Epoch 151/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.3374 - mae: 18.3374\n",
      "Epoch 152/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.2895 - mae: 10.2895\n",
      "Epoch 153/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 29.6425 - mae: 29.6425\n",
      "Epoch 154/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5555 - mae: 10.5555\n",
      "Epoch 155/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.4537 - mae: 15.4537\n",
      "Epoch 156/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.0174 - mae: 17.0174\n",
      "Epoch 157/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.8218 - mae: 32.8218\n",
      "Epoch 158/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7038 - mae: 10.7038\n",
      "Epoch 159/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9054 - mae: 8.9054\n",
      "Epoch 160/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.1321 - mae: 22.1321\n",
      "Epoch 161/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7113 - mae: 11.7113\n",
      "Epoch 162/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.5734 - mae: 21.5734\n",
      "Epoch 163/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 19.2485 - mae: 19.2485\n",
      "Epoch 164/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0156 - mae: 11.0156\n",
      "Epoch 165/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6187 - mae: 9.6187\n",
      "Epoch 166/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 24.7840 - mae: 24.784 - 0s 5ms/step - loss: 21.5908 - mae: 21.5908\n",
      "Epoch 167/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.2851 - mae: 26.2851\n",
      "Epoch 168/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.8525 - mae: 9.8525\n",
      "Epoch 169/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.5631 - mae: 22.5631\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 7ms/step - loss: 10.1499 - mae: 10.1499\n",
      "Epoch 171/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0464 - mae: 18.0464\n",
      "Epoch 172/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.8377 - mae: 28.8377\n",
      "Epoch 173/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.5279 - mae: 16.5279\n",
      "Epoch 174/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.2115 - mae: 11.2115\n",
      "Epoch 175/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 27.5839 - mae: 27.5839\n",
      "Epoch 176/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.2680 - mae: 8.2680\n",
      "Epoch 177/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 9.2580 - mae: 9.2580\n",
      "Epoch 178/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.1440 - mae: 18.1440\n",
      "Epoch 179/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5995 - mae: 10.5995\n",
      "Epoch 180/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8992 - mae: 7.8992\n",
      "Epoch 181/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.4015 - mae: 17.4015\n",
      "Epoch 182/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0089 - mae: 11.0089\n",
      "Epoch 183/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7027 - mae: 11.7027\n",
      "Epoch 184/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.4062 - mae: 30.4062\n",
      "Epoch 185/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5557 - mae: 7.5557\n",
      "Epoch 186/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9905 - mae: 15.9905\n",
      "Epoch 187/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5579 - mae: 8.5579\n",
      "Epoch 188/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 28.7339 - mae: 28.7339\n",
      "Epoch 189/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1689 - mae: 13.1689\n",
      "Epoch 190/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.3101 - mae: 18.3101\n",
      "Epoch 191/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 13.7376 - mae: 13.7376\n",
      "Epoch 192/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7104 - mae: 13.7104\n",
      "Epoch 193/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.5842 - mae: 28.5842\n",
      "Epoch 194/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0707 - mae: 7.0707\n",
      "Epoch 195/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0550 - mae: 7.0550\n",
      "Epoch 196/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.0067 - mae: 22.0067\n",
      "Epoch 197/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8443 - mae: 20.8443\n",
      "Epoch 198/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.4713 - mae: 12.4713\n",
      "Epoch 199/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.9099 - mae: 17.9099\n",
      "Epoch 200/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7493 - mae: 13.7493\n",
      "Epoch 201/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.4687 - mae: 5.4687\n",
      "Epoch 202/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7005 - mae: 13.7005\n",
      "Epoch 203/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4142 - mae: 9.4142\n",
      "Epoch 204/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.9796 - mae: 20.9796\n",
      "Epoch 205/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5470 - mae: 9.5470\n",
      "Epoch 206/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.7256 - mae: 11.7256\n",
      "Epoch 207/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.3772 - mae: 14.3772\n",
      "Epoch 208/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8579 - mae: 14.8579\n",
      "Epoch 209/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.9706 - mae: 14.9706\n",
      "Epoch 210/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.8998 - mae: 17.8998\n",
      "Epoch 211/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8327 - mae: 9.8327\n",
      "Epoch 212/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.3352 - mae: 18.3352\n",
      "Epoch 213/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0383 - mae: 15.0383\n",
      "Epoch 214/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5874 - mae: 14.5874\n",
      "Epoch 215/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.3015 - mae: 23.3015\n",
      "Epoch 216/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3613 - mae: 13.3613\n",
      "Epoch 217/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8517 - mae: 9.8517\n",
      "Epoch 218/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.5451 - mae: 12.5451\n",
      "Epoch 219/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.9472 - mae: 4.9472\n",
      "Epoch 220/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1130 - mae: 7.1130\n",
      "Epoch 221/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 35.4567 - mae: 35.4567\n",
      "Epoch 222/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 34.8634 - mae: 34.8634\n",
      "Epoch 223/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9846 - mae: 7.9846\n",
      "Epoch 224/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.7004 - mae: 14.7004\n",
      "Epoch 225/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.7196 - mae: 16.7196\n",
      "Epoch 226/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.9329 - mae: 15.9329\n",
      "Epoch 227/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.1644 - mae: 16.1644\n",
      "Epoch 228/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.9324 - mae: 13.9324\n",
      "Epoch 229/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 18.0504 - mae: 18.0504\n",
      "Epoch 230/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.6120 - mae: 15.6120\n",
      "Epoch 231/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.2041 - mae: 21.2041\n",
      "Epoch 232/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.2732 - mae: 25.2732\n",
      "Epoch 233/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3176 - mae: 16.3176\n",
      "Epoch 234/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2729 - mae: 7.2729\n",
      "Epoch 235/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.9688 - mae: 16.9688\n",
      "Epoch 236/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1225 - mae: 7.1225\n",
      "Epoch 237/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2058 - mae: 9.2058\n",
      "Epoch 238/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 8.0961 - mae: 8.0961\n",
      "Epoch 239/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.0538 - mae: 17.0538\n",
      "Epoch 240/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.8627 - mae: 8.8627\n",
      "Epoch 241/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1711 - mae: 13.1711\n",
      "Epoch 242/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7886 - mae: 8.7886\n",
      "Epoch 243/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 18.8161 - mae: 18.8161\n",
      "Epoch 244/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0531 - mae: 14.0531\n",
      "Epoch 245/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6831 - mae: 14.6831\n",
      "Epoch 246/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.8045 - mae: 15.8045\n",
      "Epoch 247/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.6810 - mae: 17.6810\n",
      "Epoch 248/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.2367 - mae: 13.2367\n",
      "Epoch 249/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.5070 - mae: 14.5070\n",
      "Epoch 250/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.2322 - mae: 23.2322\n",
      "Epoch 251/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3009 - mae: 9.3009\n",
      "Epoch 252/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 36.6568 - mae: 36.6568\n",
      "Epoch 253/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.8205 - mae: 21.8205\n",
      "Epoch 254/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2792 - mae: 7.2792\n",
      "Epoch 255/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.7126 - mae: 24.7126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 256/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4220 - mae: 12.4220\n",
      "Epoch 257/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5823 - mae: 10.5823\n",
      "Epoch 258/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.4883 - mae: 14.4883\n",
      "Epoch 259/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.6132 - mae: 8.6132\n",
      "Epoch 260/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 43.0580 - mae: 43.0580\n",
      "Epoch 261/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 18.4611 - mae: 18.4611\n",
      "Epoch 262/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 5.1868 - mae: 5.186 - 0s 4ms/step - loss: 6.8820 - mae: 6.8820\n",
      "Epoch 263/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7211 - mae: 13.7211\n",
      "Epoch 264/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.0154 - mae: 21.0154\n",
      "Epoch 265/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.3730 - mae: 19.3730\n",
      "Epoch 266/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4735 - mae: 11.4735\n",
      "Epoch 267/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.5302 - mae: 7.5302\n",
      "Epoch 268/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.6453 - mae: 21.6453\n",
      "Epoch 269/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 33.1784 - mae: 33.1784\n",
      "Epoch 270/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0833 - mae: 10.0833\n",
      "Epoch 271/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.1012 - mae: 12.1012\n",
      "Epoch 272/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 26.1372 - mae: 26.1372\n",
      "Epoch 273/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.1751 - mae: 12.1751\n",
      "Epoch 274/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.3272 - mae: 13.3272\n",
      "Epoch 275/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 29.3775 - mae: 29.3775\n",
      "Epoch 276/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.3329 - mae: 7.3329\n",
      "Epoch 277/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 31.1362 - mae: 31.1362\n",
      "Epoch 278/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.3016 - mae: 12.3016\n",
      "Epoch 279/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.4103 - mae: 16.4103\n",
      "Epoch 280/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9118 - mae: 21.9118\n",
      "Epoch 281/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 22.1500 - mae: 22.1500\n",
      "Epoch 282/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.7429 - mae: 7.7429\n",
      "Epoch 283/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 8.1429 - mae: 8.1429\n",
      "Epoch 284/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 24.9434 - mae: 24.9434\n",
      "Epoch 285/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.6958 - mae: 13.6958\n",
      "Epoch 286/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.8926 - mae: 6.8926\n",
      "Epoch 287/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.5352 - mae: 24.5352\n",
      "Epoch 288/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.1721 - mae: 20.1721\n",
      "Epoch 289/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9658 - mae: 11.9658\n",
      "Epoch 290/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 17.9305 - mae: 17.930 - 0s 4ms/step - loss: 16.5391 - mae: 16.5391\n",
      "Epoch 291/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.8017 - mae: 16.8017\n",
      "Epoch 292/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 293/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2711 - mae: 15.2711\n",
      "Epoch 294/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 22.7179 - mae: 22.7179\n",
      "Epoch 295/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 17.9234 - mae: 17.9234\n",
      "Epoch 296/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1742 - mae: 6.1742\n",
      "Epoch 297/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.9440 - mae: 10.9440\n",
      "Epoch 298/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.1530 - mae: 23.1530\n",
      "Epoch 299/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 17.7331 - mae: 17.7331\n",
      "Epoch 300/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.9824 - mae: 6.9824\n",
      "Epoch 301/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.1857 - mae: 25.1857\n",
      "Epoch 302/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9025 - mae: 8.9025\n",
      "Epoch 303/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.7668 - mae: 17.7668\n",
      "Epoch 304/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.0002 - mae: 11.0002\n",
      "Epoch 305/500\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 12.9191 - mae: 12.9191\n",
      "Epoch 306/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.4033 - mae: 8.4033\n",
      "Epoch 307/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 13.6094 - mae: 13.6094\n",
      "Epoch 308/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4404 - mae: 7.4404\n",
      "Epoch 309/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 9.4642 - mae: 9.4642\n",
      "Epoch 310/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.7099 - mae: 10.7099\n",
      "Epoch 311/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2814 - mae: 13.2814\n",
      "Epoch 312/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.9763 - mae: 29.9763\n",
      "Epoch 313/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.6304 - mae: 7.6304\n",
      "Epoch 314/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.9106 - mae: 9.9106\n",
      "Epoch 315/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.7669 - mae: 23.7669\n",
      "Epoch 316/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3936 - mae: 16.3936\n",
      "Epoch 317/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.0758 - mae: 21.0758\n",
      "Epoch 318/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.9367 - mae: 7.9367\n",
      "Epoch 319/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 17.9731 - mae: 17.9731\n",
      "Epoch 320/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.2375 - mae: 10.2375\n",
      "Epoch 321/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.3338 - mae: 8.3338\n",
      "Epoch 322/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.0621 - mae: 5.0621\n",
      "Epoch 323/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.5109 - mae: 23.5109\n",
      "Epoch 324/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 6.0865 - mae: 6.086 - 0s 4ms/step - loss: 6.8309 - mae: 6.8309\n",
      "Epoch 325/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3863 - mae: 16.3863\n",
      "Epoch 326/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5019 - mae: 7.5019\n",
      "Epoch 327/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.0573 - mae: 20.0573\n",
      "Epoch 328/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.7661 - mae: 13.7661\n",
      "Epoch 329/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.8282 - mae: 16.8282\n",
      "Epoch 330/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.0514 - mae: 7.0514\n",
      "Epoch 331/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 21.4846 - mae: 21.4846\n",
      "Epoch 332/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.2880 - mae: 12.2880\n",
      "Epoch 333/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.8117 - mae: 11.8117\n",
      "Epoch 334/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 8.3600 - mae: 8.3600\n",
      "Epoch 335/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 12.4833 - mae: 12.4833\n",
      "Epoch 336/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 32.2171 - mae: 32.2171\n",
      "Epoch 337/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.4477 - mae: 10.4477\n",
      "Epoch 338/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 19.6832 - mae: 19.6832\n",
      "Epoch 339/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 35.0762 - mae: 35.0762\n",
      "Epoch 340/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.4192 - mae: 10.4192\n",
      "Epoch 341/500\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 9.7625 - mae: 9.7625\n",
      "Epoch 342/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9500 - mae: 11.9500\n",
      "Epoch 343/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3943 - mae: 9.3943\n",
      "Epoch 344/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.6071 - mae: 5.6071\n",
      "Epoch 345/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 37.4876 - mae: 37.4876\n",
      "Epoch 346/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.8830 - mae: 16.8830\n",
      "Epoch 347/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8748 - mae: 12.8748\n",
      "Epoch 348/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.1960 - mae: 8.1960\n",
      "Epoch 349/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.5568 - mae: 13.5568\n",
      "Epoch 350/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4354 - mae: 15.4354\n",
      "Epoch 351/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.9626 - mae: 32.9626\n",
      "Epoch 352/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.2040 - mae: 14.2040\n",
      "Epoch 353/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.9196 - mae: 15.9196\n",
      "Epoch 354/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.0878 - mae: 19.0878\n",
      "Epoch 355/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 34.1178 - mae: 34.1178\n",
      "Epoch 356/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.6798 - mae: 7.6798\n",
      "Epoch 357/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 25.2287 - mae: 25.2287\n",
      "Epoch 358/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.6759 - mae: 22.6759\n",
      "Epoch 359/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.8765 - mae: 8.8765\n",
      "Epoch 360/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.4709 - mae: 21.4709\n",
      "Epoch 361/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 20.6073 - mae: 20.6073\n",
      "Epoch 362/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.0611 - mae: 7.0611\n",
      "Epoch 363/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.8117 - mae: 25.8117\n",
      "Epoch 364/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 32.2247 - mae: 32.2247\n",
      "Epoch 365/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0205 - mae: 10.0205\n",
      "Epoch 366/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6722 - mae: 9.6722\n",
      "Epoch 367/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.4171 - mae: 30.4171\n",
      "Epoch 368/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.5020 - mae: 10.5020\n",
      "Epoch 369/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9909 - mae: 14.9909\n",
      "Epoch 370/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.6580 - mae: 14.6580\n",
      "Epoch 371/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.3672 - mae: 23.3672\n",
      "Epoch 372/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.1025 - mae: 13.1025\n",
      "Epoch 373/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.2586 - mae: 9.2586\n",
      "Epoch 374/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.6648 - mae: 9.6648\n",
      "Epoch 375/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.0041 - mae: 13.0041\n",
      "Epoch 376/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.8863 - mae: 14.8863\n",
      "Epoch 377/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 14.7932 - mae: 14.7932\n",
      "Epoch 378/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.2751 - mae: 16.2751\n",
      "Epoch 379/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.8307 - mae: 20.8307\n",
      "Epoch 380/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 33.5318 - mae: 33.5318\n",
      "Epoch 381/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2166 - mae: 8.2166\n",
      "Epoch 382/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 13.0960 - mae: 13.0960\n",
      "Epoch 383/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3999 - mae: 8.3999\n",
      "Epoch 384/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1283 - mae: 7.1283\n",
      "Epoch 385/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9390 - mae: 10.9390\n",
      "Epoch 386/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 19.7654 - mae: 19.7654\n",
      "Epoch 387/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.8625 - mae: 24.8625\n",
      "Epoch 388/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7422 - mae: 8.7422\n",
      "Epoch 389/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 5.9488 - mae: 5.9488\n",
      "Epoch 390/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 24.4401 - mae: 24.4401\n",
      "Epoch 391/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 5.9771 - mae: 5.9771\n",
      "Epoch 392/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3250 - mae: 16.3250\n",
      "Epoch 393/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.0917 - mae: 6.0917\n",
      "Epoch 394/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0963 - mae: 11.0963\n",
      "Epoch 395/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9601 - mae: 14.9601\n",
      "Epoch 396/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.6462 - mae: 7.6462\n",
      "Epoch 397/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7654 - mae: 8.7654\n",
      "Epoch 398/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 14.5992 - mae: 14.5992\n",
      "Epoch 399/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3166 - mae: 11.3166\n",
      "Epoch 400/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 21.9080 - mae: 21.9080\n",
      "Epoch 401/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.8654 - mae: 14.8654\n",
      "Epoch 402/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.4970 - mae: 8.4970\n",
      "Epoch 403/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.3957 - mae: 10.3957\n",
      "Epoch 404/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.2556 - mae: 10.2556\n",
      "Epoch 405/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 6.3392 - mae: 6.3392\n",
      "Epoch 406/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4602 - mae: 17.4602\n",
      "Epoch 407/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.4627 - mae: 11.4627\n",
      "Epoch 408/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.7294 - mae: 20.7294\n",
      "Epoch 409/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 31.3339 - mae: 31.3339\n",
      "Epoch 410/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2542 - mae: 9.2542\n",
      "Epoch 411/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 14.8621 - mae: 14.8621\n",
      "Epoch 412/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 21.7182 - mae: 21.7182\n",
      "Epoch 413/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6615 - mae: 12.6615\n",
      "Epoch 414/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.0687 - mae: 6.0687\n",
      "Epoch 415/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.2201 - mae: 13.2201\n",
      "Epoch 416/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 27.4244 - mae: 27.4244\n",
      "Epoch 417/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.6407 - mae: 10.6407\n",
      "Epoch 418/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8230 - mae: 12.8230\n",
      "Epoch 419/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.8836 - mae: 15.8836\n",
      "Epoch 420/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 24.7510 - mae: 24.7510\n",
      "Epoch 421/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.3753 - mae: 17.3753\n",
      "Epoch 422/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8241 - mae: 7.8241\n",
      "Epoch 423/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 25.3789 - mae: 25.3789\n",
      "Epoch 424/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.1031 - mae: 15.1031\n",
      "Epoch 425/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.1643 - mae: 7.1643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 20.3318 - mae: 20.3318\n",
      "Epoch 427/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3283 - mae: 6.3283\n",
      "Epoch 428/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.9962 - mae: 12.9962\n",
      "Epoch 429/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7869 - mae: 10.7869\n",
      "Epoch 430/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.4007 - mae: 11.4007\n",
      "Epoch 431/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.6153 - mae: 10.6153\n",
      "Epoch 432/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.4582 - mae: 11.4582\n",
      "Epoch 433/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.3851 - mae: 11.3851\n",
      "Epoch 434/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.3986 - mae: 30.3986\n",
      "Epoch 435/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5052 - mae: 10.5052\n",
      "Epoch 436/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.8810 - mae: 28.8810\n",
      "Epoch 437/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.5916 - mae: 8.5916\n",
      "Epoch 438/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7378 - mae: 12.7378\n",
      "Epoch 439/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 33.6754 - mae: 33.6754\n",
      "Epoch 440/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.0962 - mae: 15.0962\n",
      "Epoch 441/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4813 - mae: 17.4813\n",
      "Epoch 442/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 22.3049 - mae: 22.3049\n",
      "Epoch 443/500\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 23.5841 - mae: 23.5841\n",
      "Epoch 444/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.0008 - mae: 11.0008\n",
      "Epoch 445/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.9175 - mae: 14.9175\n",
      "Epoch 446/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 17.9979 - mae: 17.9979\n",
      "Epoch 447/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 5.4482 - mae: 5.4482\n",
      "Epoch 448/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.0527 - mae: 10.0527\n",
      "Epoch 449/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0052 - mae: 14.0052\n",
      "Epoch 450/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.7782 - mae: 16.7782\n",
      "Epoch 451/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.2937 - mae: 14.2937\n",
      "Epoch 452/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.6192 - mae: 30.6192\n",
      "Epoch 453/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.6541 - mae: 7.6541\n",
      "Epoch 454/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 28.1428 - mae: 28.1428\n",
      "Epoch 455/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0017 - mae: 8.0017\n",
      "Epoch 456/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 10.3933 - mae: 10.3933\n",
      "Epoch 457/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0242 - mae: 15.0242\n",
      "Epoch 458/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 16.5653 - mae: 16.5653\n",
      "Epoch 459/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 26.8566 - mae: 26.8566\n",
      "Epoch 460/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.4852 - mae: 12.4852\n",
      "Epoch 461/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.4784 - mae: 12.4784\n",
      "Epoch 462/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3186 - mae: 13.3186\n",
      "Epoch 463/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 29.5524 - mae: 29.5524\n",
      "Epoch 464/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 3.4664 - mae: 3.4664\n",
      "Epoch 465/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 15.2136 - mae: 15.2136\n",
      "Epoch 466/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.8327 - mae: 20.8327\n",
      "Epoch 467/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 30.5108 - mae: 30.5108\n",
      "Epoch 468/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.0598 - mae: 11.0598\n",
      "Epoch 469/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.8372 - mae: 12.8372\n",
      "Epoch 470/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 3.2398 - mae: 3.2398\n",
      "Epoch 471/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 16.6964 - mae: 16.6964\n",
      "Epoch 472/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3883 - mae: 13.3883\n",
      "Epoch 473/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.2771 - mae: 15.2771\n",
      "Epoch 474/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7448 - mae: 11.7448\n",
      "Epoch 475/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.4113 - mae: 16.4113\n",
      "Epoch 476/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.8785 - mae: 13.8785\n",
      "Epoch 477/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 30.6702 - mae: 30.6702\n",
      "Epoch 478/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5880 - mae: 8.5880\n",
      "Epoch 479/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.7384 - mae: 10.7384\n",
      "Epoch 480/500\n",
      "2/2 [==============================] - ETA: 0s - loss: 21.2679 - mae: 21.267 - 0s 9ms/step - loss: 17.9051 - mae: 17.9051\n",
      "Epoch 481/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 15.8094 - mae: 15.8094\n",
      "Epoch 482/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 21.3054 - mae: 21.3054\n",
      "Epoch 483/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 25.3845 - mae: 25.3845\n",
      "Epoch 484/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.9816 - mae: 23.9816\n",
      "Epoch 485/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 5.7734 - mae: 5.7734\n",
      "Epoch 486/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 20.0011 - mae: 20.0011\n",
      "Epoch 487/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.0419 - mae: 14.0419\n",
      "Epoch 488/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 30.6088 - mae: 30.6088\n",
      "Epoch 489/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.9409 - mae: 11.9409\n",
      "Epoch 490/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.7352 - mae: 12.7352\n",
      "Epoch 491/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 23.6139 - mae: 23.6139\n",
      "Epoch 492/500\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 20.5365 - mae: 20.5365\n",
      "Epoch 493/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 4.9942 - mae: 4.9942\n",
      "Epoch 494/500\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.7987 - mae: 12.7987\n",
      "Epoch 495/500\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 13.3772 - mae: 13.3772\n",
      "Epoch 496/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 12.6727 - mae: 12.6727\n",
      "Epoch 497/500\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 17.6192 - mae: 17.6192\n",
      "Epoch 498/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.5629 - mae: 23.5629\n",
      "Epoch 499/500\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3755 - mae: 9.3755\n",
      "Epoch 500/500\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 14.6316 - mae: 14.6316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f3228db80>"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model 3 --> 2 layers trained for 500 epochs --> trained for longer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_3 = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10),\n",
    "            tf.keras.layers.Dense(1)])    # dense layer with 1 hidden unit --> thT WILL BE THE OUTPUT layer\n",
    "\n",
    "model_3.compile(loss = tf.keras.losses.mae,\n",
    "                optimizer = tf.keras.optimizers.SGD(),\n",
    "                metrics = [\"mae\"])\n",
    "\n",
    "model_3.fit(X_train, y_train, epochs = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_3 = model_3.predict(X_test)\n",
    "plot_predictions(predictions = y_pred_3)\n",
    "\n",
    "# think that model is trained for too long\n",
    "# this is overfitting --> model has learnt the traininig data very well and does'nt generalize very well at all to data it has'nt sen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=68.713615>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=4808.0273>)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae_3 = mae(y_test, y_pred_3)\n",
    "mse_3 = mse(y_test, y_pred_3)\n",
    "mae_3, mse_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with small experiments ( small models) -> make sure they work and then increase the scale when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>tf.Tensor(18.745327, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(353.57336, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>tf.Tensor(3.19694, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(13.070127, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>tf.Tensor(68.713615, shape=(), dtype=float32)</td>\n",
       "      <td>tf.Tensor(4808.0273, shape=(), dtype=float32)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model                                            mae  \\\n",
       "0  model_1  tf.Tensor(18.745327, shape=(), dtype=float32)   \n",
       "1  model_2    tf.Tensor(3.19694, shape=(), dtype=float32)   \n",
       "2  model_3  tf.Tensor(68.713615, shape=(), dtype=float32)   \n",
       "\n",
       "                                             mse  \n",
       "0  tf.Tensor(353.57336, shape=(), dtype=float32)  \n",
       "1  tf.Tensor(13.070127, shape=(), dtype=float32)  \n",
       "2  tf.Tensor(4808.0273, shape=(), dtype=float32)  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing the results of our experiments\n",
    "# compare models results using  pandas data frame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# set model_results as list of lists\n",
    "model_results = [[\"model_1\", mae_1, mse_1],\n",
    "                 [\"model_2\", mae_2, mse_2],\n",
    "                 [\"model_3\", mae_3, mse_3]]\n",
    "\n",
    "# creating data frame\n",
    "all_results = pd.DataFrame(model_results, columns = [\"model\", \"mae\", \"mse\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>model_1</td>\n",
       "      <td>18.745327</td>\n",
       "      <td>353.573364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model_2</td>\n",
       "      <td>3.196940</td>\n",
       "      <td>13.070127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>model_3</td>\n",
       "      <td>68.713615</td>\n",
       "      <td>4808.027344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model        mae          mse\n",
       "0  model_1  18.745327   353.573364\n",
       "1  model_2   3.196940    13.070127\n",
       "2  model_3  68.713615  4808.027344"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# getting just the numpy values of all of these\n",
    "\n",
    "\n",
    "# comparing the results of our experiments\n",
    "# compare models results using  pandas data frame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# set model_results as list of lists\n",
    "model_results = [[\"model_1\", mae_1.numpy(), mse_1.numpy()],\n",
    "                 [\"model_2\", mae_2.numpy(), mse_2.numpy()],\n",
    "                 [\"model_3\", mae_3.numpy(), mse_3.numpy()]]\n",
    "\n",
    "# creating data frame\n",
    "all_results = pd.DataFrame(model_results, columns = [\"model\", \"mae\", \"mse\"])\n",
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    " # can see the model_2 performs best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    " # main goal should be to minimize the time between your experiments. The more experiments we do --> more things we can see\n",
    " # what does not work --> will get loser to see what works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# above output shows that it has 2 layers -->\n",
    "# one with 10 hiddden neurons\n",
    "# output layer with 1 hidden neuron\n",
    "# it was fit for 100 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tracking experiments, track results of experiments\n",
    "# as we build more models --> Tensorboard - a component of the Tensorflow library to help track modelling experiments\n",
    "# weights and biases -> a tool for tracking all kinds of ml experiments , can be used with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving our models, exporting it somewhere else\n",
    "# saving our model allows us to use them outside jupyter notebook or wherever they were trained, can be used in a web application or a mobile app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a model --> 2 formats --> SavedModel format,  HDF5 extension       \n",
    "# two main formats we can save our model's to --> SavedModel format, HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: learned_to_save_model\\assets\n"
     ]
    }
   ],
   "source": [
    "# save modl using SavedModel format\n",
    "model_2.save(\"learned_to_save_model\")  # we get a folder here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# .pb format is called a protoby file\n",
    "# to make sure that our model saved correctly is by loading it back in and checking in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model in HDF5 format --> hierarchical data format\n",
    "model_2.save(\"learned_to_save_model_HDF5.h5\")  # we get a single file here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# can check by loading the model again and test it\n",
    "\n",
    "# loading the saved model -> can us the same method for both formats\n",
    "loaded_SavedModel_format = tf.keras.models.load_model(\"learned_to_save_model\")\n",
    "loaded_SavedModel_format.summary()  # should be same as model_2 above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# comparing model_2 predictions with SavedModel format model predictions\n",
    "model_2_pred = model_2.predict(X_test)\n",
    "loaded_SavedModel_format_pred = loaded_SavedModel_format.predict(X_test)\n",
    "model_2_pred == loaded_SavedModel_format_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean absolute error of each\n",
    "mae(y_true = y_test, y_pred = model_2_pred) == mae(y_true = y_test, y_pred = loaded_SavedModel_format_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_pred.squeeze() == loaded_SavedModel_format_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 70.552185,  75.13991 ,  79.72764 ,  84.315346,  88.90308 ,\n",
       "        93.49081 ,  98.07852 , 102.666245, 107.253975, 111.84169 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_SavedModel_format_pred.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model using  the .h5 format\n",
    "loaded_h5_model = tf.keras.models.load_model(\"F:\\mini_project\\Character-Recognition-Using-DL\\learning_concepts_practice\\learned_to_save_model_HDF5.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_h5_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_42 (Dense)             (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "dense_43 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check predictions match \n",
    "model_2_pred = model_2.predict(X_test)\n",
    "loaded_h5_model_pred =  loaded_h5_model.predict(X_test)\n",
    "model_2_pred == loaded_h5_model_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download a model or any other file from google colab\n",
    "# for downloading from google colab --> go to files tab and right click on that file and click download, \n",
    "# use code to download\n",
    "# can save it to google drive by connecting drive and copyig it there \n",
    "\n",
    "# to downlaod a file -->\n",
    "# from google.colab import files\n",
    "# files.download(\"file path\")\n",
    "\n",
    "# using google drive\n",
    "# save file from google colab to google drive --> reqquires mounting google drive\n",
    "# !cp /content/learned_HDF5_format.h5 /content/drive/MyDrive/folder_name\n",
    "\n",
    "# to see\n",
    "# !ls /content/drive/MyDrivefolder_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "         -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "         -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "          32,   36,   40,   44,   48,   52,   56])>,\n",
       " <tf.Tensor: shape=(40,), dtype=int32, numpy=\n",
       " array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "        -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "         14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "         66])>)"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a larger example\n",
    "\n",
    "X_train, y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network regression model\n",
    "# import straight \n",
    "# import required libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt ## fpr plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the insurance dataset\n",
    "# insurance = pd.read_csv(\"can directly paste link here\")\n",
    "insurance = pd.read_csv(\"C:\\\\Users\\\\dell\\\\Downloads\\\\insurance.csv\")\n",
    "insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "# charges is the amount --> medical insurance of someone based on thir age, sex, bmi, children, smoker, region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to write code to learn relationships bet these features and the target variable --> charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here dependent variable --> charges,  independent variables --> remaining varibales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0       yes\n",
       " 1        no\n",
       " 2        no\n",
       " 3        no\n",
       " 4        no\n",
       "        ... \n",
       " 1333     no\n",
       " 1334     no\n",
       " 1335     no\n",
       " 1336     no\n",
       " 1337    yes\n",
       " Name: smoker, Length: 1338, dtype: object,\n",
       " 0       19\n",
       " 1       18\n",
       " 2       28\n",
       " 3       33\n",
       " 4       32\n",
       "         ..\n",
       " 1333    50\n",
       " 1334    18\n",
       " 1335    18\n",
       " 1336    21\n",
       " 1337    61\n",
       " Name: age, Length: 1338, dtype: int64)"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insurance[\"smoker\"], insurance[\"age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some columns are numerical, some are not numerical\n",
    "# non-numerical model --> have to turn them into numbers --> numerical encoding\n",
    "# one-hot encoding --> simplest methods to turn categorical variables into numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children      charges  sex_female  sex_male  smoker_no  \\\n",
       "0   19  27.900         0  16884.92400           1         0          0   \n",
       "1   18  33.770         1   1725.55230           0         1          1   \n",
       "2   28  33.000         3   4449.46200           0         1          1   \n",
       "3   33  22.705         0  21984.47061           0         1          1   \n",
       "4   32  28.880         0   3866.85520           0         1          1   \n",
       "\n",
       "   smoker_yes  region_northeast  region_northwest  region_southeast  \\\n",
       "0           1                 0                 0                 0   \n",
       "1           0                 0                 0                 1   \n",
       "2           0                 0                 0                 1   \n",
       "3           0                 0                 1                 0   \n",
       "4           0                 0                 1                 0   \n",
       "\n",
       "   region_southwest  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding on our dataframe\n",
    "insurance_one_hot = pd.get_dummies(insurance)  # categorical columns are turned into numerical varibles\n",
    "insurance_one_hot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create X and y values ( features and labels)\n",
    "\n",
    "X = insurance_one_hot.drop(\"charges\", axis = 1) # drop charges on the first axis\n",
    "y = insurance_one_hot[\"charges\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0   19  27.900         0           1         0          0           1   \n",
       "1   18  33.770         1           0         1          1           0   \n",
       "2   28  33.000         3           0         1          1           0   \n",
       "3   33  22.705         0           0         1          1           0   \n",
       "4   32  28.880         0           0         1          1           0   \n",
       "\n",
       "   region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                 0                 0                 0                 1  \n",
       "1                 0                 0                 1                 0  \n",
       "2                 0                 0                 1                 0  \n",
       "3                 0                 1                 0                 0  \n",
       "4                 0                 1                 0                 0  "
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view X\n",
    "X.head() # first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16884.92400\n",
       "1     1725.55230\n",
       "2     4449.46200\n",
       "3    21984.47061\n",
       "4     3866.85520\n",
       "Name: charges, dtype: float64"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view y\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 1070, 268)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create training and test sets  for a feature matrix and a labelled vector \n",
    "# scikitlearn test and split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)\n",
    "len(X), len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "267.6"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can check 20% of the data\n",
    "0.20 * 1338"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>46</td>\n",
       "      <td>19.950</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1285</th>\n",
       "      <td>47</td>\n",
       "      <td>24.320</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>52</td>\n",
       "      <td>24.860</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>39</td>\n",
       "      <td>34.320</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>54</td>\n",
       "      <td>21.470</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>18</td>\n",
       "      <td>31.350</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>39</td>\n",
       "      <td>23.870</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>58</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>37</td>\n",
       "      <td>47.600</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>55</td>\n",
       "      <td>29.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1070 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "560    46  19.950         2           1         0          1           0   \n",
       "1285   47  24.320         0           1         0          1           0   \n",
       "1142   52  24.860         0           1         0          1           0   \n",
       "969    39  34.320         5           1         0          1           0   \n",
       "486    54  21.470         3           1         0          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1095   18  31.350         4           1         0          1           0   \n",
       "1130   39  23.870         5           1         0          1           0   \n",
       "1294   58  25.175         0           0         1          1           0   \n",
       "860    37  47.600         2           1         0          0           1   \n",
       "1126   55  29.900         0           0         1          1           0   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "560                  0                 1                 0                 0  \n",
       "1285                 1                 0                 0                 0  \n",
       "1142                 0                 0                 1                 0  \n",
       "969                  0                 0                 1                 0  \n",
       "486                  0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1095                 1                 0                 0                 0  \n",
       "1130                 0                 0                 1                 0  \n",
       "1294                 1                 0                 0                 0  \n",
       "860                  0                 0                 0                 1  \n",
       "1126                 0                 0                 0                 1  \n",
       "\n",
       "[1070 rows x 11 columns]"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train  # can check that it is randomly shuffled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 8637.0996 - mae: 8637.0996\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7886.7769 - mae: 7886.7769\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7558.1475 - mae: 7558.1475\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7792.0220 - mae: 7792.0220\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7748.3892 - mae: 7748.3892\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7595.3940 - mae: 7595.3940\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7589.9849 - mae: 7589.9849\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7698.5591 - mae: 7698.5591\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7496.7788 - mae: 7496.7788\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7493.1743 - mae: 7493.1743\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7769.7314 - mae: 7769.7314\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7706.9033 - mae: 7706.9033\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7687.7227 - mae: 7687.7227\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7689.8999 - mae: 7689.8999\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7393.5322 - mae: 7393.5322\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7780.6982 - mae: 7780.6982\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7578.5093 - mae: 7578.5093\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7750.8350 - mae: 7750.8350\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7739.2134 - mae: 7739.2134\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7875.0635 - mae: 7875.0635\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7466.6768 - mae: 7466.6768\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7941.2310 - mae: 7941.2310\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7640.2725 - mae: 7640.2725\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7539.2656 - mae: 7539.2656\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7619.9658 - mae: 7619.9658\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7644.1709 - mae: 7644.1709\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7709.0361 - mae: 7709.0361\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7366.8662 - mae: 7366.8662\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7444.3135 - mae: 7444.3135\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7616.4087 - mae: 7616.4087\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7686.3853 - mae: 7686.3853\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.0981 - mae: 7548.0981\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7501.5532 - mae: 7501.5532\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7363.4155 - mae: 7363.4155\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7295.4468 - mae: 7295.4468\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7569.8813 - mae: 7569.8813\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7548.2002 - mae: 7548.2002\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7424.3979 - mae: 7424.3979\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7529.7739 - mae: 7529.7739\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7467.3232 - mae: 7467.3232\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7635.9282 - mae: 7635.9282\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7536.8398 - mae: 7536.8398\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7616.5845 - mae: 7616.5845\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7439.4932 - mae: 7439.4932\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7538.0156 - mae: 7538.0156\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7415.1460 - mae: 7415.1460\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7420.6938 - mae: 7420.6938\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7509.9829 - mae: 7509.9829\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7541.1123 - mae: 7541.1123\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7467.8633 - mae: 7467.8633\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7389.3545 - mae: 7389.3545\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7499.7749 - mae: 7499.7749\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7523.9282 - mae: 7523.9282\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7243.3120 - mae: 7243.3120\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7429.5854 - mae: 7429.5854\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.4004 - mae: 7313.4004\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7526.3887 - mae: 7526.3887\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7542.2661 - mae: 7542.2661\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7576.9277 - mae: 7576.9277\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7546.4058 - mae: 7546.4058\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7351.2261 - mae: 7351.2261\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7302.1436 - mae: 7302.1436\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7393.0874 - mae: 7393.0874\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7442.2886 - mae: 7442.2886\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7492.6782 - mae: 7492.6782\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7561.9165 - mae: 7561.9165\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7340.5137 - mae: 7340.5137\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7496.0850 - mae: 7496.0850\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7617.0298 - mae: 7617.0298\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7641.1958 - mae: 7641.1958\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.2744 - mae: 7084.2744\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7240.4907 - mae: 7240.4907\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7283.4883 - mae: 7283.4883\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7335.5063 - mae: 7335.5063\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7275.6392 - mae: 7275.6392\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7313.1855 - mae: 7313.1855\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7485.7578 - mae: 7485.7578\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7352.2798 - mae: 7352.2798\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7520.5703 - mae: 7520.5703\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7279.3784 - mae: 7279.3784\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7273.8477 - mae: 7273.8477\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7176.5205 - mae: 7176.5205\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7425.6289 - mae: 7425.6289\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7403.1289 - mae: 7403.1289\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7356.0093 - mae: 7356.0093\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7484.7271 - mae: 7484.7271\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7217.6079 - mae: 7217.6079\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.0000 - mae: 7261.0000\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7134.1553 - mae: 7134.1553\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7083.4351 - mae: 7083.4351\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7254.1782 - mae: 7254.1782\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7268.7456 - mae: 7268.7456\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7470.5225 - mae: 7470.5225\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7210.9541 - mae: 7210.9541\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7395.6807 - mae: 7395.6807\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7328.0884 - mae: 7328.0884\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7230.4375 - mae: 7230.4375\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7261.3936 - mae: 7261.3936\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7342.5684 - mae: 7342.5684\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7106.1709 - mae: 7106.1709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f36935d60>"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a neural network\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create model\n",
    "\n",
    "ins_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10),\n",
    "            tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "## compile model\n",
    "\n",
    "ins_model.compile(loss = tf.keras.losses.mae,\n",
    "                  optimizer = tf.keras.optimizers.SGD(),\n",
    "                  metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "ins_model.fit(X_train, y_train, epochs = 100)\n",
    "\n",
    "# we dont have to reformat these into tensors, because pandas is built on top of NumPy, pandas data frame is a big NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 7023.3286 - mae: 7023.3286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.32861328125, 7023.32861328125]"
      ]
     },
     "execution_count": 525,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results of model on test data\n",
    "\n",
    "ins_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9575.4421, 13346.089736364489)"
      ]
     },
     "execution_count": 526,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.median() , y_train.mean()  # middle no of target variable and the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: nan - mae: nan          \n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: nan - mae: nan\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2bbabe20>"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to improve the model -- adding an extra layer with more hidden units, train for longer\n",
    "\n",
    "# building a neural network\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create model\n",
    "# adding an extra layer with 100 hidden units\n",
    "\n",
    "ins_model_2=tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.Dense(10),\n",
    "            tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "## compile model\n",
    "\n",
    "ins_model_2.compile(loss = tf.keras.losses.mae,\n",
    "                  optimizer = tf.keras.optimizers.SGD(),\n",
    "                  metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "ins_model_2.fit(X_train, y_train, epochs = 100, verbose = 1)\n",
    "\n",
    "# we dont have to reformat these into tensors, because pandas is built on top of NumPy, pandas data frame is a big NumPy array\n",
    "\n",
    "# we may get nan  --> might be bacause our model is too complex to learn anything -- might be too bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: nan - mae: nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[nan, nan]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "ins_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 1s 2ms/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12749.5420 - mae: 12749.5420\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9457.7217 - mae: 9457.7217\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 8478.6582 - mae: 8478.658 - 0s 3ms/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7528.8408 - mae: 7528.8408\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7409.0811 - mae: 7409.0811\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7348.5195 - mae: 7348.5195\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7024.3506 - mae: 7024.3506\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6969.0112 - mae: 6969.0112\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6911.7275 - mae: 6911.7275\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6652.4609 - mae: 6652.4609\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6618.1011 - mae: 6618.1011\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6530.0439 - mae: 6530.0439\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6458.8984 - mae: 6458.8984\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6417.7520 - mae: 6417.7520\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6351.5269 - mae: 6351.5269\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6337.6602 - mae: 6337.6602\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6218.0435 - mae: 6218.0435\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6148.8403 - mae: 6148.8403\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 5689.2754 - mae: 5689.275 - 0s 2ms/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6031.3848 - mae: 6031.3848\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5995.2168 - mae: 5995.2168\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5963.0718 - mae: 5963.0718\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5940.0605 - mae: 5940.0605\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5834.3066 - mae: 5834.3066\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5772.3232 - mae: 5772.3232A: 0s - loss: 5450.0166 - mae: 5450.016\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5711.3477 - mae: 5711.3477\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5600.6655 - mae: 5600.6655\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5523.6187 - mae: 5523.6187\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5170.9355 - mae: 5170.9355\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5060.0854 - mae: 5060.0854\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f37ac9730>"
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to improve the model -- adding an extra layer with more hidden units, train for longer\n",
    "\n",
    "# building a neural network\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create model\n",
    "# adding an extra layer with 100 hidden units\n",
    "\n",
    "ins_model_2=tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.Dense(10),\n",
    "            tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "## compile model\n",
    "\n",
    "ins_model_2.compile(loss = tf.keras.losses.mae,\n",
    "                  optimizer = tf.keras.optimizers.Adam(),\n",
    "                  metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "ins_model_2.fit(X_train, y_train, epochs = 100, verbose = 1)\n",
    "\n",
    "# we dont have to reformat these into tensors, because pandas is built on top of NumPy, pandas data frame is a big NumPy array\n",
    "\n",
    "# we may get nan  --> might be bacause our model is too complex to learn anything -- might be too bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 4924.5093 - mae: 4924.5093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4924.50927734375, 4924.50927734375]"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_model_2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 7023.3286 - mae: 7023.3286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.32861328125, 7023.32861328125]"
      ]
     },
     "execution_count": 531,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 1s 3ms/step - loss: 13273.1602 - mae: 13273.1602\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13104.4297 - mae: 13104.4297\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12749.5420 - mae: 12749.5420\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12055.7500 - mae: 12055.7500\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10905.8154 - mae: 10905.8154\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9457.7217 - mae: 9457.7217\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8147.6543 - mae: 8147.6543\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7528.8408 - mae: 7528.8408\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7429.1528 - mae: 7429.1528\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7409.0811 - mae: 7409.0811\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7390.8042 - mae: 7390.8042\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7368.9170 - mae: 7368.9170\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7348.5195 - mae: 7348.5195\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7326.4893 - mae: 7326.4893\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7307.5815 - mae: 7307.5815\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7285.7734 - mae: 7285.7734\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7265.7104 - mae: 7265.7104\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7242.5488 - mae: 7242.5488\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7220.5068 - mae: 7220.5068\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7197.1978 - mae: 7197.1978\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7179.0195 - mae: 7179.0195\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7151.2104 - mae: 7151.2104\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7126.4639 - mae: 7126.4639\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7101.9199 - mae: 7101.9199\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7084.3379 - mae: 7084.3379\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7052.3296 - mae: 7052.3296\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7024.3506 - mae: 7024.3506\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6996.6963 - mae: 6996.6963\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6969.0112 - mae: 6969.0112\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6942.1899 - mae: 6942.1899\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6911.7275 - mae: 6911.7275\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6884.0205 - mae: 6884.0205\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6853.4648 - mae: 6853.4648\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6823.0674 - mae: 6823.0674\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6789.6855 - mae: 6789.6855\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6755.7646 - mae: 6755.7646\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6720.2026 - mae: 6720.2026\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6689.7158 - mae: 6689.7158\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6652.4609 - mae: 6652.4609\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6618.1011 - mae: 6618.1011\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6585.8633 - mae: 6585.8633\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6559.4956 - mae: 6559.4956\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6530.0439 - mae: 6530.0439\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6506.8071 - mae: 6506.8071\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6493.5718 - mae: 6493.5718\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6475.9258 - mae: 6475.9258\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6458.8984 - mae: 6458.8984\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6445.1494 - mae: 6445.1494\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6430.9639 - mae: 6430.9639\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6417.7520 - mae: 6417.7520\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6403.2759 - mae: 6403.2759\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6392.4141 - mae: 6392.4141\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6378.7451 - mae: 6378.7451\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6364.9126 - mae: 6364.9126\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6351.5269 - mae: 6351.5269\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6337.6602 - mae: 6337.6602\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6324.8369 - mae: 6324.8369\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6310.1948 - mae: 6310.1948\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6295.6035 - mae: 6295.6035\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6284.8696 - mae: 6284.8696\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6265.6411 - mae: 6265.6411\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6253.0103 - mae: 6253.0103\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6234.9292 - mae: 6234.9292\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6218.0435 - mae: 6218.0435\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6201.1899 - mae: 6201.1899\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6183.9590 - mae: 6183.9590\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6171.2993 - mae: 6171.2993\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6148.8403 - mae: 6148.8403\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6132.5981 - mae: 6132.5981\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6112.3848 - mae: 6112.3848\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6092.7202 - mae: 6092.7202\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6073.7422 - mae: 6073.7422\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6059.4883 - mae: 6059.4883\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6031.3848 - mae: 6031.3848\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6010.3350 - mae: 6010.3350\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5995.2168 - mae: 5995.2168\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5963.0718 - mae: 5963.0718\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5940.0605 - mae: 5940.0605\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5915.1064 - mae: 5915.1064\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5887.9990 - mae: 5887.9990\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5861.6987 - mae: 5861.6987\n",
      "Epoch 82/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 5834.3066 - mae: 5834.3066\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5805.8242 - mae: 5805.8242\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5772.3232 - mae: 5772.3232\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5745.1514 - mae: 5745.1514\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5711.3477 - mae: 5711.3477\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5674.5215 - mae: 5674.5215\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5639.4927 - mae: 5639.4927\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5600.6655 - mae: 5600.6655\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5559.4326 - mae: 5559.4326\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5523.6187 - mae: 5523.6187\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5474.1250 - mae: 5474.1250\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5432.2661 - mae: 5432.2661\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5386.0527 - mae: 5386.0527\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5333.1812 - mae: 5333.1812\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5288.8159 - mae: 5288.8159\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5234.6792 - mae: 5234.6792\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5170.9355 - mae: 5170.9355\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5112.9443 - mae: 5112.9443\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5060.0854 - mae: 5060.0854\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4987.7412 - mae: 4987.7412\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4915.4463 - mae: 4915.4463\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4847.4849 - mae: 4847.4849\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4768.1797 - mae: 4768.1797\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4683.4634 - mae: 4683.4634\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4601.2051 - mae: 4601.2051\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4513.4619 - mae: 4513.4619\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4423.5933 - mae: 4423.5933\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4339.2153 - mae: 4339.2153\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4255.7852 - mae: 4255.7852\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4174.8755 - mae: 4174.8755\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4101.4229 - mae: 4101.4229\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4031.7188 - mae: 4031.7188\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3986.9080 - mae: 3986.9080\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3944.5911 - mae: 3944.5911\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3918.6140 - mae: 3918.6140\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3896.7380 - mae: 3896.7380\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3872.1243 - mae: 3872.1243\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3851.9644 - mae: 3851.9644\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3835.4441 - mae: 3835.4441\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3829.4526 - mae: 3829.4526\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3822.5391 - mae: 3822.5391\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3814.8994 - mae: 3814.8994\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3806.8052 - mae: 3806.8052\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3795.5422 - mae: 3795.5422\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3807.1848 - mae: 3807.1848\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3797.8474 - mae: 3797.8474\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3791.7202 - mae: 3791.7202\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3802.8030 - mae: 3802.8030A: 0s - loss: 3841.5842 - mae: 3841.584\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3789.7974 - mae: 3789.7974\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3781.4006 - mae: 3781.4006\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3774.9458 - mae: 3774.9458\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3770.7568 - mae: 3770.7568\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3769.5464 - mae: 3769.5464\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3767.2346 - mae: 3767.2346\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3766.0598 - mae: 3766.0598\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3775.8567 - mae: 3775.8567\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3783.4241 - mae: 3783.4241\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3761.3586 - mae: 3761.3586\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3762.6267 - mae: 3762.6267\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3763.7024 - mae: 3763.7024\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3765.6416 - mae: 3765.6416\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3755.0134 - mae: 3755.0134\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3750.5752 - mae: 3750.5752\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3751.1660 - mae: 3751.1660\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3756.9319 - mae: 3756.9319\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3751.6326 - mae: 3751.6326\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3756.2712 - mae: 3756.2712\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3743.5854 - mae: 3743.5854\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3738.7112 - mae: 3738.7112\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3741.1484 - mae: 3741.1484\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3742.1653 - mae: 3742.1653\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3743.0076 - mae: 3743.0076\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3737.0332 - mae: 3737.0332\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3737.9741 - mae: 3737.9741\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3736.7354 - mae: 3736.7354\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3732.5813 - mae: 3732.5813\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3729.4280 - mae: 3729.4280\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3728.5618 - mae: 3728.5618\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3733.9949 - mae: 3733.9949\n",
      "Epoch 161/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3728.1077 - mae: 3728.1077\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3725.3667 - mae: 3725.3667\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3722.9507 - mae: 3722.9507\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3727.0610 - mae: 3727.0610\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3717.6614 - mae: 3717.6614\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3720.3699 - mae: 3720.3699\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3720.2910 - mae: 3720.2910\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3717.2764 - mae: 3717.2764\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3713.5598 - mae: 3713.5598\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3708.0081 - mae: 3708.0081\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3707.6399 - mae: 3707.6399\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3709.0303 - mae: 3709.0303\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3705.1501 - mae: 3705.1501\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3709.5408 - mae: 3709.5408\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3710.9675 - mae: 3710.9675\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3706.6677 - mae: 3706.6677\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3698.9150 - mae: 3698.9150\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3695.3818 - mae: 3695.3818\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3706.8618 - mae: 3706.8618\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3709.3865 - mae: 3709.3865\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - ETA: 0s - loss: 3668.8474 - mae: 3668.847 - 0s 3ms/step - loss: 3695.9609 - mae: 3695.9609\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3693.4851 - mae: 3693.4851\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3691.5898 - mae: 3691.5898\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3697.9915 - mae: 3697.9915\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3692.3047 - mae: 3692.3047\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3695.7461 - mae: 3695.7461\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3688.8049 - mae: 3688.8049\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3693.3767 - mae: 3693.3767\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3684.2998 - mae: 3684.2998\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3682.4170 - mae: 3682.4170\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3701.8770 - mae: 3701.8770\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3685.1741 - mae: 3685.1741\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3674.1248 - mae: 3674.1248\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3674.9351 - mae: 3674.9351\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3672.9148 - mae: 3672.9148\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3681.3547 - mae: 3681.3547\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3666.5688 - mae: 3666.5688\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3672.4160 - mae: 3672.4160\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3680.3140 - mae: 3680.3140\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3668.1562 - mae: 3668.1562\n"
     ]
    }
   ],
   "source": [
    "# train for longer\n",
    "\n",
    "# try to improve the model -- adding an extra layer with more hidden units, train for longer\n",
    "\n",
    "# building a neural network\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create model\n",
    "# adding an extra layer with 100 hidden units\n",
    "\n",
    "ins_model_3=tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(100),\n",
    "            tf.keras.layers.Dense(10),\n",
    "            tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "## compile model\n",
    "\n",
    "ins_model_3.compile(loss = tf.keras.losses.mae,\n",
    "                  optimizer = tf.keras.optimizers.Adam(),\n",
    "                  metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "history = ins_model_3.fit(X_train, y_train, epochs = 200, verbose = 1)\n",
    "\n",
    "# we dont have to reformat these into tensors, because pandas is built on top of NumPy, pandas data frame is a big NumPy array\n",
    "\n",
    "# we may get nan  --> might be bacause our model is too complex to learn anything -- might be too bigger model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 2ms/step - loss: 3667.6089 - mae: 3667.6089\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 3494.5291 - mae: 3494.5291\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3667.60888671875, 3667.60888671875], [3494.529052734375, 3494.529052734375])"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to evaluate\n",
    "ins_model_3.evaluate(X_train, y_train), ins_model_3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 7023.3286 - mae: 7023.3286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[7023.32861328125, 7023.32861328125]"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ins_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'epochs')"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot history --> also known as loss curve or training curve\n",
    "\n",
    "pd.DataFrame(history.history).plot()\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epochs\")\n",
    "\n",
    "# shows loss curve decreasing --> as the model learns --> its loss goes down , mae goes down --> this curve shows this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow EarlyStopping Callback  -> a tensorflow component to add to model to stop training once it stops improving a certain metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>smoker_no</th>\n",
       "      <th>smoker_yes</th>\n",
       "      <th>region_northeast</th>\n",
       "      <th>region_northwest</th>\n",
       "      <th>region_southeast</th>\n",
       "      <th>region_southwest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     bmi  children  sex_female  sex_male  smoker_no  smoker_yes  \\\n",
       "0      19  27.900         0           1         0          0           1   \n",
       "1      18  33.770         1           0         1          1           0   \n",
       "2      28  33.000         3           0         1          1           0   \n",
       "3      33  22.705         0           0         1          1           0   \n",
       "4      32  28.880         0           0         1          1           0   \n",
       "...   ...     ...       ...         ...       ...        ...         ...   \n",
       "1333   50  30.970         3           0         1          1           0   \n",
       "1334   18  31.920         0           1         0          1           0   \n",
       "1335   18  36.850         0           1         0          1           0   \n",
       "1336   21  25.800         0           1         0          1           0   \n",
       "1337   61  29.070         0           1         0          0           1   \n",
       "\n",
       "      region_northeast  region_northwest  region_southeast  region_southwest  \n",
       "0                    0                 0                 0                 1  \n",
       "1                    0                 0                 1                 0  \n",
       "2                    0                 0                 1                 0  \n",
       "3                    0                 1                 0                 0  \n",
       "4                    0                 1                 0                 0  \n",
       "...                ...               ...               ...               ...  \n",
       "1333                 0                 1                 0                 0  \n",
       "1334                 1                 0                 0                 0  \n",
       "1335                 0                 0                 1                 0  \n",
       "1336                 0                 0                 0                 1  \n",
       "1337                 0                 1                 0                 0  \n",
       "\n",
       "[1338 rows x 11 columns]"
      ]
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another way of preprocessing data -> standardization and normalization\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# can see that age is on a diferent scale to what bmi is\n",
    "X[\"age\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"age\"].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"age\"].plot(kind=\"hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 547,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X[\"bmi\"].plot(kind=\"hist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we wanted to get these both on a similar scale\n",
    "# as age goes from 20 to 60, bmi goes from 15 to 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    574\n",
       "1    324\n",
       "2    240\n",
       "3    157\n",
       "4     25\n",
       "5     18\n",
       "Name: children, dtype: int64"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"children\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we wanted to get all of these between 0 and 1 --> that is what normalization does\n",
    "# distribution means spread of the data\n",
    "\n",
    "# if we change the age column to be a normal distribution --> it will reduce the effects of outlier values\n",
    "\n",
    "# normalization --> in terms of scaling values , neural networks tend to prefer normalization\n",
    "# can use both and find which performs better\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>50</td>\n",
       "      <td>male</td>\n",
       "      <td>30.970</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>10600.54830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>31.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>2205.98080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1335</th>\n",
       "      <td>18</td>\n",
       "      <td>female</td>\n",
       "      <td>36.850</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1629.83350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336</th>\n",
       "      <td>21</td>\n",
       "      <td>female</td>\n",
       "      <td>25.800</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>2007.94500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1337</th>\n",
       "      <td>61</td>\n",
       "      <td>female</td>\n",
       "      <td>29.070</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>northwest</td>\n",
       "      <td>29141.36030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1338 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      age     sex     bmi  children smoker     region      charges\n",
       "0      19  female  27.900         0    yes  southwest  16884.92400\n",
       "1      18    male  33.770         1     no  southeast   1725.55230\n",
       "2      28    male  33.000         3     no  southeast   4449.46200\n",
       "3      33    male  22.705         0     no  northwest  21984.47061\n",
       "4      32    male  28.880         0     no  northwest   3866.85520\n",
       "...   ...     ...     ...       ...    ...        ...          ...\n",
       "1333   50    male  30.970         3     no  northwest  10600.54830\n",
       "1334   18  female  31.920         0     no  northeast   2205.98080\n",
       "1335   18  female  36.850         0     no  southeast   1629.83350\n",
       "1336   21  female  25.800         0     no  southwest   2007.94500\n",
       "1337   61  female  29.070         0    yes  northwest  29141.36030\n",
       "\n",
       "[1338 rows x 7 columns]"
      ]
     },
     "execution_count": 552,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# read the data frame\n",
    "insu = pd.read_csv(\"C:\\\\Users\\\\dell\\\\Downloads\\\\insurance.csv\")  # to reinstantiate the data frame\n",
    "insu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the numerical and non-numerical features\n",
    "\n",
    "# normalize the numerical features of insurance data frame\n",
    "# to prepare data , use some classes fro Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# creating column transformer --> have to transform the columns in some way before passing to neural network\n",
    "ct = make_column_transformer(\n",
    "     (MinMaxScaler(), [\"age\", \"bmi\", \"children\"]),  # turn all values in these columns between 0 and 1\n",
    "      (OneHotEncoder(handle_unknown = \"ignore\"), [\"sex\", \"smoker\", \"region\"])\n",
    ") \n",
    "\n",
    "# Create X and y values\n",
    "\n",
    "X = insu.drop(\"charges\", axis=1)\n",
    "y = insu[\"charges\"]\n",
    "\n",
    "# create training and test data sets \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42) # 80-20% split data, random_state is for so that split happens exactly same otherwise it will give the difefrent results\n",
    "\n",
    "# fit the column transformer to the training data and then use that fit ct to transformer your test data\n",
    "\n",
    "ct.fit(X_train)\n",
    "\n",
    "# transform training and test data with normalization (MinMaxScaler and OneHotEncoder)\n",
    "X_train_normal = ct.transform(X_train)\n",
    "X_test_normal = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                19\n",
       "sex            female\n",
       "bmi              27.9\n",
       "children            0\n",
       "smoker            yes\n",
       "region      southwest\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  checking the data \n",
    "X_train.loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60869565, 0.10734463, 0.4       , 1.        , 0.        ,\n",
       "       1.        , 0.        , 0.        , 1.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 566,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal[0]  # now the data is like below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.63043478, 0.22491256, 0.        , 1.        , 0.        ,\n",
       "       1.        , 0.        , 1.        , 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 567,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60869565, 0.10734463, 0.4       , ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.63043478, 0.22491256, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.73913043, 0.23944041, 0.        , ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       ...,\n",
       "       [0.86956522, 0.24791499, 0.        , ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.41304348, 0.85122411, 0.4       , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.80434783, 0.37503363, 0.        , ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 568,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1070, 6), (1070, 11))"
      ]
     },
     "execution_count": 569,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the shapes\n",
    "X_train.shape, X_train_normal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_78 (Dense)             (None, 100)               1200      \n",
      "_________________________________________________________________\n",
      "dense_79 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_80 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 2,221\n",
      "Trainable params: 2,221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ins_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - 14s 14ms/step - loss: 13342.6494 - mae: 13342.6494\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 13333.4785 - mae: 13333.4785\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13312.0234 - mae: 13312.0234\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13267.7930 - mae: 13267.7930\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13189.5830 - mae: 13189.5830\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13066.4502 - mae: 13066.4502\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12888.1953 - mae: 12888.1953\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12644.6523 - mae: 12644.6523\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 12325.5469 - mae: 12325.5469\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11925.9658 - mae: 11925.9658\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11454.3350 - mae: 11454.3350\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 10949.8076 - mae: 10949.8076\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 10448.9404 - mae: 10448.9404\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 9951.6250 - mae: 9951.6250\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9482.7412 - mae: 9482.7412\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9066.7461 - mae: 9066.7461\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8721.9854 - mae: 8721.9854\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8441.2002 - mae: 8441.2002\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 8227.5117 - mae: 8227.5117\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8081.9775 - mae: 8081.9775\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7973.8945 - mae: 7973.8945\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7899.1597 - mae: 7899.1597\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7840.3906 - mae: 7840.3906\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7787.9619 - mae: 7787.9619\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7749.2622 - mae: 7749.2622\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7697.9595 - mae: 7697.9595\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7656.0273 - mae: 7656.0273\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7613.4780 - mae: 7613.4780\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7570.9482 - mae: 7570.9482\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7527.4175 - mae: 7527.4175\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7483.5947 - mae: 7483.5947\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7439.4424 - mae: 7439.4424\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7395.0547 - mae: 7395.0547\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7346.8125 - mae: 7346.8125\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7300.0488 - mae: 7300.0488\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7249.8452 - mae: 7249.8452\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7199.5303 - mae: 7199.5303\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7148.4805 - mae: 7148.4805\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 7093.6660 - mae: 7093.6660\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7038.1797 - mae: 7038.1797\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6981.7397 - mae: 6981.7397\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6922.7847 - mae: 6922.7847\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6860.1724 - mae: 6860.1724\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6793.7969 - mae: 6793.7969\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6726.6201 - mae: 6726.6201\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6657.4683 - mae: 6657.4683\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6586.3086 - mae: 6586.3086\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6507.5063 - mae: 6507.5063\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6428.6021 - mae: 6428.6021\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6342.7100 - mae: 6342.7100\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6258.0718 - mae: 6258.0718\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 6164.7046 - mae: 6164.7046\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6068.6748 - mae: 6068.6748\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5970.0981 - mae: 5970.0981\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5862.5625 - mae: 5862.5625\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5753.9531 - mae: 5753.9531\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5638.0942 - mae: 5638.0942\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5519.8687 - mae: 5519.8687\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5401.3198 - mae: 5401.3198\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5277.3501 - mae: 5277.3501\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 5149.7642 - mae: 5149.7642\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5019.3535 - mae: 5019.3535\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4889.6865 - mae: 4889.6865\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4756.8560 - mae: 4756.8560\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4629.4370 - mae: 4629.4370\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4503.5991 - mae: 4503.5991\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4392.9922 - mae: 4392.9922\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4284.3862 - mae: 4284.3862\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4182.6182 - mae: 4182.6182\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 4089.5725 - mae: 4089.5725\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4003.3896 - mae: 4003.3896\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3929.0093 - mae: 3929.0093\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3866.3110 - mae: 3866.3110\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3813.7144 - mae: 3813.7144\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3773.0312 - mae: 3773.0312\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3744.1995 - mae: 3744.1995\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3719.6868 - mae: 3719.6868\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3702.9109 - mae: 3702.9109\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3691.8792 - mae: 3691.8792\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3682.8350 - mae: 3682.8350\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3676.9763 - mae: 3676.9763\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3673.9492 - mae: 3673.9492\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3667.8452 - mae: 3667.8452\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3664.5757 - mae: 3664.5757\n",
      "Epoch 85/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3661.8562 - mae: 3661.8562\n",
      "Epoch 86/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3660.3044 - mae: 3660.3044\n",
      "Epoch 87/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3657.5134 - mae: 3657.5134\n",
      "Epoch 88/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3655.2200 - mae: 3655.2200\n",
      "Epoch 89/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3653.8831 - mae: 3653.8831\n",
      "Epoch 90/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3652.0193 - mae: 3652.0193\n",
      "Epoch 91/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3648.9990 - mae: 3648.9990\n",
      "Epoch 92/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3648.4458 - mae: 3648.4458\n",
      "Epoch 93/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3646.2300 - mae: 3646.2300\n",
      "Epoch 94/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3644.4380 - mae: 3644.4380\n",
      "Epoch 95/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3645.8770 - mae: 3645.8770\n",
      "Epoch 96/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3642.2573 - mae: 3642.2573\n",
      "Epoch 97/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3640.1189 - mae: 3640.1189\n",
      "Epoch 98/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3638.0647 - mae: 3638.0647\n",
      "Epoch 99/100\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3637.2051 - mae: 3637.2051\n",
      "Epoch 100/100\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3636.1707 - mae: 3636.1707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f3a1f17f0>"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as data is normalized and one_hot encoded we can build model and fit normalized data on it.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "ins_model_4 = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(100),\n",
    "                tf.keras.layers.Dense(10),\n",
    "                tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "ins_model_4.compile(loss = tf.keras.losses.mae,\n",
    "                    optimizer = tf.keras.optimizers.Adam(),\n",
    "                    metrics = [\"mae\"])\n",
    "\n",
    "# we are changing the data here -> normalized data here\n",
    "ins_model_4.fit(X_train_normal, y_train, epochs = 100)  # fitting on the same labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 1s 6ms/step - loss: 3438.7844 - mae: 3438.7844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3438.784423828125, 3438.784423828125]"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model build using normalized data\n",
    "\n",
    "# have to evaluate the model on normalized data\n",
    "ins_model_4.evaluate(X_test_normal, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so, this model performed better than model 2 by normalizing data\n",
    "\n",
    "# we just converted the values of the target features to be between 0 and 1\n",
    "# normalization --> gives a faster convergence time --> model gets to a better result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "34/34 [==============================] - 2s 3ms/step - loss: 13340.0576 - mae: 13340.0576\n",
      "Epoch 2/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 13274.2119 - mae: 13274.2119\n",
      "Epoch 3/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 12902.4678 - mae: 12902.4678\n",
      "Epoch 4/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 11627.9072 - mae: 11627.9072\n",
      "Epoch 5/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 9409.8906 - mae: 9409.8906\n",
      "Epoch 6/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 8040.1831 - mae: 8040.1831\n",
      "Epoch 7/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7812.9692 - mae: 7812.9692\n",
      "Epoch 8/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7643.8770 - mae: 7643.8770\n",
      "Epoch 9/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7474.1938 - mae: 7474.1938\n",
      "Epoch 10/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7287.1401 - mae: 7287.1401\n",
      "Epoch 11/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 7084.9023 - mae: 7084.9023\n",
      "Epoch 12/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6842.2212 - mae: 6842.2212\n",
      "Epoch 13/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6562.9932 - mae: 6562.9932\n",
      "Epoch 14/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 6206.1650 - mae: 6206.1650\n",
      "Epoch 15/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5772.8926 - mae: 5772.8926\n",
      "Epoch 16/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 5240.9233 - mae: 5240.9233\n",
      "Epoch 17/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4661.9497 - mae: 4661.9497\n",
      "Epoch 18/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 4128.2378 - mae: 4128.2378\n",
      "Epoch 19/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3791.5327 - mae: 3791.5327\n",
      "Epoch 20/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3673.1504 - mae: 3673.1504\n",
      "Epoch 21/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3654.5793 - mae: 3654.5793\n",
      "Epoch 22/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3646.1877 - mae: 3646.1877\n",
      "Epoch 23/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3637.7112 - mae: 3637.7112\n",
      "Epoch 24/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3631.6672 - mae: 3631.6672\n",
      "Epoch 25/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3626.1050 - mae: 3626.1050\n",
      "Epoch 26/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3610.1890 - mae: 3610.1890\n",
      "Epoch 27/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3602.3193 - mae: 3602.3193\n",
      "Epoch 28/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3602.0762 - mae: 3602.0762\n",
      "Epoch 29/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3586.9050 - mae: 3586.9050\n",
      "Epoch 30/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3594.6167 - mae: 3594.6167\n",
      "Epoch 31/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3586.1243 - mae: 3586.1243\n",
      "Epoch 32/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3566.6870 - mae: 3566.6870\n",
      "Epoch 33/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3570.9761 - mae: 3570.9761\n",
      "Epoch 34/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3548.4902 - mae: 3548.4902\n",
      "Epoch 35/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3552.9055 - mae: 3552.9055\n",
      "Epoch 36/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3538.3013 - mae: 3538.3013\n",
      "Epoch 37/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3529.5615 - mae: 3529.5615\n",
      "Epoch 38/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3537.5234 - mae: 3537.5234\n",
      "Epoch 39/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3520.8137 - mae: 3520.8137\n",
      "Epoch 40/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3523.9150 - mae: 3523.9150\n",
      "Epoch 41/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3506.1304 - mae: 3506.1304\n",
      "Epoch 42/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3507.6758 - mae: 3507.6758\n",
      "Epoch 43/200\n",
      "34/34 [==============================] - 0s 4ms/step - loss: 3505.7041 - mae: 3505.7041A: 0s - loss: 3467.6494 - mae: 3467.649\n",
      "Epoch 44/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3491.9543 - mae: 3491.9543\n",
      "Epoch 45/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.4570 - mae: 3480.4570\n",
      "Epoch 46/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3488.7170 - mae: 3488.7170\n",
      "Epoch 47/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3488.3669 - mae: 3488.3669\n",
      "Epoch 48/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.8733 - mae: 3482.8733\n",
      "Epoch 49/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3500.7119 - mae: 3500.7119\n",
      "Epoch 50/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3474.4292 - mae: 3474.4292\n",
      "Epoch 51/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3476.0637 - mae: 3476.0637\n",
      "Epoch 52/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3483.2905 - mae: 3483.2905\n",
      "Epoch 53/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3475.5408 - mae: 3475.5408\n",
      "Epoch 54/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3492.6777 - mae: 3492.6777\n",
      "Epoch 55/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3504.7305 - mae: 3504.7305\n",
      "Epoch 56/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.6160 - mae: 3482.6160\n",
      "Epoch 57/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.1648 - mae: 3480.1648\n",
      "Epoch 58/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3476.9785 - mae: 3476.9785\n",
      "Epoch 59/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.0273 - mae: 3484.0273\n",
      "Epoch 60/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.6765 - mae: 3483.6765\n",
      "Epoch 61/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.1824 - mae: 3484.1824\n",
      "Epoch 62/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.1245 - mae: 3478.1245\n",
      "Epoch 63/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.8635 - mae: 3479.8635\n",
      "Epoch 64/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.9626 - mae: 3483.9626\n",
      "Epoch 65/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3492.1665 - mae: 3492.1667\n",
      "Epoch 66/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3487.6404 - mae: 3487.6404\n",
      "Epoch 67/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.7659 - mae: 3479.7659\n",
      "Epoch 68/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3489.1006 - mae: 3489.1006\n",
      "Epoch 69/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3476.5869 - mae: 3476.5869\n",
      "Epoch 70/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3488.2239 - mae: 3488.2239\n",
      "Epoch 71/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.2266 - mae: 3480.2266\n",
      "Epoch 72/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3490.0820 - mae: 3490.0820\n",
      "Epoch 73/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3485.2380 - mae: 3485.2380\n",
      "Epoch 74/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.9919 - mae: 3478.9919\n",
      "Epoch 75/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.9890 - mae: 3477.9890\n",
      "Epoch 76/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.4399 - mae: 3478.4399\n",
      "Epoch 77/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.2400 - mae: 3478.2400\n",
      "Epoch 78/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.5125 - mae: 3479.5125\n",
      "Epoch 79/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.6189 - mae: 3481.6189\n",
      "Epoch 80/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.5508 - mae: 3483.5508\n",
      "Epoch 81/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.1292 - mae: 3483.1292\n",
      "Epoch 82/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.8965 - mae: 3479.8965\n",
      "Epoch 83/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.5376 - mae: 3479.5376\n",
      "Epoch 84/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.4707 - mae: 3481.4707\n",
      "Epoch 85/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3475.3628 - mae: 3475.3628\n",
      "Epoch 86/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3476.6106 - mae: 3476.6106\n",
      "Epoch 87/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.5857 - mae: 3482.5857\n",
      "Epoch 88/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.2830 - mae: 3480.2830\n",
      "Epoch 89/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.9539 - mae: 3479.9539\n",
      "Epoch 90/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.8364 - mae: 3480.8364\n",
      "Epoch 91/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.5107 - mae: 3478.5107\n",
      "Epoch 92/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.9546 - mae: 3481.9546\n",
      "Epoch 93/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.4761 - mae: 3477.4761\n",
      "Epoch 94/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.8401 - mae: 3479.8401\n",
      "Epoch 95/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.7971 - mae: 3478.7971\n",
      "Epoch 96/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.3862 - mae: 3483.3862\n",
      "Epoch 97/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3485.0371 - mae: 3485.0371\n",
      "Epoch 98/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.5874 - mae: 3478.5874\n",
      "Epoch 99/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.8193 - mae: 3482.8193\n",
      "Epoch 100/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.5972 - mae: 3483.5972\n",
      "Epoch 101/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.7515 - mae: 3481.7515\n",
      "Epoch 102/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.0728 - mae: 3478.0728\n",
      "Epoch 103/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.5676 - mae: 3481.5676\n",
      "Epoch 104/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.2495 - mae: 3477.2495\n",
      "Epoch 105/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3485.9849 - mae: 3485.9849\n",
      "Epoch 106/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.9724 - mae: 3479.9724\n",
      "Epoch 107/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.9211 - mae: 3482.9211\n",
      "Epoch 108/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.7720 - mae: 3477.7720\n",
      "Epoch 109/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.1550 - mae: 3484.1550\n",
      "Epoch 110/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3475.1091 - mae: 3475.1091\n",
      "Epoch 111/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3485.9648 - mae: 3485.9648\n",
      "Epoch 112/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.3699 - mae: 3483.3699\n",
      "Epoch 113/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.6604 - mae: 3482.6604\n",
      "Epoch 114/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3504.0886 - mae: 3504.0886\n",
      "Epoch 115/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.9102 - mae: 3484.9102\n",
      "Epoch 116/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.0498 - mae: 3482.0498\n",
      "Epoch 117/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3487.4741 - mae: 3487.4741\n",
      "Epoch 118/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3474.7727 - mae: 3474.7727\n",
      "Epoch 119/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.0154 - mae: 3482.0154\n",
      "Epoch 120/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.0273 - mae: 3478.0273\n",
      "Epoch 121/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.9829 - mae: 3484.9829\n",
      "Epoch 122/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3487.7524 - mae: 3487.7524\n",
      "Epoch 123/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.4023 - mae: 3482.4023\n",
      "Epoch 124/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3476.7026 - mae: 3476.7026\n",
      "Epoch 125/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.5540 - mae: 3482.5540\n",
      "Epoch 126/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.4963 - mae: 3481.4963\n",
      "Epoch 127/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3487.9475 - mae: 3487.9475\n",
      "Epoch 128/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3487.8560 - mae: 3487.8560\n",
      "Epoch 129/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3494.9006 - mae: 3494.9006\n",
      "Epoch 130/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.7974 - mae: 3478.7974\n",
      "Epoch 131/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.7183 - mae: 3480.7183\n",
      "Epoch 132/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.8015 - mae: 3479.8015\n",
      "Epoch 133/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.8943 - mae: 3477.8943\n",
      "Epoch 134/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.3264 - mae: 3478.3264\n",
      "Epoch 135/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.1948 - mae: 3479.1948\n",
      "Epoch 136/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3476.8350 - mae: 3476.8350\n",
      "Epoch 137/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.1150 - mae: 3484.1150\n",
      "Epoch 138/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.6963 - mae: 3484.6963\n",
      "Epoch 139/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3486.5142 - mae: 3486.5142\n",
      "Epoch 140/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.5493 - mae: 3482.5493\n",
      "Epoch 141/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3491.0610 - mae: 3491.0610\n",
      "Epoch 142/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3487.2517 - mae: 3487.2517\n",
      "Epoch 143/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.0112 - mae: 3484.0112\n",
      "Epoch 144/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.2507 - mae: 3480.2507\n",
      "Epoch 145/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.2122 - mae: 3481.2122\n",
      "Epoch 146/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3491.5598 - mae: 3491.5598\n",
      "Epoch 147/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.8311 - mae: 3479.8311\n",
      "Epoch 148/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3485.6733 - mae: 3485.6733\n",
      "Epoch 149/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.5754 - mae: 3478.5754\n",
      "Epoch 150/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3474.4353 - mae: 3474.4353\n",
      "Epoch 151/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.8760 - mae: 3482.8760\n",
      "Epoch 152/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.9727 - mae: 3484.9727\n",
      "Epoch 153/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.6506 - mae: 3477.6506\n",
      "Epoch 154/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.9226 - mae: 3483.9226\n",
      "Epoch 155/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.0037 - mae: 3483.0037\n",
      "Epoch 156/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.8486 - mae: 3482.8486\n",
      "Epoch 157/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.5176 - mae: 3483.5176\n",
      "Epoch 158/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.3635 - mae: 3483.3635\n",
      "Epoch 159/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.9629 - mae: 3477.9629\n",
      "Epoch 160/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.0007 - mae: 3482.0007\n",
      "Epoch 161/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.6233 - mae: 3482.6233\n",
      "Epoch 162/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3476.7083 - mae: 3476.7083\n",
      "Epoch 163/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.5120 - mae: 3478.5120\n",
      "Epoch 164/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.9939 - mae: 3484.9939\n",
      "Epoch 165/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.8071 - mae: 3477.8071\n",
      "Epoch 166/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.2524 - mae: 3479.2524\n",
      "Epoch 167/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.6860 - mae: 3479.6860\n",
      "Epoch 168/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.8809 - mae: 3480.8809\n",
      "Epoch 169/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.9646 - mae: 3477.9646\n",
      "Epoch 170/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.1099 - mae: 3482.1099\n",
      "Epoch 171/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3479.2271 - mae: 3479.2271\n",
      "Epoch 172/200\n",
      "34/34 [==============================] - 0s 2ms/step - loss: 3484.0474 - mae: 3484.0474\n",
      "Epoch 173/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3476.8608 - mae: 3476.8608\n",
      "Epoch 174/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.3474 - mae: 3480.3474\n",
      "Epoch 175/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.2202 - mae: 3479.2202\n",
      "Epoch 176/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3491.2493 - mae: 3491.2493\n",
      "Epoch 177/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.4504 - mae: 3479.4504\n",
      "Epoch 178/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.2341 - mae: 3482.2341\n",
      "Epoch 179/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3488.3523 - mae: 3488.3523\n",
      "Epoch 180/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3491.3101 - mae: 3491.3101\n",
      "Epoch 181/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.3931 - mae: 3481.3931\n",
      "Epoch 182/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.6177 - mae: 3482.6177\n",
      "Epoch 183/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3480.9834 - mae: 3480.9834\n",
      "Epoch 184/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3482.9207 - mae: 3482.9207\n",
      "Epoch 185/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.2646 - mae: 3483.2646\n",
      "Epoch 186/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.6030 - mae: 3483.6030\n",
      "Epoch 187/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.3872 - mae: 3478.3872\n",
      "Epoch 188/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.9111 - mae: 3479.9111\n",
      "Epoch 189/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.7378 - mae: 3478.7378\n",
      "Epoch 190/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3483.7673 - mae: 3483.7673\n",
      "Epoch 191/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3498.7161 - mae: 3498.7161\n",
      "Epoch 192/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3487.9248 - mae: 3487.9248\n",
      "Epoch 193/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3484.6208 - mae: 3484.6208\n",
      "Epoch 194/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3479.2610 - mae: 3479.2610\n",
      "Epoch 195/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3474.7588 - mae: 3474.7588\n",
      "Epoch 196/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3486.5461 - mae: 3486.5461\n",
      "Epoch 197/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3477.0808 - mae: 3477.0808\n",
      "Epoch 198/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3492.5405 - mae: 3492.5405\n",
      "Epoch 199/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3481.3950 - mae: 3481.3950\n",
      "Epoch 200/200\n",
      "34/34 [==============================] - 0s 3ms/step - loss: 3478.9324 - mae: 3478.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f3a43d490>"
      ]
     },
     "execution_count": 580,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as data is normalized and one_hot encoded we can build model and fit normalized data on it.\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "ins_model_5 = tf.keras.Sequential([\n",
    "                tf.keras.layers.Dense(100),\n",
    "                tf.keras.layers.Dense(100),\n",
    "                tf.keras.layers.Dense(10),\n",
    "                tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "ins_model_5.compile(loss = tf.keras.losses.mae,\n",
    "                    optimizer = tf.keras.optimizers.Adam(),\n",
    "                    metrics = [\"mae\"])\n",
    "\n",
    "# we are changing the data here -> normalized data here\n",
    "ins_model_5.fit(X_train_normal, y_train, epochs = 200)  # fitting on the same labels \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network classification\n",
    "\n",
    "# multilabel --> multiple labels per sample\n",
    "# mutilclass --> only one label per sample\n",
    "\n",
    "# our model needs to like -->\n",
    "# we need to pass numerical data\n",
    "# numerical encode the images\n",
    "# colour channels of our image --> red, green and blue pixels combination in 224 by 224 -> going to give us image\n",
    "# turn inputs to tensors --> numerical encoding which are the normalized pixel values between 0 and 1\n",
    "# have to turn images into numbers in some way before passing to algorithm\n",
    "# for an image we have to grab the pixel vales\n",
    "# the algo figures out patterns in the input tensors or in the input image and create some predicted output based on looking at lot of actual samples of image-label pair.\n",
    "\n",
    "# batch size --> 32 is common, depending on data, size of chip --> it may have only that much memory to look at 32 samples, images at one time.\n",
    "# means our algorithm may only look at 32 images at a time so tha it does not run out of memory.\n",
    "\n",
    "# output shape may be (will be equal to) the no of classes in multi -class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# width, heifht, no of colour channels  -> can change depending on the problem\n",
    "# 224 pixels wide, 224 pixels high, 3 difefrent colour channels\n",
    "# reLu - Rectified linear unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network classification --> where we classify something as one thing or another\n",
    "# binary classification, multi-class classification, multi-label classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating data to view and fit\n",
    "\n",
    "from sklearn.datasets import make_circles\n",
    "\n",
    "# taking 1000 examples\n",
    "n_samples = 1000;\n",
    "\n",
    "# creating circles\n",
    "X, y = make_circles(n_samples,\n",
    "                    noise = 0.03,\n",
    "                    random_state = 42)  # for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.75424625,  0.23148074],\n",
       "       [-0.75615888,  0.15325888],\n",
       "       [-0.81539193,  0.17328203],\n",
       "       ...,\n",
       "       [-0.13690036, -0.81001183],\n",
       "       [ 0.67036156, -0.76750154],\n",
       "       [ 0.28105665,  0.96382443]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75424625, 0.23148074]), array([0.28105665, 0.96382443]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], X[999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the labels\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.754246</td>\n",
       "      <td>0.231481</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.756159</td>\n",
       "      <td>0.153259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.815392</td>\n",
       "      <td>0.173282</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.393731</td>\n",
       "      <td>0.692883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.442208</td>\n",
       "      <td>-0.896723</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.244054</td>\n",
       "      <td>0.944125</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.978655</td>\n",
       "      <td>-0.272373</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.136900</td>\n",
       "      <td>-0.810012</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.670362</td>\n",
       "      <td>-0.767502</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.281057</td>\n",
       "      <td>0.963824</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           X0        X1  label\n",
       "0    0.754246  0.231481      1\n",
       "1   -0.756159  0.153259      1\n",
       "2   -0.815392  0.173282      1\n",
       "3   -0.393731  0.692883      1\n",
       "4    0.442208 -0.896723      0\n",
       "..        ...       ...    ...\n",
       "995  0.244054  0.944125      0\n",
       "996 -0.978655 -0.272373      0\n",
       "997 -0.136900 -0.810012      1\n",
       "998  0.670362 -0.767502      0\n",
       "999  0.281057  0.963824      0\n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is binary class classification\n",
    "# visualize the data\n",
    "\n",
    "import pandas as pd\n",
    "# turn into a dataframe\n",
    "circles = pd.DataFrame({\"X0\":X[:, 0], \"X1\":X[:, 1], \"label\":y})\n",
    "circles\n",
    "\n",
    "# so, we have two features per label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x28a404639a0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualizing with a plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap = plt.cm.RdYlBu)  # cmap is the colour layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify red or blue dots --> we try to draw a line throgh a middle of these two\n",
    "# if we have another 100 rows and if we gave values like these --> will they be 0 or 1 (red or blue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 2), (1000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# difference between this data and regression data (in terms of images)\n",
    "# input and output shapes of our neural network\n",
    "\n",
    "# check shapes of our labels and features\n",
    "X.shape, y.shape  # X has a shape of 2, y is scalar -> does not have second dimension, 1000 samples of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 1000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check no of samples \n",
    "len(X), len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.75424625, 0.23148074]), 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example of features and labels\n",
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.5694666 , 0.84476776]), 0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[11], y[11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "32/32 [==============================] - 3s 4ms/step - loss: 2.8544 - accuracy: 0.4600\n",
      "Epoch 2/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.7131 - accuracy: 0.5430\n",
      "Epoch 3/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6973 - accuracy: 0.5090\n",
      "Epoch 4/5\n",
      "32/32 [==============================] - ETA: 0s - loss: 0.6950 - accuracy: 0.50 - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5010\n",
      "Epoch 5/5\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6942 - accuracy: 0.4820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a474106a0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelling steps\n",
    "# neural network classify if something is a blue dot or a red dot\n",
    "\n",
    "# steps are typically --> create or import a model, compile the model, fit the model, evaluate the model, tweak , evaluate\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create using sequential api\n",
    "# using 1 hidden layer\n",
    "model_1 = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile\n",
    "\n",
    "model_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer = tf.keras.optimizers.SGD(),\n",
    "                metrics = [\"accuracy\"])  # out of 100 examples, how many our model got right - what percentage\n",
    "\n",
    "model_1.fit(X, y, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6935 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6934831142425537, 0.5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# accuracy is 48 percent --> means on an average, out of 100 examples our model gets only 48 right\n",
    "\n",
    "\n",
    "# train for longer to improve the model\n",
    "\n",
    "model_1.fit(X, y, epochs = 200, verbose = 0)\n",
    "model_1.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a49bf7c10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we are working on a binary classification problem and our model is getting around 50% accuracy it is performing as if it is guessing so \n",
    "# adding another layer to improve the model\n",
    "\n",
    "# set the random seed\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "\n",
    "model_2 = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(1),\n",
    "          tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_2.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
    "                optimizer = tf.keras.optimizers.SGD(),\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "model_2.fit(X, y, epochs = 100, verbose=0)  # ideally we should fit on the training data and evaluate on the testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6950 - accuracy: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6949684619903564, 0.5]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model\n",
    "\n",
    "model_2.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circles[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve the model\n",
    "\n",
    "# create - add more layers, or increase no of hidden units within a layer\n",
    "# compliling a model - use a different optimization function \n",
    "# fitting a model - fit our model for more epochs --> train for longer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a4acf2a60>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# increase the no of hidden units , adding an extra layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create\n",
    "model_3 = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(100),  # adding 100 dense neurons\n",
    "          tf.keras.layers.Dense(10),   # adding anothe layer with 10 neurons\n",
    "          tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_3.compile(loss = tf.keras.losses.BinaryCrossentropy(),   #  loss function is that how wrong our model predictions are\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"accuracy\"])\n",
    "\n",
    "model_3.fit(X, y, epochs = 100, verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step - loss: 0.6980 - accuracy: 0.5080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6980255246162415, 0.5080000162124634]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 401\n",
      "Trainable params: 401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 100)               300       \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 1,321\n",
      "Trainable params: 1,321\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48793244],\n",
       "       [0.558876  ],\n",
       "       [0.56292844],\n",
       "       [0.5705067 ],\n",
       "       [0.44141144],\n",
       "       [0.57388216],\n",
       "       [0.5576486 ],\n",
       "       [0.48246646],\n",
       "       [0.4775583 ],\n",
       "       [0.57502264],\n",
       "       [0.514849  ],\n",
       "       [0.530877  ],\n",
       "       [0.56437737],\n",
       "       [0.45787305],\n",
       "       [0.45052725],\n",
       "       [0.461299  ],\n",
       "       [0.5405582 ],\n",
       "       [0.4638092 ],\n",
       "       [0.5479803 ],\n",
       "       [0.50375676],\n",
       "       [0.5063044 ],\n",
       "       [0.58775455],\n",
       "       [0.4590246 ],\n",
       "       [0.49123323],\n",
       "       [0.583216  ],\n",
       "       [0.5704256 ],\n",
       "       [0.55239356],\n",
       "       [0.4631735 ],\n",
       "       [0.45773405],\n",
       "       [0.45440978],\n",
       "       [0.47872233],\n",
       "       [0.57856053],\n",
       "       [0.5554615 ],\n",
       "       [0.46339148],\n",
       "       [0.45849162],\n",
       "       [0.58986676],\n",
       "       [0.5724737 ],\n",
       "       [0.52974397],\n",
       "       [0.45870548],\n",
       "       [0.51092887],\n",
       "       [0.49994153],\n",
       "       [0.5463086 ],\n",
       "       [0.51099026],\n",
       "       [0.4579724 ],\n",
       "       [0.5223273 ],\n",
       "       [0.53888035],\n",
       "       [0.44872284],\n",
       "       [0.5443396 ],\n",
       "       [0.43547922],\n",
       "       [0.49381846],\n",
       "       [0.522716  ],\n",
       "       [0.46464878],\n",
       "       [0.5530753 ],\n",
       "       [0.5224747 ],\n",
       "       [0.48307395],\n",
       "       [0.4876278 ],\n",
       "       [0.5528224 ],\n",
       "       [0.47150165],\n",
       "       [0.58121073],\n",
       "       [0.5046949 ],\n",
       "       [0.5187712 ],\n",
       "       [0.5020586 ],\n",
       "       [0.5015654 ],\n",
       "       [0.5853279 ],\n",
       "       [0.54401124],\n",
       "       [0.57290995],\n",
       "       [0.566548  ],\n",
       "       [0.47396797],\n",
       "       [0.5214059 ],\n",
       "       [0.50142056],\n",
       "       [0.5550637 ],\n",
       "       [0.45795166],\n",
       "       [0.53313994],\n",
       "       [0.55748683],\n",
       "       [0.5253388 ],\n",
       "       [0.5308998 ],\n",
       "       [0.5634172 ],\n",
       "       [0.4941492 ],\n",
       "       [0.5403439 ],\n",
       "       [0.51473683],\n",
       "       [0.5671911 ],\n",
       "       [0.51623994],\n",
       "       [0.53770965],\n",
       "       [0.52235174],\n",
       "       [0.5024864 ],\n",
       "       [0.5076409 ],\n",
       "       [0.46971345],\n",
       "       [0.56809825],\n",
       "       [0.55303365],\n",
       "       [0.4990753 ],\n",
       "       [0.45178312],\n",
       "       [0.4419011 ],\n",
       "       [0.48661464],\n",
       "       [0.58249176],\n",
       "       [0.5302316 ],\n",
       "       [0.43410558],\n",
       "       [0.54515857],\n",
       "       [0.5427116 ],\n",
       "       [0.51787245],\n",
       "       [0.4964019 ],\n",
       "       [0.56353104],\n",
       "       [0.47142828],\n",
       "       [0.45357966],\n",
       "       [0.5548917 ],\n",
       "       [0.5603533 ],\n",
       "       [0.5691158 ],\n",
       "       [0.5102997 ],\n",
       "       [0.4555856 ],\n",
       "       [0.582548  ],\n",
       "       [0.45634735],\n",
       "       [0.49066037],\n",
       "       [0.5052185 ],\n",
       "       [0.46990073],\n",
       "       [0.50882906],\n",
       "       [0.53646785],\n",
       "       [0.4383697 ],\n",
       "       [0.5868218 ],\n",
       "       [0.4641418 ],\n",
       "       [0.49692422],\n",
       "       [0.5252752 ],\n",
       "       [0.46029425],\n",
       "       [0.43716383],\n",
       "       [0.5702903 ],\n",
       "       [0.5582317 ],\n",
       "       [0.5745436 ],\n",
       "       [0.5137148 ],\n",
       "       [0.5269222 ],\n",
       "       [0.44201523],\n",
       "       [0.47215527],\n",
       "       [0.52213144],\n",
       "       [0.5406763 ],\n",
       "       [0.48092633],\n",
       "       [0.548063  ],\n",
       "       [0.46937704],\n",
       "       [0.49083304],\n",
       "       [0.51206845],\n",
       "       [0.563671  ],\n",
       "       [0.581044  ],\n",
       "       [0.48329043],\n",
       "       [0.5279756 ],\n",
       "       [0.49815482],\n",
       "       [0.56008285],\n",
       "       [0.5666285 ],\n",
       "       [0.5404355 ],\n",
       "       [0.46073073],\n",
       "       [0.4533254 ],\n",
       "       [0.5121632 ],\n",
       "       [0.5652162 ],\n",
       "       [0.5033343 ],\n",
       "       [0.5000837 ],\n",
       "       [0.56449443],\n",
       "       [0.5812211 ],\n",
       "       [0.46355522],\n",
       "       [0.44018215],\n",
       "       [0.45463413],\n",
       "       [0.44468862],\n",
       "       [0.5129016 ],\n",
       "       [0.5684134 ],\n",
       "       [0.5153597 ],\n",
       "       [0.46175706],\n",
       "       [0.5427882 ],\n",
       "       [0.5411566 ],\n",
       "       [0.56279004],\n",
       "       [0.57015985],\n",
       "       [0.4742506 ],\n",
       "       [0.5703185 ],\n",
       "       [0.5231675 ],\n",
       "       [0.5726741 ],\n",
       "       [0.5087246 ],\n",
       "       [0.51319414],\n",
       "       [0.4665066 ],\n",
       "       [0.45217705],\n",
       "       [0.55751324],\n",
       "       [0.46757734],\n",
       "       [0.45041484],\n",
       "       [0.46598017],\n",
       "       [0.55641127],\n",
       "       [0.5541836 ],\n",
       "       [0.5166019 ],\n",
       "       [0.57122195],\n",
       "       [0.45476633],\n",
       "       [0.5717005 ],\n",
       "       [0.4561363 ],\n",
       "       [0.48998255],\n",
       "       [0.49082285],\n",
       "       [0.5755754 ],\n",
       "       [0.47046155],\n",
       "       [0.4612748 ],\n",
       "       [0.45442075],\n",
       "       [0.5550501 ],\n",
       "       [0.45591837],\n",
       "       [0.49835002],\n",
       "       [0.56910944],\n",
       "       [0.5840391 ],\n",
       "       [0.58318734],\n",
       "       [0.44692475],\n",
       "       [0.48954403],\n",
       "       [0.5834775 ],\n",
       "       [0.5498082 ],\n",
       "       [0.5287381 ],\n",
       "       [0.4850306 ],\n",
       "       [0.49466783],\n",
       "       [0.5716707 ],\n",
       "       [0.5119249 ],\n",
       "       [0.49464816],\n",
       "       [0.53863335],\n",
       "       [0.58644104],\n",
       "       [0.45271975],\n",
       "       [0.46110708],\n",
       "       [0.5024093 ],\n",
       "       [0.52208376],\n",
       "       [0.57922   ],\n",
       "       [0.4541139 ],\n",
       "       [0.4982608 ],\n",
       "       [0.5638522 ],\n",
       "       [0.48878646],\n",
       "       [0.570598  ],\n",
       "       [0.56237376],\n",
       "       [0.45640332],\n",
       "       [0.56574297],\n",
       "       [0.51824874],\n",
       "       [0.56198716],\n",
       "       [0.46152925],\n",
       "       [0.50293845],\n",
       "       [0.45784473],\n",
       "       [0.46390378],\n",
       "       [0.50197357],\n",
       "       [0.474118  ],\n",
       "       [0.4553309 ],\n",
       "       [0.49670243],\n",
       "       [0.4834655 ],\n",
       "       [0.4711135 ],\n",
       "       [0.45382738],\n",
       "       [0.52795506],\n",
       "       [0.49023253],\n",
       "       [0.48824847],\n",
       "       [0.57512903],\n",
       "       [0.45282495],\n",
       "       [0.5892132 ],\n",
       "       [0.49295312],\n",
       "       [0.4661634 ],\n",
       "       [0.582744  ],\n",
       "       [0.48128343],\n",
       "       [0.5211879 ],\n",
       "       [0.52079874],\n",
       "       [0.55982614],\n",
       "       [0.44012457],\n",
       "       [0.52891773],\n",
       "       [0.5332327 ],\n",
       "       [0.5327585 ],\n",
       "       [0.53258854],\n",
       "       [0.4672413 ],\n",
       "       [0.52960485],\n",
       "       [0.46257335],\n",
       "       [0.44957036],\n",
       "       [0.50163376],\n",
       "       [0.48375487],\n",
       "       [0.45157593],\n",
       "       [0.4512    ],\n",
       "       [0.46838325],\n",
       "       [0.56545746],\n",
       "       [0.44669604],\n",
       "       [0.54397964],\n",
       "       [0.5527145 ],\n",
       "       [0.47108608],\n",
       "       [0.4704715 ],\n",
       "       [0.5222311 ],\n",
       "       [0.45582062],\n",
       "       [0.5592408 ],\n",
       "       [0.45295674],\n",
       "       [0.4549402 ],\n",
       "       [0.5642217 ],\n",
       "       [0.45949626],\n",
       "       [0.56313115],\n",
       "       [0.4891073 ],\n",
       "       [0.47747004],\n",
       "       [0.5880551 ],\n",
       "       [0.5467006 ],\n",
       "       [0.5319388 ],\n",
       "       [0.52964413],\n",
       "       [0.531213  ],\n",
       "       [0.52472126],\n",
       "       [0.5687661 ],\n",
       "       [0.53070974],\n",
       "       [0.58306956],\n",
       "       [0.56969523],\n",
       "       [0.4731382 ],\n",
       "       [0.44159043],\n",
       "       [0.57428724],\n",
       "       [0.45652086],\n",
       "       [0.453866  ],\n",
       "       [0.52308327],\n",
       "       [0.47285074],\n",
       "       [0.44388944],\n",
       "       [0.46423614],\n",
       "       [0.44352013],\n",
       "       [0.45260566],\n",
       "       [0.4426213 ],\n",
       "       [0.46980006],\n",
       "       [0.5832042 ],\n",
       "       [0.49836856],\n",
       "       [0.43970108],\n",
       "       [0.4541201 ],\n",
       "       [0.44110686],\n",
       "       [0.53566486],\n",
       "       [0.45371193],\n",
       "       [0.48427832],\n",
       "       [0.52339864],\n",
       "       [0.45333308],\n",
       "       [0.52008384],\n",
       "       [0.53954595],\n",
       "       [0.4904006 ],\n",
       "       [0.52897227],\n",
       "       [0.5671212 ],\n",
       "       [0.4432863 ],\n",
       "       [0.439771  ],\n",
       "       [0.5739996 ],\n",
       "       [0.47417927],\n",
       "       [0.5654862 ],\n",
       "       [0.5799096 ],\n",
       "       [0.5298415 ],\n",
       "       [0.577492  ],\n",
       "       [0.5198554 ],\n",
       "       [0.55777967],\n",
       "       [0.53454006],\n",
       "       [0.47743338],\n",
       "       [0.47960907],\n",
       "       [0.45131415],\n",
       "       [0.5703051 ],\n",
       "       [0.57023585],\n",
       "       [0.56826067],\n",
       "       [0.506412  ],\n",
       "       [0.56370646],\n",
       "       [0.55336636],\n",
       "       [0.46095818],\n",
       "       [0.5071226 ],\n",
       "       [0.57065254],\n",
       "       [0.5069176 ],\n",
       "       [0.46533352],\n",
       "       [0.492849  ],\n",
       "       [0.44744706],\n",
       "       [0.4426052 ],\n",
       "       [0.5865733 ],\n",
       "       [0.56645316],\n",
       "       [0.45089418],\n",
       "       [0.4401012 ],\n",
       "       [0.5084352 ],\n",
       "       [0.45891303],\n",
       "       [0.54342633],\n",
       "       [0.45217556],\n",
       "       [0.58975774],\n",
       "       [0.54371953],\n",
       "       [0.4624079 ],\n",
       "       [0.52572185],\n",
       "       [0.5277507 ],\n",
       "       [0.5739029 ],\n",
       "       [0.5222435 ],\n",
       "       [0.43621707],\n",
       "       [0.49266976],\n",
       "       [0.57648414],\n",
       "       [0.44038582],\n",
       "       [0.5304904 ],\n",
       "       [0.57508886],\n",
       "       [0.44151843],\n",
       "       [0.58496976],\n",
       "       [0.4850986 ],\n",
       "       [0.5390901 ],\n",
       "       [0.587509  ],\n",
       "       [0.44901544],\n",
       "       [0.4768585 ],\n",
       "       [0.5845551 ],\n",
       "       [0.56962836],\n",
       "       [0.57748866],\n",
       "       [0.58892006],\n",
       "       [0.46738034],\n",
       "       [0.5556814 ],\n",
       "       [0.45102334],\n",
       "       [0.5298837 ],\n",
       "       [0.4561879 ],\n",
       "       [0.5101252 ],\n",
       "       [0.5661124 ],\n",
       "       [0.58029455],\n",
       "       [0.528921  ],\n",
       "       [0.5714935 ],\n",
       "       [0.57867616],\n",
       "       [0.45554757],\n",
       "       [0.47771925],\n",
       "       [0.5702183 ],\n",
       "       [0.46479285],\n",
       "       [0.53989   ],\n",
       "       [0.58790594],\n",
       "       [0.4966929 ],\n",
       "       [0.5708069 ],\n",
       "       [0.5544862 ],\n",
       "       [0.5330157 ],\n",
       "       [0.5141853 ],\n",
       "       [0.4463145 ],\n",
       "       [0.44018757],\n",
       "       [0.5504332 ],\n",
       "       [0.47011322],\n",
       "       [0.47921687],\n",
       "       [0.44495678],\n",
       "       [0.49808288],\n",
       "       [0.49317908],\n",
       "       [0.55050856],\n",
       "       [0.5696295 ],\n",
       "       [0.4551012 ],\n",
       "       [0.49226856],\n",
       "       [0.5074503 ],\n",
       "       [0.4737689 ],\n",
       "       [0.485218  ],\n",
       "       [0.45180923],\n",
       "       [0.5328443 ],\n",
       "       [0.54863787],\n",
       "       [0.50820696],\n",
       "       [0.57055396],\n",
       "       [0.5720333 ],\n",
       "       [0.49644244],\n",
       "       [0.48503923],\n",
       "       [0.441495  ],\n",
       "       [0.4792714 ],\n",
       "       [0.56806535],\n",
       "       [0.45131922],\n",
       "       [0.5231435 ],\n",
       "       [0.4378314 ],\n",
       "       [0.4639321 ],\n",
       "       [0.5351661 ],\n",
       "       [0.51345843],\n",
       "       [0.56530035],\n",
       "       [0.5469412 ],\n",
       "       [0.53547037],\n",
       "       [0.46612185],\n",
       "       [0.47372156],\n",
       "       [0.4424219 ],\n",
       "       [0.5413743 ],\n",
       "       [0.4716493 ],\n",
       "       [0.5888468 ],\n",
       "       [0.46117014],\n",
       "       [0.46466005],\n",
       "       [0.5508245 ],\n",
       "       [0.5774397 ],\n",
       "       [0.52293   ],\n",
       "       [0.45892972],\n",
       "       [0.5713342 ],\n",
       "       [0.5026893 ],\n",
       "       [0.5274163 ],\n",
       "       [0.55851704],\n",
       "       [0.58654165],\n",
       "       [0.57292336],\n",
       "       [0.57118887],\n",
       "       [0.53213954],\n",
       "       [0.46951747],\n",
       "       [0.44548076],\n",
       "       [0.5849841 ],\n",
       "       [0.56229615],\n",
       "       [0.5639691 ],\n",
       "       [0.46243668],\n",
       "       [0.572152  ],\n",
       "       [0.4594794 ],\n",
       "       [0.44160438],\n",
       "       [0.524316  ],\n",
       "       [0.5570559 ],\n",
       "       [0.5383098 ],\n",
       "       [0.45820534],\n",
       "       [0.44833636],\n",
       "       [0.55487335],\n",
       "       [0.5607388 ],\n",
       "       [0.4394812 ],\n",
       "       [0.4862345 ],\n",
       "       [0.44143015],\n",
       "       [0.4470058 ],\n",
       "       [0.53930014],\n",
       "       [0.450769  ],\n",
       "       [0.5388264 ],\n",
       "       [0.4838878 ],\n",
       "       [0.46543497],\n",
       "       [0.4544686 ],\n",
       "       [0.45254123],\n",
       "       [0.5477902 ],\n",
       "       [0.5398521 ],\n",
       "       [0.5463901 ],\n",
       "       [0.54445416],\n",
       "       [0.47647738],\n",
       "       [0.44585276],\n",
       "       [0.495066  ],\n",
       "       [0.4953826 ],\n",
       "       [0.49810815],\n",
       "       [0.48935956],\n",
       "       [0.58634543],\n",
       "       [0.4586997 ],\n",
       "       [0.46327668],\n",
       "       [0.5428008 ],\n",
       "       [0.54937065],\n",
       "       [0.55176175],\n",
       "       [0.44200438],\n",
       "       [0.58494556],\n",
       "       [0.44040716],\n",
       "       [0.44293672],\n",
       "       [0.4729281 ],\n",
       "       [0.46449977],\n",
       "       [0.57611495],\n",
       "       [0.586679  ],\n",
       "       [0.44475693],\n",
       "       [0.45423168],\n",
       "       [0.5239818 ],\n",
       "       [0.45663232],\n",
       "       [0.5712521 ],\n",
       "       [0.45277083],\n",
       "       [0.4587859 ],\n",
       "       [0.55283564],\n",
       "       [0.55554837],\n",
       "       [0.49854368],\n",
       "       [0.48834026],\n",
       "       [0.47325557],\n",
       "       [0.49763042],\n",
       "       [0.54517144],\n",
       "       [0.58109576],\n",
       "       [0.5928483 ],\n",
       "       [0.46494848],\n",
       "       [0.4805504 ],\n",
       "       [0.4708466 ],\n",
       "       [0.56902087],\n",
       "       [0.4792924 ],\n",
       "       [0.48490095],\n",
       "       [0.44101596],\n",
       "       [0.5058966 ],\n",
       "       [0.49662054],\n",
       "       [0.5887762 ],\n",
       "       [0.5548478 ],\n",
       "       [0.545085  ],\n",
       "       [0.51036155],\n",
       "       [0.52242744],\n",
       "       [0.55718464],\n",
       "       [0.53553516],\n",
       "       [0.48419178],\n",
       "       [0.44087428],\n",
       "       [0.5829692 ],\n",
       "       [0.52747047],\n",
       "       [0.5611985 ],\n",
       "       [0.44079   ],\n",
       "       [0.58832276],\n",
       "       [0.54580027],\n",
       "       [0.5685574 ],\n",
       "       [0.4577381 ],\n",
       "       [0.564226  ],\n",
       "       [0.4529261 ],\n",
       "       [0.47852176],\n",
       "       [0.50261074],\n",
       "       [0.53592783],\n",
       "       [0.5664567 ],\n",
       "       [0.56300795],\n",
       "       [0.447451  ],\n",
       "       [0.5725418 ],\n",
       "       [0.5096972 ],\n",
       "       [0.47668546],\n",
       "       [0.45567656],\n",
       "       [0.4608996 ],\n",
       "       [0.54851514],\n",
       "       [0.50175494],\n",
       "       [0.4780153 ],\n",
       "       [0.58573717],\n",
       "       [0.47005862],\n",
       "       [0.4963019 ],\n",
       "       [0.55981356],\n",
       "       [0.5508589 ],\n",
       "       [0.43630344],\n",
       "       [0.574208  ],\n",
       "       [0.51346356],\n",
       "       [0.4857325 ],\n",
       "       [0.45606244],\n",
       "       [0.58026934],\n",
       "       [0.5647974 ],\n",
       "       [0.5303152 ],\n",
       "       [0.5091277 ],\n",
       "       [0.4756233 ],\n",
       "       [0.45376736],\n",
       "       [0.57523793],\n",
       "       [0.44256508],\n",
       "       [0.4469111 ],\n",
       "       [0.5588287 ],\n",
       "       [0.50175565],\n",
       "       [0.48047996],\n",
       "       [0.5087348 ],\n",
       "       [0.5265167 ],\n",
       "       [0.51637983],\n",
       "       [0.44331652],\n",
       "       [0.4985752 ],\n",
       "       [0.55298513],\n",
       "       [0.49541664],\n",
       "       [0.5860805 ],\n",
       "       [0.56467324],\n",
       "       [0.4994403 ],\n",
       "       [0.57275677],\n",
       "       [0.55059737],\n",
       "       [0.4760154 ],\n",
       "       [0.58030707],\n",
       "       [0.53106356],\n",
       "       [0.54511213],\n",
       "       [0.5228694 ],\n",
       "       [0.56002796],\n",
       "       [0.47275513],\n",
       "       [0.56986547],\n",
       "       [0.49930346],\n",
       "       [0.55687076],\n",
       "       [0.56797683],\n",
       "       [0.45884615],\n",
       "       [0.5881502 ],\n",
       "       [0.56177247],\n",
       "       [0.5554645 ],\n",
       "       [0.54768   ],\n",
       "       [0.5841339 ],\n",
       "       [0.5188697 ],\n",
       "       [0.5424239 ],\n",
       "       [0.56945837],\n",
       "       [0.5678125 ],\n",
       "       [0.5736315 ],\n",
       "       [0.45923638],\n",
       "       [0.48275763],\n",
       "       [0.46373004],\n",
       "       [0.4969406 ],\n",
       "       [0.45605767],\n",
       "       [0.5799099 ],\n",
       "       [0.47950423],\n",
       "       [0.5833475 ],\n",
       "       [0.475177  ],\n",
       "       [0.4796806 ],\n",
       "       [0.50037956],\n",
       "       [0.46363932],\n",
       "       [0.45273125],\n",
       "       [0.48271513],\n",
       "       [0.4567536 ],\n",
       "       [0.44711536],\n",
       "       [0.5380085 ],\n",
       "       [0.56619316],\n",
       "       [0.4667679 ],\n",
       "       [0.57561225],\n",
       "       [0.48461992],\n",
       "       [0.45307463],\n",
       "       [0.43739325],\n",
       "       [0.4564433 ],\n",
       "       [0.4627474 ],\n",
       "       [0.5760385 ],\n",
       "       [0.4898265 ],\n",
       "       [0.45692998],\n",
       "       [0.45846725],\n",
       "       [0.4411747 ],\n",
       "       [0.45950794],\n",
       "       [0.48371327],\n",
       "       [0.56888425],\n",
       "       [0.49070507],\n",
       "       [0.58155036],\n",
       "       [0.48481995],\n",
       "       [0.47552037],\n",
       "       [0.47529733],\n",
       "       [0.45520955],\n",
       "       [0.4965738 ],\n",
       "       [0.5306202 ],\n",
       "       [0.45889032],\n",
       "       [0.58585995],\n",
       "       [0.46111178],\n",
       "       [0.5801483 ],\n",
       "       [0.52232665],\n",
       "       [0.46758038],\n",
       "       [0.5505181 ],\n",
       "       [0.55787814],\n",
       "       [0.5807991 ],\n",
       "       [0.5711032 ],\n",
       "       [0.5484874 ],\n",
       "       [0.44401217],\n",
       "       [0.4362045 ],\n",
       "       [0.55080503],\n",
       "       [0.5320506 ],\n",
       "       [0.5344566 ],\n",
       "       [0.5725672 ],\n",
       "       [0.56598806],\n",
       "       [0.5081097 ],\n",
       "       [0.58199966],\n",
       "       [0.4438091 ],\n",
       "       [0.44985557],\n",
       "       [0.58157384],\n",
       "       [0.56717473],\n",
       "       [0.49022555],\n",
       "       [0.5457128 ],\n",
       "       [0.46918517],\n",
       "       [0.51466143],\n",
       "       [0.4875651 ],\n",
       "       [0.43896663],\n",
       "       [0.57140654],\n",
       "       [0.561532  ],\n",
       "       [0.5168852 ],\n",
       "       [0.55335355],\n",
       "       [0.52112573],\n",
       "       [0.55844504],\n",
       "       [0.5640062 ],\n",
       "       [0.46269298],\n",
       "       [0.5561985 ],\n",
       "       [0.54678774],\n",
       "       [0.52418196],\n",
       "       [0.44213045],\n",
       "       [0.58126277],\n",
       "       [0.5257908 ],\n",
       "       [0.55912   ],\n",
       "       [0.4579624 ],\n",
       "       [0.5040586 ],\n",
       "       [0.46553355],\n",
       "       [0.4531759 ],\n",
       "       [0.58115476],\n",
       "       [0.5757076 ],\n",
       "       [0.5627081 ],\n",
       "       [0.4538241 ],\n",
       "       [0.5576926 ],\n",
       "       [0.5667539 ],\n",
       "       [0.47768503],\n",
       "       [0.44579065],\n",
       "       [0.49796093],\n",
       "       [0.58534753],\n",
       "       [0.56742746],\n",
       "       [0.48118114],\n",
       "       [0.5488304 ],\n",
       "       [0.5787448 ],\n",
       "       [0.45593423],\n",
       "       [0.58531666],\n",
       "       [0.54755634],\n",
       "       [0.5406728 ],\n",
       "       [0.52752376],\n",
       "       [0.44288832],\n",
       "       [0.5662744 ],\n",
       "       [0.5860605 ],\n",
       "       [0.58524024],\n",
       "       [0.43632627],\n",
       "       [0.56668174],\n",
       "       [0.44202596],\n",
       "       [0.45549423],\n",
       "       [0.54359627],\n",
       "       [0.46138012],\n",
       "       [0.49523735],\n",
       "       [0.46491975],\n",
       "       [0.5648217 ],\n",
       "       [0.56355405],\n",
       "       [0.4472587 ],\n",
       "       [0.5304719 ],\n",
       "       [0.54233867],\n",
       "       [0.5620045 ],\n",
       "       [0.45794237],\n",
       "       [0.5824466 ],\n",
       "       [0.5617925 ],\n",
       "       [0.45596766],\n",
       "       [0.5483781 ],\n",
       "       [0.5178241 ],\n",
       "       [0.45351446],\n",
       "       [0.55438536],\n",
       "       [0.46663618],\n",
       "       [0.5485966 ],\n",
       "       [0.45300633],\n",
       "       [0.46356088],\n",
       "       [0.4736035 ],\n",
       "       [0.5476688 ],\n",
       "       [0.5048331 ],\n",
       "       [0.4422034 ],\n",
       "       [0.4594798 ],\n",
       "       [0.5598377 ],\n",
       "       [0.57107335],\n",
       "       [0.57792264],\n",
       "       [0.4736988 ],\n",
       "       [0.5464865 ],\n",
       "       [0.56903625],\n",
       "       [0.4604187 ],\n",
       "       [0.46766663],\n",
       "       [0.48956174],\n",
       "       [0.57431656],\n",
       "       [0.5305159 ],\n",
       "       [0.5713128 ],\n",
       "       [0.50105107],\n",
       "       [0.5627482 ],\n",
       "       [0.44125205],\n",
       "       [0.4582106 ],\n",
       "       [0.571943  ],\n",
       "       [0.4699812 ],\n",
       "       [0.5527905 ],\n",
       "       [0.5506892 ],\n",
       "       [0.5579124 ],\n",
       "       [0.55924255],\n",
       "       [0.53442883],\n",
       "       [0.4543699 ],\n",
       "       [0.45486283],\n",
       "       [0.57828575],\n",
       "       [0.45247072],\n",
       "       [0.51237035],\n",
       "       [0.44333893],\n",
       "       [0.47841603],\n",
       "       [0.47761327],\n",
       "       [0.5633757 ],\n",
       "       [0.4660867 ],\n",
       "       [0.45086795],\n",
       "       [0.45815265],\n",
       "       [0.5529397 ],\n",
       "       [0.47929186],\n",
       "       [0.5169218 ],\n",
       "       [0.5631662 ],\n",
       "       [0.48760223],\n",
       "       [0.50976706],\n",
       "       [0.4605006 ],\n",
       "       [0.52955854],\n",
       "       [0.5214972 ],\n",
       "       [0.53434527],\n",
       "       [0.56839216],\n",
       "       [0.57254416],\n",
       "       [0.5843936 ],\n",
       "       [0.48510063],\n",
       "       [0.49228245],\n",
       "       [0.49677366],\n",
       "       [0.5795212 ],\n",
       "       [0.56880444],\n",
       "       [0.46034092],\n",
       "       [0.47876543],\n",
       "       [0.48567098],\n",
       "       [0.45187312],\n",
       "       [0.5623836 ],\n",
       "       [0.5454093 ],\n",
       "       [0.5143055 ],\n",
       "       [0.56999904],\n",
       "       [0.5549194 ],\n",
       "       [0.52702993],\n",
       "       [0.5718128 ],\n",
       "       [0.44028145],\n",
       "       [0.51121634],\n",
       "       [0.46160007],\n",
       "       [0.5810264 ],\n",
       "       [0.44769925],\n",
       "       [0.5240535 ],\n",
       "       [0.44504023],\n",
       "       [0.542263  ],\n",
       "       [0.48628592],\n",
       "       [0.57908297],\n",
       "       [0.46514463],\n",
       "       [0.5416215 ],\n",
       "       [0.56505334],\n",
       "       [0.45073724],\n",
       "       [0.54650205],\n",
       "       [0.55467296],\n",
       "       [0.5035159 ],\n",
       "       [0.5666131 ],\n",
       "       [0.5715147 ],\n",
       "       [0.55364543],\n",
       "       [0.5197008 ],\n",
       "       [0.56630373],\n",
       "       [0.5218443 ],\n",
       "       [0.44018382],\n",
       "       [0.46884716],\n",
       "       [0.49923098],\n",
       "       [0.48758894],\n",
       "       [0.5356054 ],\n",
       "       [0.49176592],\n",
       "       [0.5829139 ],\n",
       "       [0.57535386],\n",
       "       [0.48377675],\n",
       "       [0.4684679 ],\n",
       "       [0.5762822 ],\n",
       "       [0.45395523],\n",
       "       [0.5338486 ],\n",
       "       [0.45532614],\n",
       "       [0.53203964],\n",
       "       [0.43950415],\n",
       "       [0.57396775],\n",
       "       [0.44852918],\n",
       "       [0.53666216],\n",
       "       [0.46040195],\n",
       "       [0.57013655],\n",
       "       [0.5172525 ],\n",
       "       [0.4445578 ],\n",
       "       [0.5643342 ],\n",
       "       [0.56894994],\n",
       "       [0.46532714],\n",
       "       [0.4849912 ],\n",
       "       [0.4896775 ],\n",
       "       [0.46086085],\n",
       "       [0.51786923],\n",
       "       [0.50886565],\n",
       "       [0.4732523 ],\n",
       "       [0.58433384],\n",
       "       [0.49731225],\n",
       "       [0.45760947],\n",
       "       [0.45529234],\n",
       "       [0.586121  ],\n",
       "       [0.5483906 ],\n",
       "       [0.57934904],\n",
       "       [0.5292184 ],\n",
       "       [0.507503  ],\n",
       "       [0.46448225],\n",
       "       [0.48869908],\n",
       "       [0.55106914],\n",
       "       [0.5671568 ],\n",
       "       [0.5665699 ],\n",
       "       [0.52638674],\n",
       "       [0.57072765],\n",
       "       [0.56267107],\n",
       "       [0.5661477 ],\n",
       "       [0.44445556],\n",
       "       [0.44007242],\n",
       "       [0.4704374 ],\n",
       "       [0.5036055 ],\n",
       "       [0.47257745],\n",
       "       [0.5489425 ],\n",
       "       [0.5878068 ],\n",
       "       [0.58023447],\n",
       "       [0.51049477],\n",
       "       [0.5616669 ],\n",
       "       [0.4445004 ],\n",
       "       [0.5731932 ],\n",
       "       [0.44577324],\n",
       "       [0.50309795],\n",
       "       [0.5377734 ],\n",
       "       [0.5557824 ],\n",
       "       [0.5142989 ],\n",
       "       [0.4536587 ],\n",
       "       [0.46256465],\n",
       "       [0.45359862],\n",
       "       [0.4664638 ],\n",
       "       [0.5110539 ],\n",
       "       [0.53305125],\n",
       "       [0.58474594],\n",
       "       [0.4885931 ],\n",
       "       [0.53689766],\n",
       "       [0.47743136],\n",
       "       [0.4426893 ],\n",
       "       [0.4374742 ],\n",
       "       [0.46451205],\n",
       "       [0.5409066 ],\n",
       "       [0.489161  ],\n",
       "       [0.45906788],\n",
       "       [0.5146387 ],\n",
       "       [0.4809481 ],\n",
       "       [0.5376653 ],\n",
       "       [0.56954217],\n",
       "       [0.4724052 ],\n",
       "       [0.5084489 ],\n",
       "       [0.53899467],\n",
       "       [0.4507336 ],\n",
       "       [0.544632  ],\n",
       "       [0.5823794 ],\n",
       "       [0.49032146],\n",
       "       [0.46831018],\n",
       "       [0.56261206],\n",
       "       [0.50497866],\n",
       "       [0.45310885],\n",
       "       [0.46565986],\n",
       "       [0.47418684],\n",
       "       [0.4988464 ],\n",
       "       [0.566487  ],\n",
       "       [0.5193517 ],\n",
       "       [0.4718004 ],\n",
       "       [0.5136833 ],\n",
       "       [0.5715244 ],\n",
       "       [0.58237964],\n",
       "       [0.52930444],\n",
       "       [0.5700893 ],\n",
       "       [0.44789255],\n",
       "       [0.56990683],\n",
       "       [0.47978747],\n",
       "       [0.51103854],\n",
       "       [0.4469366 ],\n",
       "       [0.5095531 ],\n",
       "       [0.4796695 ],\n",
       "       [0.55173355],\n",
       "       [0.5612636 ],\n",
       "       [0.48061156],\n",
       "       [0.5082974 ],\n",
       "       [0.43942732],\n",
       "       [0.5878481 ],\n",
       "       [0.53996265],\n",
       "       [0.4581988 ],\n",
       "       [0.5861301 ],\n",
       "       [0.4509073 ],\n",
       "       [0.5103052 ],\n",
       "       [0.4431355 ],\n",
       "       [0.45783812],\n",
       "       [0.48165673],\n",
       "       [0.5442973 ],\n",
       "       [0.51553714],\n",
       "       [0.5721374 ],\n",
       "       [0.57358426],\n",
       "       [0.5728896 ],\n",
       "       [0.47194242],\n",
       "       [0.5495779 ],\n",
       "       [0.4569984 ],\n",
       "       [0.54184616],\n",
       "       [0.4412676 ],\n",
       "       [0.49296725],\n",
       "       [0.5821945 ],\n",
       "       [0.45009542],\n",
       "       [0.5593627 ],\n",
       "       [0.5509916 ],\n",
       "       [0.47605973],\n",
       "       [0.56897056],\n",
       "       [0.5271709 ],\n",
       "       [0.5525547 ],\n",
       "       [0.5465449 ],\n",
       "       [0.47503227],\n",
       "       [0.43715405],\n",
       "       [0.551795  ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make predictions and visualize\n",
    "\n",
    "model_3.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize this model's predictions\n",
    "# make a plotting function\n",
    "# plot our model predictions against the actual data\n",
    "\n",
    "# plot_decision_boundary() : # this function will take in a trained model features x and labels y,\n",
    "                           # create a meshgrid of the difefrent X values and make predictions\n",
    "                           # across the meshgrid, then plot the predictions as well as a line between zones ( where each unique class falls)\n",
    "            \n",
    "            \n",
    "def plot_decision_boundary(model, X, y) :\n",
    "    # plots decision boundary created by a model predicting on X\n",
    "    \n",
    "    # define the axis boundaries of the plot and create a meshgrid\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1    # we do 0.1 to give margin \n",
    "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    \n",
    "    # creating the meshgrid ( see documentation)\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), # linspace() returns evenly spaced numbers over a specified interval --> we want evenly specified numbers between x_min and x_max \n",
    "                         np.linspace(y_min, y_max, 100))  # means return 100 values evenly spaced between y_min and y_max and create a meshgrid between the two parameters\n",
    "    \n",
    "    # create X values and make predictions on these\n",
    "    x_in = np.c_[xx.ravel(), yy.ravel()] # stack 2D arrays together\n",
    "    \n",
    "    # make predictions\n",
    "    y_pred = model.predict(x_in)\n",
    "    \n",
    "    # check for multi-class classification --> if we have R, B, green circles --> multiple classes\n",
    "    \n",
    "    if len(y_pred[0]) > 1 :\n",
    "        print(\"doing multi-class classification\")\n",
    "        # we have to reshape our predictions to get them ready\n",
    "        y_pred = np.argmax(y_pred, axis = 1).reshape(xx.shape)\n",
    "    \n",
    "    else :\n",
    "        print(\"doing binary classification\")\n",
    "        y_pred = np.round(y_pred).reshape(xx.shape)\n",
    "        \n",
    "    # plotting the decision boundary\n",
    "    \n",
    "    plt.contourf(xx, yy, y_pred, cmap = plt.cm.RdYlBu, alpha = 0.7)\n",
    "    plt.scatter(X[ :, 0], X[ :, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doing binary classification\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plotting \n",
    "# decision boundary -> cut off point between the decisions it is making red and blue dots  \n",
    "plot_decision_boundary(model = model_3, X = X, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the above plot shows that our model is trying to make a straight line through the data\n",
    "# we have got circular data, so the issu here is that our data is not separable by a staright line\n",
    "# if we do regression problem --> model can work because it is drawing a straight line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-1.1595024599098636,\n",
       " 1.1337117525463374,\n",
       " -1.1677683182718437,\n",
       " 1.1360036756154805)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1   # we do 0.1 to give margin \n",
    "\n",
    "y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
    "    \n",
    "x_min, x_max, y_min, y_max   # these are the boundaries to create our meshgrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as our model is drawing a straight line --> can we adopt it to a regression problem\n",
    "# it is predicting that the decision boundary is linear, a straight(linear) line but our data is circular or non-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
       " array([  0,   5,  10,  15,  20,  25,  30,  35,  40,  45,  50,  55,  60,\n",
       "         65,  70,  75,  80,  85,  90,  95, 100, 105, 110, 115, 120, 125,\n",
       "        130, 135, 140, 145, 150, 155, 160, 165, 170, 175, 180, 185, 190,\n",
       "        195, 200, 205, 210, 215, 220, 225, 230, 235, 240, 245, 250, 255,\n",
       "        260, 265, 270, 275, 280, 285, 290, 295, 300, 305, 310, 315, 320,\n",
       "        325, 330, 335, 340, 345, 350, 355, 360, 365, 370, 375, 380, 385,\n",
       "        390, 395, 400, 405, 410, 415, 420, 425, 430, 435, 440, 445, 450,\n",
       "        455, 460, 465, 470, 475, 480, 485, 490, 495, 500, 505, 510, 515,\n",
       "        520, 525, 530, 535, 540, 545, 550, 555, 560, 565, 570, 575, 580,\n",
       "        585, 590, 595, 600, 605, 610, 615, 620, 625, 630, 635, 640, 645,\n",
       "        650, 655, 660, 665, 670, 675, 680, 685, 690, 695, 700, 705, 710,\n",
       "        715, 720, 725, 730, 735, 740, 745, 750, 755, 760, 765, 770, 775,\n",
       "        780, 785, 790, 795, 800, 805, 810, 815, 820, 825, 830, 835, 840,\n",
       "        845, 850, 855, 860, 865, 870, 875, 880, 885, 890, 895, 900, 905,\n",
       "        910, 915, 920, 925, 930, 935, 940, 945, 950, 955, 960, 965, 970,\n",
       "        975, 980, 985, 990, 995])>,\n",
       " <tf.Tensor: shape=(200,), dtype=int32, numpy=\n",
       " array([ 100,  105,  110,  115,  120,  125,  130,  135,  140,  145,  150,\n",
       "         155,  160,  165,  170,  175,  180,  185,  190,  195,  200,  205,\n",
       "         210,  215,  220,  225,  230,  235,  240,  245,  250,  255,  260,\n",
       "         265,  270,  275,  280,  285,  290,  295,  300,  305,  310,  315,\n",
       "         320,  325,  330,  335,  340,  345,  350,  355,  360,  365,  370,\n",
       "         375,  380,  385,  390,  395,  400,  405,  410,  415,  420,  425,\n",
       "         430,  435,  440,  445,  450,  455,  460,  465,  470,  475,  480,\n",
       "         485,  490,  495,  500,  505,  510,  515,  520,  525,  530,  535,\n",
       "         540,  545,  550,  555,  560,  565,  570,  575,  580,  585,  590,\n",
       "         595,  600,  605,  610,  615,  620,  625,  630,  635,  640,  645,\n",
       "         650,  655,  660,  665,  670,  675,  680,  685,  690,  695,  700,\n",
       "         705,  710,  715,  720,  725,  730,  735,  740,  745,  750,  755,\n",
       "         760,  765,  770,  775,  780,  785,  790,  795,  800,  805,  810,\n",
       "         815,  820,  825,  830,  835,  840,  845,  850,  855,  860,  865,\n",
       "         870,  875,  880,  885,  890,  895,  900,  905,  910,  915,  920,\n",
       "         925,  930,  935,  940,  945,  950,  955,  960,  965,  970,  975,\n",
       "         980,  985,  990,  995, 1000, 1005, 1010, 1015, 1020, 1025, 1030,\n",
       "        1035, 1040, 1045, 1050, 1055, 1060, 1065, 1070, 1075, 1080, 1085,\n",
       "        1090, 1095])>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using the above model for a regression problem\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# creating regression data\n",
    "\n",
    "X_regression = tf.range(0, 1000, 5)\n",
    "y_regression = tf.range(100, 1100, 5) # y = X + 100\n",
    "\n",
    "X_regression, y_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    F:\\saicharan\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    F:\\saicharan\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    F:\\saicharan\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_7 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-2780ea8be425>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# fit model of classification to regression data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mmodel_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_reg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_reg_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 _r=1):\n\u001b[0;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3036\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m-> 3038\u001b[1;33m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[0;32m   3039\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3457\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3458\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m-> 3459\u001b[1;33m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[0;32m   3460\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[1;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[0;32m   3379\u001b[0m           expand_composites=True)\n\u001b[0;32m   3380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3381\u001b[1;33m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[0;32m   3382\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0;32m   3383\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3296\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3297\u001b[0m     graph_function = ConcreteFunction(\n\u001b[1;32m-> 3298\u001b[1;33m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[0;32m   3299\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3300\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1007\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1008\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1009\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    666\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m           \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    992\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    993\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 994\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    995\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py:853 train_function  *\n        return step_function(self, iterator)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py:842 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    F:\\saicharan\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:1286 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    F:\\saicharan\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:2849 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    F:\\saicharan\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py:3632 _call_for_each_replica\n        return fn(*args, **kwargs)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py:835 run_step  **\n        outputs = model.train_step(data)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py:787 train_step\n        y_pred = self(x, training=True)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\base_layer.py:1020 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    F:\\saicharan\\lib\\site-packages\\keras\\engine\\input_spec.py:250 assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer sequential_7 is incompatible with the layer: expected axis -1 of input shape to have value 2 but received input with shape (None, 1)\n"
     ]
    }
   ],
   "source": [
    "# split our regression data into training and test sets\n",
    "\n",
    "X_reg_train = X_regression[:150]\n",
    "X_reg_test = X_regression[150:]\n",
    "y_reg_train = Y_regression[:150]\n",
    "y_reg_test = y_regression[150:]\n",
    "\n",
    "\n",
    "# fit model of classification to regression data\n",
    "\n",
    "model_3.fit(X_reg_train, y_reg_train, epochs = 100)  \n",
    "\n",
    "# this will give error because of shape issue\n",
    "# because the model was compiled for binary classification problem but we tried it on regression problem\n",
    "# loss function was BinaryCrossentropy()\n",
    "\n",
    "# so we change our loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5/5 [==============================] - 1s 8ms/step - loss: 248.2155 - mae: 248.2155\n",
      "Epoch 2/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 138.9005 - mae: 138.9005\n",
      "Epoch 3/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 53.1039 - mae: 53.1039\n",
      "Epoch 4/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 73.5170 - mae: 73.5170\n",
      "Epoch 5/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 71.2358 - mae: 71.2358\n",
      "Epoch 6/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 47.0040 - mae: 47.0040\n",
      "Epoch 7/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 45.9386 - mae: 45.9386\n",
      "Epoch 8/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 42.3638 - mae: 42.3638\n",
      "Epoch 9/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 43.6831 - mae: 43.6831\n",
      "Epoch 10/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 42.6198 - mae: 42.6198\n",
      "Epoch 11/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 42.4797 - mae: 42.4797\n",
      "Epoch 12/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.5537 - mae: 41.5537\n",
      "Epoch 13/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 42.0972 - mae: 42.0972\n",
      "Epoch 14/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 41.8647 - mae: 41.8647\n",
      "Epoch 15/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.5342 - mae: 41.5342\n",
      "Epoch 16/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.4028 - mae: 41.4028\n",
      "Epoch 17/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.6887 - mae: 41.6887\n",
      "Epoch 18/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.6137 - mae: 41.6137\n",
      "Epoch 19/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.2796 - mae: 41.2796\n",
      "Epoch 20/100\n",
      "5/5 [==============================] - 0s 6ms/step - loss: 41.1947 - mae: 41.1947\n",
      "Epoch 21/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.2130 - mae: 41.2130\n",
      "Epoch 22/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.0893 - mae: 41.0893\n",
      "Epoch 23/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.2019 - mae: 41.2019\n",
      "Epoch 24/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.9989 - mae: 40.9989\n",
      "Epoch 25/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.0131 - mae: 41.0131\n",
      "Epoch 26/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.0654 - mae: 41.0654\n",
      "Epoch 27/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 40.8764 - mae: 40.8764\n",
      "Epoch 28/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.0545 - mae: 41.0545\n",
      "Epoch 29/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.0480 - mae: 41.0480\n",
      "Epoch 30/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.8807 - mae: 40.8807\n",
      "Epoch 31/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.2695 - mae: 41.2695\n",
      "Epoch 32/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.9949 - mae: 40.9949\n",
      "Epoch 33/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 41.0760 - mae: 41.0760\n",
      "Epoch 34/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.2471 - mae: 41.2471\n",
      "Epoch 35/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.6102 - mae: 40.6102\n",
      "Epoch 36/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.1093 - mae: 41.1093\n",
      "Epoch 37/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.8191 - mae: 40.8191\n",
      "Epoch 38/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 40.2485 - mae: 40.2485\n",
      "Epoch 39/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 41.0625 - mae: 41.0625\n",
      "Epoch 40/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.5311 - mae: 40.5311\n",
      "Epoch 41/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.5497 - mae: 40.5497\n",
      "Epoch 42/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.4322 - mae: 40.4322\n",
      "Epoch 43/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.5367 - mae: 40.5367\n",
      "Epoch 44/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 40.2487 - mae: 40.2487\n",
      "Epoch 45/100\n",
      "5/5 [==============================] - 0s 5ms/step - loss: 40.5152 - mae: 40.5152\n",
      "Epoch 46/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.3702 - mae: 40.3702\n",
      "Epoch 47/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.4769 - mae: 40.4769\n",
      "Epoch 48/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.1532 - mae: 40.1532\n",
      "Epoch 49/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.7291 - mae: 40.7291\n",
      "Epoch 50/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.1536 - mae: 40.1536\n",
      "Epoch 51/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.2711 - mae: 40.2711\n",
      "Epoch 52/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.6572 - mae: 40.6572\n",
      "Epoch 53/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.6573 - mae: 40.6573\n",
      "Epoch 54/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.6894 - mae: 40.6894\n",
      "Epoch 55/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.2771 - mae: 41.2771\n",
      "Epoch 56/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 41.8519 - mae: 41.8519\n",
      "Epoch 57/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.7903 - mae: 40.7903\n",
      "Epoch 58/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.3128 - mae: 40.3128\n",
      "Epoch 59/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.7198 - mae: 40.7198\n",
      "Epoch 60/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.1478 - mae: 40.1478\n",
      "Epoch 61/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.1117 - mae: 40.1117\n",
      "Epoch 62/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 40.7800 - mae: 40.7800\n",
      "Epoch 63/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 39.7242 - mae: 39.7242\n",
      "Epoch 64/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 40.1465 - mae: 40.1465\n",
      "Epoch 65/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.6887 - mae: 39.6887\n",
      "Epoch 66/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.2840 - mae: 40.2840\n",
      "Epoch 67/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.5541 - mae: 39.5541\n",
      "Epoch 68/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 39.7378 - mae: 39.7378\n",
      "Epoch 69/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 39.9784 - mae: 39.9784\n",
      "Epoch 70/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.0016 - mae: 40.0016\n",
      "Epoch 71/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 40.0913 - mae: 40.0913\n",
      "Epoch 72/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.2547 - mae: 39.2547\n",
      "Epoch 73/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 39.6828 - mae: 39.6828\n",
      "Epoch 74/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 39.5373 - mae: 39.5373\n",
      "Epoch 75/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.6265 - mae: 39.6265\n",
      "Epoch 76/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 39.3110 - mae: 39.3110\n",
      "Epoch 77/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.1599 - mae: 39.1599\n",
      "Epoch 78/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.7550 - mae: 39.7550\n",
      "Epoch 79/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.2542 - mae: 39.2542\n",
      "Epoch 80/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 38.6968 - mae: 38.6968\n",
      "Epoch 81/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.5442 - mae: 39.5442\n",
      "Epoch 82/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 39.8686 - mae: 39.8686\n",
      "Epoch 83/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 39.1693 - mae: 39.1693\n",
      "Epoch 84/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.8840 - mae: 38.8840\n",
      "Epoch 85/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.8887 - mae: 38.8887\n",
      "Epoch 86/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.6614 - mae: 38.6614\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 3ms/step - loss: 38.8399 - mae: 38.8399\n",
      "Epoch 88/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.6604 - mae: 38.6604\n",
      "Epoch 89/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.7559 - mae: 38.7559\n",
      "Epoch 90/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 38.5442 - mae: 38.5442\n",
      "Epoch 91/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.3247 - mae: 38.3247\n",
      "Epoch 92/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.8431 - mae: 38.8431\n",
      "Epoch 93/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 39.1137 - mae: 39.1137\n",
      "Epoch 94/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 38.1463 - mae: 38.1463\n",
      "Epoch 95/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.3998 - mae: 38.3998\n",
      "Epoch 96/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.5599 - mae: 38.5599\n",
      "Epoch 97/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.1038 - mae: 38.1038\n",
      "Epoch 98/100\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 39.0081 - mae: 39.0081\n",
      "Epoch 99/100\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 38.3056 - mae: 38.3056\n",
      "Epoch 100/100\n",
      "5/5 [==============================] - 0s 4ms/step - loss: 37.9976 - mae: 37.9976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28a4ed7fa00>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the loss function in mosdel 3 so that loss function is regression specific\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model_3 = tf.keras.Sequential([\n",
    "          tf.keras.layers.Dense(100),\n",
    "          tf.keras.layers.Dense(10),\n",
    "          tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_3.compile(loss = tf.keras.losses.mae,\n",
    "                optimizer = tf.keras.optimizers.Adam(),\n",
    "                metrics = [\"mae\"])\n",
    "\n",
    "model_3.fit(X_reg_train, y_reg_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 57.8926 - mae: 57.8926\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[57.892578125, 57.892578125]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(X_reg_test, y_reg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x28a4eafeeb0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot regression data,\n",
    "# make predictions with the trained model\n",
    "y_reg_pred = model_3.predict(X_reg_test)\n",
    "\n",
    "# plot the model's predictions against the regression data\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(X_reg_train, y_reg_train, c=\"b\", label = \"Training data\")\n",
    "plt.scatter(X_reg_test, y_reg_test, c=\"g\", label = \"Testing data\")\n",
    "plt.scatter(X_reg_test, y_reg_pred, c = \"r\", label = \"Predictions\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this regression is a straght line, but our classification data is not a straight line, not linear --> \n",
    "# but the decision boundary our model is trying to plot is linear, straight line\n",
    "# we have not included non-linearity in our model for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00_tensorflow_fund.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
