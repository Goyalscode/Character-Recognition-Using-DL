{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0xzVEmWP8mMu"
   },
   "source": [
    "# fundamental concepts of tensors usig tensorflow\n",
    "* intro to tensors\n",
    "* information from tensors\n",
    "* manipulating tensors\n",
    "* tensors and numpy\n",
    "* using @tf.function ( a way to speed up regular python functions)\n",
    "* using gpus with tensorflow (or tpus) for faster numerical computaion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej9c3PGR-1b7"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5hNDTWY9SCw"
   },
   "source": [
    "*italicized text*# intro to tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fee2jBYS_-Eb"
   },
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__) # for checking the version of tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5M96xDSBA0EX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=7>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## create tensors with tf.constant()\n",
    "import tensorflow as tf\n",
    "scalar  = tf.constant(7)\n",
    "scalar\n",
    "\n",
    "# commands - ctrl + MM  - markdown cell, ctrl + my - code cell\n",
    "#            ctrl + MB - new cell\n",
    "#            ctrl + shift + space - info about a command\n",
    "\n",
    "## tensorflow has inbuilt modules which are able to read in data sorces such as how many diiferent images \n",
    "## and automatically convert them into tensors and later on the neural network model \n",
    "## will process these tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZfYgV62UEL_O",
    "outputId": "415ab951-9c48-4b8f-86e3-df44edc84dc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check no of dimensions of a tensor ( ndim stands for no of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxdhoVJ6EXxD",
    "outputId": "db48ae64-ac59-4ec7-986c-e735f95bac95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10])>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a vector\n",
    "vector = tf.constant([10, 10])\n",
    "vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IPI1f-yzErMe",
    "outputId": "8812990b-cd23-4135-d464-4bb3aa90692d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check dimensions of a vector\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mUzPAe6sEzgr",
    "outputId": "f568ced0-2949-4ff3-9e30-66d9ded7d2be"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[11,  7],\n",
       "       [ 7, 11]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# create a matrix ( has more than 1 dimension)\n",
    "import tensorflow as tf\n",
    "matrix = tf.constant([[11, 7],\n",
    "                      [7, 11]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "VgBcJ8xfFK4k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in f:\\saicharan\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.37.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.39.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in f:\\saicharan\\lib\\site-packages (from tensorflow) (0.13.0)\n",
      "Requirement already satisfied: tensorflow-estimator~=2.6 in f:\\saicharan\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: wheel~=0.35 in f:\\saicharan\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in c:\\users\\dell\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in f:\\saicharan\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: gast==0.4.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: tensorboard~=2.6 in f:\\saicharan\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: keras~=2.6 in f:\\saicharan\\lib\\site-packages (from tensorflow) (2.6.0)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: six~=1.15.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in f:\\saicharan\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in f:\\saicharan\\lib\\site-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: h5py~=3.1.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: clang~=5.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (5.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: numpy~=1.19.2 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.19.5)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in f:\\saicharan\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in f:\\saicharan\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in f:\\saicharan\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in f:\\saicharan\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in f:\\saicharan\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in f:\\saicharan\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in f:\\saicharan\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in f:\\saicharan\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in f:\\saicharan\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in f:\\saicharan\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\saicharan\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in f:\\saicharan\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    " pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[11,  7],\n",
       "       [ 7, 11]])>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a matrix ( has more than 1 dimension)\n",
    "import tensorflow as tf\n",
    "matrix = tf.constant([[11, 7],\n",
    "                      [7, 11]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-f2cc0e3c08ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtensorflw\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_version_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflw'"
     ]
    }
   ],
   "source": [
    "import tensorflw as tf\n",
    "print(tf._version_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensors with tf.constant()\n",
    "scalar = tf.constant(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the number of dimnsions of a tensor ( ndim stands for number of dimensions)\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([10, 10])>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a vector\n",
    "vector = tf.constant([10, 10])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the dimnsion of our vector\n",
    "vector.ndim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 7, 10]])>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a matrix(has more tahn 1 dimension)\n",
    "matrix = tf.constant([[10, 7],\n",
    "                    [7, 10]])\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float16, numpy=\n",
       "array([[10.,  7.],\n",
       "       [ 3.,  2.],\n",
       "       [ 8.,  9.]], dtype=float16)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create anothe rmatrix\n",
    "another_matrix = tf.constant([[10., 7.],\n",
    "                             [3., 2.],\n",
    "                             [8., 9.]], dtype=tf.float16)  # specify the data type with the dytpe parameter\n",
    "another_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "another_matrix.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-24-4ed3bdee1d9a>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-24-4ed3bdee1d9a>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    total no of dimensions = no of elements in shape\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "total no of dimensions = no of elements in shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]],\n",
       "\n",
       "       [[13, 14, 15],\n",
       "        [16, 17, 18]]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how to increase the number ofdiensions\n",
    "# lets create a tensor\n",
    "# a tensor\n",
    "tensor = tf.constant([[[1, 2, 3],\n",
    "                     [4, 5, 6]],\n",
    "                     [[7, 8, 9],\n",
    "                    [10, 11, 12]],\n",
    "                     [[13, 14, 15],\n",
    "                     [16, 17, 18]]])\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# what we've created so far\n",
    "\n",
    "* Scalar : a single number\n",
    "* Vector : a number with direction (eg wind speed and direction)\n",
    "* matrix : a 2-dimensional array of numbers\n",
    "* Tenso : an n-dimensional array of numbers ( when n can be any number, a 0-dimensional tensor is a scalar, a 1-dimensional tensor is a vector)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Variable 'Variable:0' shape=(2,) dtype=int32, numpy=array([10,  7])>,\n",
       " <tf.Tensor: shape=(2,), dtype=int32, numpy=array([10,  7])>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating tensors with tf.variable\n",
    "changeable_tensor = tf.Variable([10, 7])\n",
    "unchangeable_tensor = tf.constant([10, 7])\n",
    "changeable_tensor, unchangeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ResourceVariable' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-df74dc611499>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#lets try change one of the elements in our changeable vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mchangeable_tensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mchangeable_tensor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'ResourceVariable' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "#lets try change one of the elements in our changeable vector\n",
    "changeable_tensor[0] = 7\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trying .assign()\n",
    "changeable_tensor[0].assign(7)\n",
    "changeable_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try to change unchangeable tensor\n",
    "unchangeable_tensor[0].assign(7)\n",
    "unchangeable_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating random tensors\n",
    "random tensors are tensors of some arbitrary size which contains random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create two random tensors\n",
    "random_1= tf.random.Generator.from_seed(4) # set seed for reproducibility\n",
    "random_1 = random_1.normal(shape=(3,2))\n",
    "random_1\n",
    "random_2 = tf.random.Generator.from_seed(4)\n",
    "random_2 = random_2.normal(shape=(3, 2))\n",
    "random_1, random_2, random_1 == random_2\n",
    "\n",
    "# they have come from a normal distrbution\n",
    "\n",
    "# they are pseudo random numbers\n",
    "# settig the seed -> create randm numbers but flavour them with x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  shuffle the order of elements in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle a tensor ( valuable for when you  want to shuffle your data so that inherent order does not affect learning)\n",
    "not_shuffled = tf.constant([[10, 7],\n",
    "                          [3, 4],\n",
    "                          [2, 5]])\n",
    "not_shuffled.ndim\n",
    "\n",
    "# shuffle our non-shffled tensor\n",
    "tf.random.shuffle(not_shuffled)  # shuffles elements along its first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffle our non-shffled tensor\n",
    "tf.random.shuffle(not_shuffled)  # shuffles elements along its first dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [ 3,  4],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using seed\n",
    "# shuffle our non-shffled tensor\n",
    "tf.random.shuffle(not_shuffled, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 2,  5],\n",
       "       [ 3,  4],\n",
       "       [10,  7]])>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.shuffle(not_shuffled, seed = 42)  # gives differen result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42) \n",
    "tf.random.shuffle(not_shuffled, seed = 42)  # gives same order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read through tensorflow documentation on random seed generator\n",
    "# write 5 random tansors and shuffle them\\\n",
    "\n",
    "# operational and global level random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main aim to shuffle the order of tensors is --> for classification neural networks -> any kind of images first may learn only one type of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-35-b66b7616e12f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-35-b66b7616e12f>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    tf.random.shuffle(not_shuffled, seed = 42)  3 we get a different order each time\u001b[0m\n\u001b[1;37m                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "tf.random.shuffle(not_shuffled, seed = 42)  3 we get a different order each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4],\n",
       "       [ 2,  5]])>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using global radom seed \n",
    "tf.random.set_seed(42) # --> gives same order\n",
    "tf.random.shuffle(not_shuffled, seed = 42)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if we want our shuffled tensors to be in the same order , we have to use the global level random seed as well as the operational level random seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### other ways to make tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 7), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all ones\n",
    "tf.ones([10, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor of all zeroes\n",
    "tf.zeros(shape=(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-39-7d4003424638>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-39-7d4003424638>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    main differencce NumPy arrays and TensorFlow tensors is that tensors can be run on a GPU ( must faster for numerical computing)\u001b[0m\n\u001b[1;37m         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "### turn numpy arrays into tensors\n",
    "\n",
    "main differencce NumPy arrays and TensorFlow tensors is that tensors can be run on a GPU ( must faster for numerical computing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can also turn NumPy arrays into tensors\n",
    "import numpy as np\n",
    "numpy_A = np.arange(1, 25, dtype = np.int32) # create a NumPy array between 1 and 25\n",
    "numpy_A\n",
    "\n",
    "# X = tf.constant(some_matrix) # capital for matrix or tensor\n",
    "# y = tf.constant(vector)  # non-capital for vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       "array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = tf.constant(numpy_A)\n",
    "A\n",
    "\n",
    "# converted NumPy rray into a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 8), dtype=int32, numpy=\n",
       " array([[ 1,  2,  3,  4,  5,  6,  7,  8],\n",
       "        [ 9, 10, 11, 12, 13, 14, 15, 16],\n",
       "        [17, 18, 19, 20, 21, 22, 23, 24]])>,\n",
       " <tf.Tensor: shape=(24,), dtype=int32, numpy=\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24])>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing shape --> its shape is 24 if we want it into a 3-dimensional tensor\n",
    "2*3*4\n",
    "A = tf.constant(numpy_A, shape = (3, 8))  # 3 rows and 8 elements in one column\n",
    "A  # this would be a tensor becoz it has got more than 1 dimension \n",
    "B= tf.constant(numpy_A)  # this is a vector\n",
    "A, B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting informatin from tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_A.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NumPy arrays are a very common form of representing numerical data --> can be converted into tensors\n",
    "\n",
    "basic difference beteween numpy array and tensorflow tensor --> although they may store the same information here \n",
    "a tensor formmat can run on a gpu and finding pattrens in numerial data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### want to get attribute s of tensors\n",
    "\n",
    "When dealing with tensors want to be aware of the following attributes ->\n",
    "* Shape - the length of each of the dimensions of a tensor\n",
    "* Rank - the number of tensor dimensions . A scalar has rank 0, a vector has rank 1, a matrix has rank 2 , a tensor has rank n\n",
    "* Axis or dimension - a particular dimension of a tensor --> tensor[0], tensor[:, 1]...\n",
    "* Size - the total number of items in a tensor tf.size(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3, 4, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a rank 4 matrix --> 4 dimensions\n",
    "rank_4_tensor = tf.zeros(shape = [2, 3, 4, 5])\n",
    "rank_4_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# when you pass a tensor into a neural network --> has to be in a certain shape and output also has to be in a certain shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 4, 5), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[0][1][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank_4_tensor[0][1][4] -->gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3, 4, 5]), 4, <tf.Tensor: shape=(), dtype=int32, numpy=120>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor.shape, rank_4_tensor.ndim, tf.size(rank_4_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype of every element <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (2, 3, 4, 5)\n",
      "elemnts along the 0 axis: 2\n",
      "elements along the last axis: 5\n",
      "Total number of elemnts in our tensor: tf.Tensor(120, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# fget various attributes of our tensors\n",
    "print(\"datatype of every element\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"elemnts along the 0 axis:\",rank_4_tensor.shape[0])\n",
    "print(\"elements along the last axis:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elemnts in our tensor:\", tf.size(rank_4_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datatype of every element <dtype: 'float32'>\n",
      "Number of dimensions (rank): 4\n",
      "Shape of tensor: (2, 3, 4, 5)\n",
      "elemnts along the 0 axis: 2\n",
      "elements along the last axis: 5\n",
      "Total number of elemnts in our tensor: tf.Tensor(120, shape=(), dtype=int32)\n",
      "Total number of elemnts in our tensor: 120\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"datatype of every element\", rank_4_tensor.dtype)\n",
    "print(\"Number of dimensions (rank):\", rank_4_tensor.ndim)\n",
    "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
    "print(\"elemnts along the 0 axis:\",rank_4_tensor.shape[0])\n",
    "print(\"elements along the last axis:\", rank_4_tensor.shape[-1])\n",
    "print(\"Total number of elemnts in our tensor:\", tf.size(rank_4_tensor))\n",
    "print(\"Total number of elemnts in our tensor:\", tf.size(rank_4_tensor).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing tensors\n",
    "\n",
    "Tensors can be indexed like python lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = [1, 2, 3, 4]\n",
    "some_list[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 2, 2), dtype=float32, numpy=\n",
       "array([[[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0.],\n",
       "         [0., 0.]],\n",
       "\n",
       "        [[0., 0.],\n",
       "         [0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first 2 elements of each dimension\n",
    "rank_4_tensor[:2, :2, :2, :2] # we seaparate the dimensions by commas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the first element from each dimension frome each index except for the final one\n",
    "rank_4_tensor[:1, :1, :1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 5), dtype=float32, numpy=array([[[[0., 0., 0., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:1, :1, :1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 4, 1), dtype=float32, numpy=\n",
       "array([[[[0.],\n",
       "         [0.],\n",
       "         [0.],\n",
       "         [0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:1, :1, :, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 1, 1), dtype=float32, numpy=\n",
       "array([[[[0.]]],\n",
       "\n",
       "\n",
       "       [[[0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_4_tensor[:, :1, :1, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 2]), 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a rank 2 tensor (2 dimensions)\n",
    "rank_2_tensor = tf.constant([[10, 7],\n",
    "                           [3, 4]])\n",
    "rank_2_tensor\n",
    "rank_2_tensor.shape, rank_2_tensor.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4], 4, [1, 2, 3])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list, some_list[-1], some_list[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([7, 4])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the last item of eah row of rank_2_matrix\n",
    "rank_2_tensor[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=int32, numpy=\n",
       "array([[10],\n",
       "       [ 3]])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if we want to add an extra dimension to this tensor\n",
    "# we may need to alter the size of our tensors so that their shape line up\n",
    "\n",
    "# add in extra dimension to our rank 2 tensor but information should be same\n",
    "rank_3_tensor = rank_2_tensor[..., tf.newaxis]\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_3_tensor = rank_2_tensor[:, :, tf.newaxis]\n",
    "rank_3_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 1), dtype=int32, numpy=\n",
       "array([[[10],\n",
       "        [ 7]],\n",
       "\n",
       "       [[ 3],\n",
       "        [ 4]]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternative to tf.newaxis\n",
    "tf.expand_dims(rank_2_tensor, axis=-1) # \"-1\" means expand the final axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1, 2), dtype=int32, numpy=\n",
       "array([[[10,  7]],\n",
       "\n",
       "       [[ 3,  4]]])>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=1) #extra dimension u=in the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2, 2), dtype=int32, numpy=\n",
       "array([[[10,  7],\n",
       "        [ 3,  4]]])>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(rank_2_tensor, axis=0) # expand the 0-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rank_2_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# how the numbers are stored changes just in changing dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manipulating tensors (tensor operations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[20, 17],\n",
       "        [13, 14]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[10,  7],\n",
       "        [ 3,  4]])>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can add values to a tensor using the addition operator\n",
    "tensor = tf.constant([[10, 7], [3,4]])\n",
    "tensor + 10, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor+=20\n",
    "tensor\n",
    "tensor-=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 0, -3],\n",
       "       [-7, -6]])>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  70],\n",
       "       [ 30,  40]])>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can use the tensorflow built-in function too\n",
    "tf.multiply(tensor, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[10,  7],\n",
       "       [ 3,  4]])>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Matrix Multiplication\n",
    "In machine learning, matrix multiplication is one of the most common tensor operations\n",
    "1. the inner dimnsions must match\n",
    "2. the resulting matrix has shape of the outer dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10  7]\n",
      " [ 3  4]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# matrix multiplication in tensorflow\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[121,  98],\n",
       "       [ 42,  37]])>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[100,  49],\n",
       "       [  9,  16]])>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor * tensor  # it is element wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-79-4b7b1ef36c31>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-79-4b7b1ef36c31>\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    tensor @ tensor  used for matricx multiplication\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# matricx multiplication with python operator \"@\"\n",
    "tensor @ tensor  used for matricx multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([2, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       "array([[ 7, 16],\n",
       "       [27, 40],\n",
       "       [55, 72]])>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with different shapes\n",
    "# create a tensor (3, 2) tensor\n",
    "X = tf.constant([[1, 2],\n",
    "                 [3, 4],\n",
    "                [5, 6]])\n",
    "Y = tf.constant([[7, 8],\n",
    "                 [9, 10],\n",
    "                [11, 12]])\n",
    "X*Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X , Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "In[0] mismatch In[1] shape: 2 vs. 3: [3,2] [3,2] 0 0 [Op:MatMul]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-603b9dc11460>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Matrix multilpy tensors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1365\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1367\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1368\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul_wrapper\u001b[1;34m(a, b, name)\u001b[0m\n\u001b[0;32m   3761\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_style_type_promotion\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3762\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3763\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3764\u001b[0m \u001b[0mmatmul_wrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3765\u001b[0m \u001b[0m_OverrideBinaryOperatorHelper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatmul_wrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"matmul\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3652\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[0;32m   3653\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3654\u001b[1;33m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[0;32m   3655\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0;32m   3656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   5693\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5694\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5695\u001b[1;33m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5696\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5697\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   6939\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6940\u001b[0m   \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6941\u001b[1;33m   \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6942\u001b[0m   \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: In[0] mismatch In[1] shape: 2 vs. 3: [3,2] [3,2] 0 0 [Op:MatMul]"
     ]
    }
   ],
   "source": [
    "#Matrix multilpy tensors\n",
    "X @ Y\n",
    "tf.multiply(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# have to change the shape of either matrix\n",
    "# or cretae new matrice sof same shape\n",
    "\n",
    "# lets change the shape of y\n",
    "tf.reshape(Y, shape = (2,3)), Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, tf.reshape(Y, shape = (2, 3)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]])>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to multiply X by reshaped y\n",
    "X @ tf.reshape(Y, shape = (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]])>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, tf.reshape(Y, shape = (2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([3, 2]),\n",
       " TensorShape([3, 2]),\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[ 58,  64],\n",
       "        [139, 154]])>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping X\n",
    "X.shape, Y.shape, tf.matmul(tf.reshape(X, shape=(2, 3)), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 3, 5],\n",
       "        [2, 4, 6]])>,\n",
       " <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       " array([[1, 2, 3],\n",
       "        [4, 5, 6]])>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can do the same wwith transpose\n",
    "X, tf.transpose(X), tf.reshape(X ,shape=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose --> flips the axes rather than shuffling elements of tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       "array([[ 89,  98],\n",
       "       [116, 128]])>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try matricx mult with transpose rather than reshape\n",
    "tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** the dot product\n",
    "matricx multis also referred to as the dot product\n",
    "can perform mat mult using -->\n",
    "* tf.matmul()\n",
    "* tf.tensordot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])>,\n",
       " <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
       " array([[ 7,  8],\n",
       "        [ 9, 10],\n",
       "        [11, 12]])>)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[ 89,  98],\n",
       "        [116, 128]])>,\n",
       " <tf.Tensor: shape=(2, 2), dtype=int32, numpy=\n",
       " array([[ 89,  98],\n",
       "        [116, 128]])>)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform the dot product on X and Y ( requires X or Y to be transposed)\n",
    "# transposiing( flipping the axis) results in different outputs rather than reshaping ( reshuffling)\n",
    "\n",
    "tf.tensordot(tf.transpose(X), Y, axes = 1), tf.matmul(tf.transpose(X), Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]])>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perfor mat mult bet x and y(transposed)\n",
    "tf.matmul(X, tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 27,  30,  33],\n",
       "       [ 61,  68,  75],\n",
       "       [ 95, 106, 117]])>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform mat ult bet x and y (reshaped)\n",
    "tf.matmul(X, tf.reshape(Y, shape=(2, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norml Y\n",
      " tf.Tensor(\n",
      "[[ 7  8]\n",
      " [ 9 10]\n",
      " [11 12]], shape=(3, 2), dtype=int32)\n",
      "Y reshaped to (2, 3) : \n",
      "tf.Tensor(\n",
      "[[ 7  8  9]\n",
      " [10 11 12]], shape=(2, 3), dtype=int32) \n",
      "\n",
      "Y transposed\n",
      "tf.Tensor(\n",
      "[[ 7  9 11]\n",
      " [ 8 10 12]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# check the values of y, reshape Y, transposed Y\n",
    "print(\"Norml Y\\n\", Y)\n",
    "print(\"Y reshaped to (2, 3) : \")\n",
    "print(tf.reshape(Y, (2, 3)), \"\\n\")\n",
    "print(\"Y transposed\")\n",
    "print(tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int32, numpy=\n",
       "array([[ 23,  29,  35],\n",
       "       [ 53,  67,  81],\n",
       "       [ 83, 105, 127]])>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, tf.transpose(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# which one to use - transpose or reshape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally , when performing matrix mltiplication on two tensors , and one of the axes does'nt line up, use transpose, rather than reshape to satisfy multiplication rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.float32"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### changing the dataype of a tensor\n",
    "# generally default datatpe of tensors will be int32\n",
    "\n",
    "# create a tensor with dafault datatype ( float 32)\n",
    "B = tf.constant([1.7, 7.4])\n",
    "B.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tf.int32"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = tf.constant(([7, 10]))\n",
    "C.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float16, numpy=array([1.7, 7.4], dtype=float16)>,\n",
       " tf.float16)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change from float 32 to float 16\n",
    "D = tf.cast(B, dtype = tf.float16)\n",
    "D, D.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2,), dtype=float32, numpy=array([ 7., 10.], dtype=float32)>,\n",
       " tf.float32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change fro int32 to float32\n",
    "E = tf.cast(C , dtype = tf.float32)\n",
    "E, E.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float16, numpy=array([ 7., 10.], dtype=float16)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_float16  = tf.cast(E, dtype = tf.float16)\n",
    "E_float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensors Aggregating\n",
    "\n",
    "Aggregating tensors means condensing them from multiple values down to a smaller amount of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ -7, -10])>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---> get the absolute values\n",
    "D = tf.constant([-7, -10])\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([ 7, 10])>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.abs(D) # for getting absolute values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "other forms of aggregation\n",
    "\n",
    "* get the minimm\n",
    "* get the maximum\n",
    "* get the mean ofa tensor\n",
    "* get the sum of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([25, 86, 62, 12, 98, 40, 57, 95, 16, 74,  2, 56,  0, 30,  1, 63, 36,\n",
       "       13,  2, 15, 70, 40, 43, 97, 90, 73,  6, 67, 19, 66, 78, 10, 22, 86,\n",
       "       18, 28,  7, 64, 77,  5, 94, 40, 53, 50, 38, 78, 20, 31, 59,  8])>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a radom tensor with values between 0 and 100 of size 50\n",
    "E = tf.constant(np.random.randint(0, 100, size=50))\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=50>, 1, TensorShape([50]))"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.size(E), E.ndim, E.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# minimum of a tensor\n",
    "tf.reduce_min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in numPy\n",
    "np.min(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=98>, 98)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maximum \n",
    "tf.reduce_max(E), np.max(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=44>, 44.4)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean\n",
    "tf.reduce_mean(E), np.mean(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=2220>, 2220)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(E), np.sum(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorlflow_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=924.68>, 924.68)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## tfp means tensorflow probability\n",
    "## import tensorflow_probability as tfp\n",
    "\n",
    "## variance and stadard deviation only work with real or complex input\n",
    "# --> hence convert E to real type\n",
    "# or\n",
    "# to find variance of tensor , we need access to tensorflow_probability\n",
    "#import tensorflow_probability as tfp\n",
    "# tfp.stats.variance(E)\n",
    "\n",
    "tf.math.reduce_variance(tf.cast(E, dtype = tf.float32)), np.var(E)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input must be either real or complex",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-113-a08a9643d051>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce_std\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_std\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2693\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2694\u001b[0m     \u001b[0minput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2695\u001b[1;33m     \u001b[0mvariance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_variance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2696\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvariance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2697\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mreduce_variance\u001b[1;34m(input_tensor, axis, keepdims, name)\u001b[0m\n\u001b[0;32m   2633\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreduce_mean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2634\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_integer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2635\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Input must be either real or complex\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2636\u001b[0m     \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_tensor\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2637\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Input must be either real or complex"
     ]
    }
   ],
   "source": [
    "tf.math.reduce_std(E), np.std(E), E.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the positional maximum and minimum\n",
    "\n",
    "#### used in neural network output prediction probabilities\n",
    "#### representtion outputs are referred to as prediction probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=float32, numpy=\n",
       "array([0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "       0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "       0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "       0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "       0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "       0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "       0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "       0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "       0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "       0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensor for finding poitional min and max\n",
    "tf.random.set_seed(42)\n",
    "F = tf.random.uniform(shape=[50])\n",
    "F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=42>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at which position max elemnt occurs --> find the positional maximum\n",
    "tf.argmax(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the largest value using the index\n",
    "F[tf.argmax(F)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.9671384>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding the max value value of\n",
    "tf.reduce_max(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for equality\n",
    "F[tf.argmax(F)] == tf.reduce_max(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=16>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmin(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.009463668>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F[tf.argmin(F)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=bool, numpy=True>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_min(F) == F[tf.argmin(F)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## squeezing our tensor --> removing all single dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1, 1, 1, 50), dtype=float32, numpy=\n",
       "array([[[[[0.6645621 , 0.44100678, 0.3528825 , 0.46448255, 0.03366041,\n",
       "           0.68467236, 0.74011743, 0.8724445 , 0.22632635, 0.22319686,\n",
       "           0.3103881 , 0.7223358 , 0.13318717, 0.5480639 , 0.5746088 ,\n",
       "           0.8996835 , 0.00946367, 0.5212307 , 0.6345445 , 0.1993283 ,\n",
       "           0.72942245, 0.54583454, 0.10756552, 0.6767061 , 0.6602763 ,\n",
       "           0.33695042, 0.60141766, 0.21062577, 0.8527372 , 0.44062173,\n",
       "           0.9485276 , 0.23752594, 0.81179297, 0.5263394 , 0.494308  ,\n",
       "           0.21612847, 0.8457197 , 0.8718841 , 0.3083862 , 0.6868038 ,\n",
       "           0.23764038, 0.7817228 , 0.9671384 , 0.06870162, 0.79873943,\n",
       "           0.66028714, 0.5871513 , 0.16461694, 0.7381023 , 0.32054043]]]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "G = tf.constant(tf.random.uniform(shape=[50]), shape=(1, 1, 1, 1, 50))\n",
    "G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 1, 1, 1, 50])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 1, 1, 1, 50]), TensorShape([50]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.squeezed = tf.squeeze(G)  # removes dimensions of size 1 from shape of  atensor\n",
    "G.shape, G.squeezed.shape ## gets rid of extra dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one hot encoding tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=float32, numpy=\n",
       "array([[1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## see ml mastery for this \n",
    "# it is a form of numerical encoding\n",
    "# can one hot encode words and pass those as tensors to neural networks\n",
    "\n",
    "# create a list of indices\n",
    "some_list = [0, 1, 2, 3] # could be red, green, blue, purple\n",
    "\n",
    "\n",
    "\n",
    "# one hot encode this list of indices ---->\n",
    "tf.one_hot(some_list, depth = 4)  # depth --> usually no of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 4), dtype=string, numpy=\n",
       "array([[b'Y', b'N', b'N', b'N'],\n",
       "       [b'N', b'Y', b'N', b'N'],\n",
       "       [b'N', b'N', b'Y', b'N'],\n",
       "       [b'N', b'N', b'N', b'Y']], dtype=object)>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using custom values for one-hot encoding\n",
    "tf.one_hot(some_list, depth = 4, on_value = 'Y', off_value = 'N')   # using on_value and of_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### more math operations \n",
    "##### squaring, log, square root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7, 8, 9])>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = tf.range(1, 10)\n",
    "H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=int32, numpy=array([ 1,  4,  9, 16, 25, 36, 49, 64, 81])>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(H) ## squaring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.sqrt(H) --> gives error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.99999994, 1.4142134 , 1.7320508 , 1.9999999 , 2.236068  ,\n",
       "       2.4494896 , 2.6457512 , 2.8284268 , 3.        ], dtype=float32)>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sqrt(tf.cast(H, dtype = tf.float32)) # find root \n",
    "# sqrt requires non-int type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(9,), dtype=float32, numpy=\n",
       "array([0.       , 0.6931472, 1.0986123, 1.3862944, 1.609438 , 1.7917595,\n",
       "       1.9459102, 2.0794415, 2.1972246], dtype=float32)>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.cast(H, dtype = tf.float32))  #finding log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NumPy(fundamental package for scientific computing with python) and tensorflow\n",
    "\n",
    "**  tensorflow interacts beautifully with NumPy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=float64, numpy=array([ 3.,  7., 10.])>,\n",
       " tensorflow.python.framework.ops.EagerTensor)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a tensor directly from a NumPy array\n",
    "J = tf.constant(np.array([3., 7., 10.]))\n",
    "J, type(J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert from tensor to NumPy array\n",
    "np.array(J), type(np.array(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 3.,  7., 10.]), numpy.ndarray)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert tensor J to  anumpy array\n",
    "J.numpy(), type(J.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## useful in some of the functionalities\n",
    "J = tf.constant([3.])\n",
    "J.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tf.float64, tf.float32)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## default types of each are slightly different\n",
    "numpy_J = tf.constant(np.array([3., 7., 10.]))\n",
    "tensor_J = tf.constant([3., 7., 10.])  \n",
    "numpy_J.dtype, tensor_J.dtype\n",
    "\n",
    "# for tensor --> default type is float 32\n",
    "# for numpy array --> default type is float 64\n",
    "# NumPy - fundamental pav=ckage for scientific computing in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression --> predicting a number\n",
    "# other -> trying to predict the corners in a object detection problem\n",
    "\n",
    "\n",
    "# Regression inputs and outputs\n",
    "# some neural networks may have 1000 hidden layers\n",
    "\n",
    "# architecture of a regression model - \n",
    "# hyperparameter -> a setting that you can change as a data analyst\n",
    "\n",
    "# define our loss function --> how wrong our neural network predictions are, how wrong the relationships are \n",
    "# optimizer -> infrms neuralnetwork how to improve patterns bet input and output variables , to reduce the loss function\n",
    "# fit model -> telling model to look at bunch ofdifferent examples in the training datat for 100 laps of the data --> that's what epochs variablee stands for\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# regression with neural networls in tensorflow\n",
    "\n",
    "# predicting a numerical variable based on some other combination of variables\n",
    "\n",
    "# Importing tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22f25e67dc0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# data to view and fit\n",
    "# regression model is red line throgh the middle , blue dots are the data points\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# features --> usually denoted by X\n",
    "X = np.array([-7.0, -4.0, -1.0, 2.0, 5.0, 8.0, 11.0, 14.0])\n",
    "\n",
    "# labels--> usually denoted by y\n",
    "y = np.array([3.0, 6.0, 9.0, 12.00, 15.0, 18.0, 21.0, 24.0])\n",
    "\n",
    "# visualize the relationship\n",
    "plt.scatter(X, y)\n",
    "\n",
    "# can take X as independent varible, Y as dependent variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y == X+10 # --> this is the relationship or function bet input features(ind) and our labels(dep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=string, numpy=array([b'bedroom', b'bathroom', b'garage'], dtype=object)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([939700])>)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input and output shapes\n",
    "\n",
    "# create a demo tensor for housing price prediction tensor\n",
    "house_info = tf.constant([\"bedroom\", \"bathroom\", \"garage\"])\n",
    "house_price = tf.constant([939700])\n",
    "house_info, house_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8,), (8,), array([ 3.,  6.,  9., 12., 15., 18., 21., 24.]))"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in thiis cas we want to use X to predict y\n",
    "input_shape = X.shape\n",
    "output_shape = y.shape\n",
    "input_shape, output_shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((), ())"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we want to use one input feature of X to predict one y value\n",
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-7.0, 3.0)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model the reltionship between X and y\n",
    "\n",
    "# turn NumPy arrays into tensorswith dtype float 32\n",
    "X = tf.cast(tf.constant(X), dtype = tf.float32)\n",
    "y = tf.cast(tf.constant(y), dtype = tf.float32)\n",
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([]), TensorShape([]))"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = X[0].shape\n",
    "output_shape = y[0].shape\n",
    "input_shape, output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to build a model to find the realtionship\n",
    "# modelling with Tensorflow\n",
    "\n",
    "# 1- create model --> definr the input and output layers, as awell as the hidden layers of a deep learning model\n",
    "# 2 -> compiling a model -> define the loss function -> which tells our model how wrong it is , and opyimizer --> tellu our model to improve the patterns its learning\n",
    "#  and evaluation metrics --> what we can use to interpret the performnce of our model\n",
    "# 3 -> fitting a model -> lettin the model try to find patterns between X and y( features and labels)\n",
    "\n",
    "\n",
    "# building or picking a model often involves step 1 and 2 -> always have to compile it\n",
    "# step 3 - fitting the model, epochs - look at the training data 5 times\n",
    "# step 4 - evaluate our model -> on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1/1 [==============================] - 3s 3s/step - loss: 11.5048 - mae: 11.5048\n",
      "Epoch 2/5\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 11.3723 - mae: 11.3723\n",
      "Epoch 3/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2398 - mae: 11.2398\n",
      "Epoch 4/5\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.1073 - mae: 11.1073\n",
      "Epoch 5/5\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.9748 - mae: 10.9748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2824a580>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed -> for reproducability\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 1 create a model using the sequential API\n",
    "\n",
    "# --> telling to tensorflow --> wnat yo cretae a model and want you to sequentially go throgh the following\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    " # make with 1 layer  , used 1 - becausse in this case we want a model which takes input 1 no and predict one no.  \n",
    "    # tf.keras.layers.Dense(1)  # add them to ypur layer\n",
    "    # tf.keras.layers.Dense(1) --> no of diiferenrr hidden layers\n",
    "    #(1) -- no of ddifefrent hidden neurons in each of those layers\n",
    "\n",
    "# or\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(tf.keras.layers.Dense(1))\n",
    "# model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "\n",
    "\n",
    "# can put layers, can use .add etod to add them to the sequential model\n",
    "# or can put them into a list as done above and them to your layer\n",
    "\n",
    "\n",
    "# 2 compile the model\n",
    "model.compile(loss = tf.keras.losses.mae,          \n",
    "            optimizer=tf.keras.optimizers.SGD(),     \n",
    "            metrics = [\"mae\"])\n",
    "\n",
    "# mae is shrt for mean absolute error, computes the mean absolute error between labels and predictions, on average how wrong our prediction is\n",
    "#  sgd is short for stochstic gradient descent\n",
    "    \n",
    "# 3 . fit the model\n",
    "# fit the model on X and y for 5 laps,\n",
    "#  telling our model that lokk at X and y and try and figure out the patterns and you have 5 oppurtunities to go throgh all X and y  can set it to more\n",
    "\n",
    "model.fit(X, y, epochs=5)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss --> is our loss function --> how wrong oyr deep neural network is \n",
    "\n",
    "# because we have set our metrics same as loss function - we get same output in evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to make prediction using our model\n",
    "# check out X and y\n",
    "X ,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.716021]], dtype=float32)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a prediction using our model\n",
    "\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8.245661]], dtype=float32)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([11.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[12.716021]], dtype=float32), array([[23.71602]], dtype=float32))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict([17.0])\n",
    "y_pred  # on average 11 points off where it should be\n",
    "y_pred, y_pred+11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# improve our model\n",
    "\n",
    "# can improve model by altering the steps we took to create a model\n",
    "\n",
    "# creating the model --> we migth add more layers, increase the number of hidden units ( also called neurons) within each hidden layers, \n",
    "# we might chnage the activation functions of each layer\n",
    "\n",
    "# --> compiling the model --> can change the optimization function or the laerning rate of the optiixation function\n",
    "\n",
    "# --> fitting the model --> can fit a model for more epochs ( leave it training for longer) or on more data ( give model more example sto learn from)\n",
    "\n",
    "# epochs --> no of times looking at our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# larger model -->now has 4 hidden layers, hidden neurons in each hidden layers is 100, in compiling change optimization to adam epochs increased to 100 \n",
    "\n",
    "# adam optimization - the optimixzer tells our model how it can improve, adam optimizer is a very comon and useful optimizer \n",
    "# lr parameter - learning rate, how much it should improve every step larger lr -> more the adam optimizer pushes the model to improve, smaller lr - smaller steps our optmizer tells our neural network to improve\n",
    "\n",
    "# in fitting, larger model takes more time to figure out patterns \n",
    "# can split dataset into subsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 582ms/step - loss: 7.9432 - mae: 7.9432\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.8107 - mae: 7.8107\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.6782 - mae: 7.6782\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5457 - mae: 7.5457\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4700 - mae: 7.4700\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4644 - mae: 7.4644\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.4587 - mae: 7.4587\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4531 - mae: 7.4531\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4475 - mae: 7.4475\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4419 - mae: 7.4419\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.4363 - mae: 7.4363\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4306 - mae: 7.4306\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4250 - mae: 7.4250\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4194 - mae: 7.4194\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.4138 - mae: 7.4138\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4081 - mae: 7.4081\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.4025 - mae: 7.4025\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3969 - mae: 7.3969\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3913 - mae: 7.3913\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3856 - mae: 7.3856\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3800 - mae: 7.3800\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3744 - mae: 7.3744\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3688 - mae: 7.3688\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3631 - mae: 7.3631\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.3575 - mae: 7.3575\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3519 - mae: 7.3519\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.3463 - mae: 7.3463\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3406 - mae: 7.3406\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3350 - mae: 7.3350\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.3294 - mae: 7.3294\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.3238 - mae: 7.3238\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3181 - mae: 7.3181\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3125 - mae: 7.3125\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3069 - mae: 7.3069\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 7.3012 - mae: 7.3012\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2956 - mae: 7.2956\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2900 - mae: 7.2900\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2844 - mae: 7.2844\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2787 - mae: 7.2787\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2731 - mae: 7.2731\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2675 - mae: 7.2675\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.2619 - mae: 7.2619\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2563 - mae: 7.2563\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2506 - mae: 7.2506\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2450 - mae: 7.2450\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2394 - mae: 7.2394\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2338 - mae: 7.2338\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2281 - mae: 7.2281\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.2225 - mae: 7.2225\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2169 - mae: 7.2169\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.2113 - mae: 7.2113\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.2056 - mae: 7.2056\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.2000 - mae: 7.2000\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1944 - mae: 7.1944\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1887 - mae: 7.1887\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.1831 - mae: 7.1831\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1775 - mae: 7.1775\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1719 - mae: 7.1719\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1663 - mae: 7.1663\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1606 - mae: 7.1606\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1550 - mae: 7.1550\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1494 - mae: 7.1494\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.1438 - mae: 7.1438\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1381 - mae: 7.1381\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1325 - mae: 7.1325\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1269 - mae: 7.1269\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.1213 - mae: 7.1213\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.1156 - mae: 7.1156\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1100 - mae: 7.1100\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.1044 - mae: 7.1044\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0988 - mae: 7.0988\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.0931 - mae: 7.0931\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0875 - mae: 7.0875\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0819 - mae: 7.0819\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0763 - mae: 7.0763\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0706 - mae: 7.0706\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0650 - mae: 7.0650\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0594 - mae: 7.0594\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0538 - mae: 7.0538\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0481 - mae: 7.0481\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0425 - mae: 7.0425\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 7.0369 - mae: 7.0369\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0312 - mae: 7.0312\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0256 - mae: 7.0256\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0200 - mae: 7.0200\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0144 - mae: 7.0144\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.0088 - mae: 7.0088\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 7.0031 - mae: 7.0031\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9975 - mae: 6.9975\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 6.9919 - mae: 6.991 - 0s 5ms/step - loss: 6.9919 - mae: 6.9919\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9862 - mae: 6.9862\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9806 - mae: 6.9806\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9750 - mae: 6.9750\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9694 - mae: 6.9694\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.9638 - mae: 6.9638\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9581 - mae: 6.9581\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.9525 - mae: 6.9525\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9469 - mae: 6.9469\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.9413 - mae: 6.9413\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.9356 - mae: 6.9356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2854be80>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by increasing the number of epochs --> looking the training data 100 times\n",
    "\n",
    "# create model  --> its a sequential model --> meaning it will run from bottom to top, pass throgh this one layer\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile model\n",
    "# defined our loss function as mean absolute error \n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer =tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model ( train for longer)\n",
    "model.fit(X, y, epochs = 100)\n",
    "\n",
    "# the final loss and mae \n",
    "#trying to get this lower (11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[17.833738]], dtype=float32)"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8,), dtype=float32, numpy=array([-7., -4., -1.,  2.,  5.,  8., 11., 14.], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8,), dtype=float32, numpy=array([ 3.,  6.,  9., 12., 15., 18., 21., 24.], dtype=float32)>)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.081117]], dtype=float32)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[189.622]], dtype=float32)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([111\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so just by altering one hyperparameter of our model -- no of epochs -- decreased our loss and mae from 11 to 7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022F299B49D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[29.955261]], dtype=float32)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 708ms/step - loss: 10.5874 - mae: 10.5874\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5869 - mae: 10.5869\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5865 - mae: 10.5865\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5860 - mae: 10.5860\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5856 - mae: 10.5856\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5851 - mae: 10.5851\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5847 - mae: 10.5847\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5842 - mae: 10.5842\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5838 - mae: 10.5838\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5833 - mae: 10.5833\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5829 - mae: 10.5829\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5824 - mae: 10.5824\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5820 - mae: 10.5820\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5815 - mae: 10.5815\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5811 - mae: 10.5811\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.5806 - mae: 10.5806\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5802 - mae: 10.5802\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5797 - mae: 10.5797\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5793 - mae: 10.5793\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5788 - mae: 10.5788\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5784 - mae: 10.5784\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5779 - mae: 10.5779\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.5775 - mae: 10.5775\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5770 - mae: 10.5770\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5766 - mae: 10.5766\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5761 - mae: 10.5761\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5757 - mae: 10.5757\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5752 - mae: 10.5752\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5748 - mae: 10.5748\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5743 - mae: 10.5743\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5739 - mae: 10.5739\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 10.5734 - mae: 10.5734\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 10.5730 - mae: 10.5730\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5725 - mae: 10.5725\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5721 - mae: 10.5721\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5716 - mae: 10.5716\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5712 - mae: 10.5712\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5707 - mae: 10.5707\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5703 - mae: 10.5703\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5698 - mae: 10.5698\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5694 - mae: 10.5694\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5689 - mae: 10.5689\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5685 - mae: 10.5685\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5680 - mae: 10.5680\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5676 - mae: 10.5676\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5671 - mae: 10.5671\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.5667 - mae: 10.5667\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5662 - mae: 10.5662\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5658 - mae: 10.5658\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5653 - mae: 10.5653\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5649 - mae: 10.5649\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5644 - mae: 10.5644\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5640 - mae: 10.5640\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5635 - mae: 10.5635\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5631 - mae: 10.5631\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5626 - mae: 10.5626\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5622 - mae: 10.5622\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5617 - mae: 10.5617\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5613 - mae: 10.5613\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 10.5608 - mae: 10.5608\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5604 - mae: 10.5604\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5599 - mae: 10.5599\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5595 - mae: 10.5595\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5590 - mae: 10.5590\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5586 - mae: 10.5586\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5581 - mae: 10.5581\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5577 - mae: 10.5577\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5572 - mae: 10.5572\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 10.5568 - mae: 10.5568\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5563 - mae: 10.5563\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5559 - mae: 10.5559\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5554 - mae: 10.5554\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5550 - mae: 10.5550\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5545 - mae: 10.5545\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5541 - mae: 10.5541\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5536 - mae: 10.5536\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5532 - mae: 10.5532\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5527 - mae: 10.5527\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5523 - mae: 10.5523\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 10.5518 - mae: 10.5518\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5514 - mae: 10.5514\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5509 - mae: 10.5509\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5505 - mae: 10.5505\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.5500 - mae: 10.5500\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5496 - mae: 10.5496\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5491 - mae: 10.5491\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5487 - mae: 10.5487\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5482 - mae: 10.5482\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 10.5478 - mae: 10.5478\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5473 - mae: 10.5473\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5469 - mae: 10.5469\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5464 - mae: 10.5464\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5460 - mae: 10.5460\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5455 - mae: 10.5455\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5451 - mae: 10.5451\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5446 - mae: 10.5446\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.5442 - mae: 10.5442\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5437 - mae: 10.5437\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.5433 - mae: 10.5433\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5428 - mae: 10.5428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f299025e0>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also can change the optimizer, can add one hidden layer, can increase the number of neurons in each hidden layer\n",
    "\n",
    "# creating the model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,\n",
    "              optimizer = tf.keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, y, epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022F2AABF0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[30.130241]], dtype=float32)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 516ms/step - loss: 12.1815 - mae: 12.1815\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6749 - mae: 11.6749\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.1534 - mae: 11.1534\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.6492 - mae: 10.6492\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1213 - mae: 10.1213\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5802 - mae: 9.5802\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.0121 - mae: 9.0121\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.4049 - mae: 8.4049\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.7530 - mae: 7.7530\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0502 - mae: 7.0502\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.2911 - mae: 6.2911\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.4690 - mae: 5.4690\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.5768 - mae: 4.5768\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.0327 - mae: 4.0327\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9158 - mae: 3.9158\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9665 - mae: 3.9665\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9010 - mae: 3.9010\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 3.9615 - mae: 3.9615\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9098 - mae: 3.9098\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9442 - mae: 3.9442\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.9219 - mae: 3.9219\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.9190 - mae: 3.9190\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9283 - mae: 3.9283\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8937 - mae: 3.8937\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.9348 - mae: 3.9348\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8698 - mae: 3.8698\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9397 - mae: 3.9397\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8845 - mae: 3.8845\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9214 - mae: 3.9214\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8910 - mae: 3.8910\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 3.8960 - mae: 3.8960\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8976 - mae: 3.8976\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8704 - mae: 3.8704\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.9044 - mae: 3.9044\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8446 - mae: 3.8446\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.9170 - mae: 3.9170\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8546 - mae: 3.8546\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8973 - mae: 3.8973\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8613 - mae: 3.8613\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8716 - mae: 3.8716\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8681 - mae: 3.8681\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 3.8458 - mae: 3.8458\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8750 - mae: 3.8750\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8234 - mae: 3.8234\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8905 - mae: 3.8905\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 3.8258 - mae: 3.8258\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.8719 - mae: 3.8719\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8326 - mae: 3.8326\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8460 - mae: 3.8460\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8397 - mae: 3.8397\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8198 - mae: 3.8198\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8482 - mae: 3.8482\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8013 - mae: 3.8013\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8623 - mae: 3.8623\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7981 - mae: 3.7981\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8452 - mae: 3.8452\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8051 - mae: 3.8051\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.8190 - mae: 3.8190\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8123 - mae: 3.8123\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7926 - mae: 3.7926\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8271 - mae: 3.8271\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7737 - mae: 3.7737\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8354 - mae: 3.8354\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7714 - mae: 3.7714\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8173 - mae: 3.8173\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7786 - mae: 3.7786\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7907 - mae: 3.7907\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7860 - mae: 3.7860\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7697 - mae: 3.7697\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.8019 - mae: 3.8019\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 3.7448 - mae: 3.7448\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.8094 - mae: 3.8094\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7457 - mae: 3.7457\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 3.7880 - mae: 3.7880\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7532 - mae: 3.753 - 0s 6ms/step - loss: 3.7532 - mae: 3.7532\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7611 - mae: 3.7611\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7641 - mae: 3.7641\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7418 - mae: 3.7418\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7768 - mae: 3.7768\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7145 - mae: 3.7145\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7845 - mae: 3.7845\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7211 - mae: 3.7211\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.7574 - mae: 3.7574\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7288 - mae: 3.7288\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7317 - mae: 3.7317\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7449 - mae: 3.7449\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7105 - mae: 3.7105\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7527 - mae: 3.7527\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6898 - mae: 3.6898\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7528 - mae: 3.7528\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.6975 - mae: 3.6975\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7255 - mae: 3.7255\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.7054 - mae: 3.7054\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 3.7051 - mae: 3.7051\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7217 - mae: 3.7217\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6779 - mae: 3.6779\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 3.7297 - mae: 3.7297\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.6669 - mae: 3.6669\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.7198 - mae: 3.719 - 0s 6ms/step - loss: 3.7198 - mae: 3.7198\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.6749 - mae: 3.6749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2bbb2430>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making another change to improve our model --> increase one layer\n",
    "## \n",
    "# creating the model with an extra hidden layer (with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation = \"relu\"),  # relu activation  can also take --> # can take activation function = None\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,   # or can write loss = \"mae\",  \n",
    "              optimizer = tf.keras.optimizers.SGD(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, y, epochs = 100)  # first features come(X) , then comes labels(Y) \n",
    "\n",
    "# mae - on an average , how wrong our model prediction is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.425943]], dtype=float32)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make prediction\n",
    "model.predict([17])\n",
    "\n",
    "# in this case it gives even more error but mae is slower\n",
    "# --->  implies that our model may be overfitting --> it might be learning the training data too well\n",
    "\n",
    "# learning patterns bet X and y too well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.9976897]], dtype=float32)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting --> means during training\n",
    "\n",
    "# main thing is how our model performs on real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 528ms/step - loss: 13.3616 - mae: 13.3616\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.2981 - mae: 13.2981\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.2346 - mae: 13.2346\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 13.1711 - mae: 13.1711\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 13.1077 - mae: 13.1077\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 13.0442 - mae: 13.0442\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.9807 - mae: 12.9807\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.9172 - mae: 12.9172\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.8536 - mae: 12.8536\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.7900 - mae: 12.7900\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.7264 - mae: 12.7264\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.6627 - mae: 12.6627\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.5989 - mae: 12.5989\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.5351 - mae: 12.5351\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 12.4712 - mae: 12.4712\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.4071 - mae: 12.4071\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.3430 - mae: 12.3430\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2788 - mae: 12.2788\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 12.2144 - mae: 12.2144\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 12.1500 - mae: 12.1500\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 12.0853 - mae: 12.0853\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.0206 - mae: 12.0206\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 11.9556 - mae: 11.9556\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.8905 - mae: 11.8905\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.8253 - mae: 11.8253\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.7598 - mae: 11.7598\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.6942 - mae: 11.6942\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.6283 - mae: 11.6283\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 11.5623 - mae: 11.5623\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.4960 - mae: 11.4960\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4295 - mae: 11.4295\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.3628 - mae: 11.3628\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 11.2958 - mae: 11.2958\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.2286 - mae: 11.2286\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 11.1611 - mae: 11.1611\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.0933 - mae: 11.0933\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 11.0253 - mae: 11.0253\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.9570 - mae: 10.9570\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8884 - mae: 10.8884\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.8195 - mae: 10.8195\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.7503 - mae: 10.7503\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.6807 - mae: 10.6807\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.6109 - mae: 10.6109\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.5407 - mae: 10.5407\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.4702 - mae: 10.4702\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.3993 - mae: 10.3993\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.3281 - mae: 10.3281\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.2566 - mae: 10.2566\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 10.1846 - mae: 10.1846\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 10.1123 - mae: 10.1123\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 10.0397 - mae: 10.0397\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.9666 - mae: 9.9666\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.8932 - mae: 9.8932\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 9.8193 - mae: 9.8193\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.7450 - mae: 9.7450\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.6704 - mae: 9.6704\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 9.5953 - mae: 9.5953\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.5198 - mae: 9.5198\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.4438 - mae: 9.4438\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.3674 - mae: 9.3674\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.2906 - mae: 9.2906\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 9.2133 - mae: 9.2133\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 9.1356 - mae: 9.1356\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 9.0574 - mae: 9.0574\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.9787 - mae: 8.9787\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.8996 - mae: 8.8996\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 8.8200 - mae: 8.8200\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.7399 - mae: 8.7399\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.6593 - mae: 8.6593\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 8.5782 - mae: 8.5782\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 8.4966 - mae: 8.4966\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.4145 - mae: 8.4145\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3319 - mae: 8.3319\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.2487 - mae: 8.2487\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 8.1650 - mae: 8.1650\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.0808 - mae: 8.0808\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.9961 - mae: 7.9961\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.9108 - mae: 7.9108\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.8250 - mae: 7.8250\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.7386 - mae: 7.7386\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 7.6516 - mae: 7.6516\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.5641 - mae: 7.5641\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.4761 - mae: 7.4761\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 7.3874 - mae: 7.3874\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2982 - mae: 7.2982\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.2083 - mae: 7.2083\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 7.1179 - mae: 7.1179\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 5ms/step - loss: 7.0269 - mae: 7.0269\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 6.9353 - mae: 6.9353\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.8431 - mae: 6.8431\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.7503 - mae: 6.7503\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.7062 - mae: 6.7062\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 6.6943 - mae: 6.6943\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6827 - mae: 6.6827\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6714 - mae: 6.6714\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.6603 - mae: 6.6603\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 6.6495 - mae: 6.6495\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 6.6388 - mae: 6.6388\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.6283 - mae: 6.6283\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.6180 - mae: 6.6180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2bc22220>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# making another change to improve our model --> increase one layer\n",
    "## \n",
    "# creating the model with an extra hidden layer (with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation = None),  # relu activation  can also take --> # can take activation function = None\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,   # or can write loss = \"mae\",  \n",
    "              optimizer = tf.keras.optimizers.Adam(),\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, y, epochs = 100)  # first features come(X) , then comes labels(Y) \n",
    "\n",
    "# mae - on an average , how wrong our model prediction is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[31.484047]], dtype=float32)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# new sample \n",
    "model.predict([17.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 568ms/step - loss: 14.4889 - mae: 14.4889\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 13.7204 - mae: 13.7204\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 12.9558 - mae: 12.9558\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 12.1943 - mae: 12.1943\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 11.4335 - mae: 11.4335\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 10.6713 - mae: 10.6713\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 9.9055 - mae: 9.9055\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 9.1344 - mae: 9.1344\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 8.3556 - mae: 8.3556\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5670 - mae: 7.5670\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.7662 - mae: 6.7662\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 6.6955 - mae: 6.6955\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 7.0553 - mae: 7.0553\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.3170 - mae: 7.3170\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 7.5321 - mae: 7.5321\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 7.5373 - mae: 7.5373\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.3799 - mae: 7.3799\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 7.0961 - mae: 7.0961\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 6.8115 - mae: 6.8115\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.5498 - mae: 6.5498\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.2733 - mae: 6.2733\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0405 - mae: 6.0405\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.9927 - mae: 5.9927\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 5.9806 - mae: 5.9806\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 6.0575 - mae: 6.0575\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 6.0368 - mae: 6.0368\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.9300 - mae: 5.9300\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 5.7459 - mae: 5.7459\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.5496 - mae: 5.5496\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 5.4525 - mae: 5.4525\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.3527 - mae: 5.3527\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 5.2715 - mae: 5.2715\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.2437 - mae: 5.2437\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 5.1738 - mae: 5.1738\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 5.0653 - mae: 5.0653\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 4.9213 - mae: 4.9213\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.7861 - mae: 4.7861\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.6932 - mae: 4.6932\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.5946 - mae: 4.5946\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.4900 - mae: 4.4900\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.3793 - mae: 4.3793\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 4.2625 - mae: 4.2625\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 4.1394 - mae: 4.1394\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 4.0259 - mae: 4.0259\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.8644 - mae: 3.8644\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.7127 - mae: 3.7127\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.5546 - mae: 3.5546\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 3.4137 - mae: 3.4137\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 3.2781 - mae: 3.2781\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 3.0887 - mae: 3.0887\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 2.9112 - mae: 2.9112\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.7441 - mae: 2.7441\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 2.5669 - mae: 2.5669\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 2.4430 - mae: 2.4430\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 2.1712 - mae: 2.1712\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.9534 - mae: 1.9534\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 1.7315 - mae: 1.7315\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.5116 - mae: 1.5116\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 1.2754 - mae: 1.2754\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 1.0746 - mae: 1.0746\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.7776 - mae: 0.7776\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5647 - mae: 0.5647\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.3138 - mae: 0.3138\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2068 - mae: 0.2068\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2753 - mae: 0.2753\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5000 - mae: 0.5000\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.5904 - mae: 0.5904\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.6596 - mae: 0.6596\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.7348 - mae: 0.7348\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6845 - mae: 0.6845\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6698 - mae: 0.6698\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5823 - mae: 0.5823\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5082 - mae: 0.5082\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3435 - mae: 0.3435\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2407 - mae: 0.2407\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0927 - mae: 0.0927\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1227 - mae: 0.1227\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2664 - mae: 0.2664\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3580 - mae: 0.3580\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.3578 - mae: 0.3578\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4553 - mae: 0.4553\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4116 - mae: 0.4116\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3394 - mae: 0.3394\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2711 - mae: 0.2711\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2318 - mae: 0.2318\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.1627 - mae: 0.1627\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1842 - mae: 0.1842\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2410 - mae: 0.2410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1765 - mae: 0.1765\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2222 - mae: 0.2222\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1781 - mae: 0.1781\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0933 - mae: 0.0933\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.0846 - mae: 0.0846\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2120 - mae: 0.2120\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1663 - mae: 0.1663\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.2844 - mae: 0.2844\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.3299 - mae: 0.3299\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2170 - mae: 0.2170\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1968 - mae: 0.1968\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1727 - mae: 0.1727\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2ce331f0>"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# changing the learning rate  --> optimizer tells our model how it should improve, lr tells it by how much it should\n",
    "\n",
    "# making another change to improve our model --> increase one layer\n",
    "## \n",
    "# creating the model with an extra hidden layer (with 100 hidden units)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(50, activation = None),  # relu activation  can also take --> # can take activation function = None\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# compile the model\n",
    "\n",
    "model.compile(loss=tf.keras.losses.mae,   # or can write loss = \"mae\",  \n",
    "              optimizer = tf.keras.optimizers.Adam(learning_rate = 0.01),   # adam lr = 0.001 by default -> increase it by 10  = 0.1\n",
    "              metrics = [\"mae\"])\n",
    "\n",
    "# fit the model\n",
    "\n",
    "model.fit(X, y, epochs = 100)  # first features come(X) , then comes labels(Y) \n",
    "\n",
    "# mae - on an average , how wrong our model prediction is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[26.587706]], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([17.0])   # best model sso far as we see from the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we can see that in this case, adjusting the lr of optimizer yields best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imp --> learning rate is most imp hyperparameter can change on all neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a larger data set\n",
    "\n",
    "# common ways to improve a model -\n",
    "# adding layers\n",
    "# increase no of hidden units\n",
    "# change the activation function\n",
    "# change the learning rate\n",
    "# fitting on more data \n",
    "# fitting for longer --> increase no of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluating a model -- how exactly  do we tell how good ourr model predictions are, how good the patterns it has laerned bet X and y are\n",
    "\n",
    "## normally, a workflow for building neural networks is -->\n",
    "\n",
    "# build a model, fit it, evaluate it, tweak a model, fit it, evaluate it, tweak a model, fit it, evaluate it, ....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter -> like  a dial n your neurakl network you can adjust to see how it improves\n",
    "\n",
    "# parameter --> usually the patterns that neural network learns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for evaluation --> visualize, .....\n",
    "\n",
    "# we should visualize \n",
    "# visualize the data -> what data are we working eith, how does it look like\n",
    "# model itself, how does it look klike\n",
    "# training of a model --> how does a model perform while it learns\n",
    "# predictions of the model - how do the predictions of a model line up against the ground truth (original labels)\n",
    "\n",
    "# for building --> experiment, ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-100,  -96,  -92,  -88,  -84,  -80,  -76,  -72,  -68,  -64,  -60,\n",
       "        -56,  -52,  -48,  -44,  -40,  -36,  -32,  -28,  -24,  -20,  -16,\n",
       "        -12,   -8,   -4,    0,    4,    8,   12,   16,   20,   24,   28,\n",
       "         32,   36,   40,   44,   48,   52,   56,   60,   64,   68,   72,\n",
       "         76,   80,   84,   88,   92,   96])>"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a bigger data set \n",
    "X = tf.range(-100, 100, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(50,), dtype=int32, numpy=\n",
       "array([-90, -86, -82, -78, -74, -70, -66, -62, -58, -54, -50, -46, -42,\n",
       "       -38, -34, -30, -26, -22, -18, -14, -10,  -6,  -2,   2,   6,  10,\n",
       "        14,  18,  22,  26,  30,  34,  38,  42,  46,  50,  54,  58,  62,\n",
       "        66,  70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labels for the data set\n",
    "y = X+10;  # formual we wnat our model to learn\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22f2df3ddc0>]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visulaize the data\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x22f2ccda970>"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the 3 sets... split X and y into training and test set\n",
    "# not going to fit and evaluate om the same set\n",
    "\n",
    "# actually --> 3 different set sof data \n",
    "# 1 --> training set -> the model learns from this data, which is typically 70-80% of the total data you have available\n",
    "\n",
    "# 2 --> validation set -> the model gets tuned on this data\n",
    "#   this is where you tweak different things --> changing no of hidden layers, optimization function, will test how hese tweaks affected your model's performance on the validation set\n",
    "#    typically 10-15% of the data available\n",
    "\n",
    "\n",
    "# 3 --> the model gets evaluated on this data to test what it has learn, has typically 10-15% of the total data available\n",
    "\n",
    "\n",
    "# check the length of how many samples we have \n",
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 10, 40, 10)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split the data into train and test sets\n",
    "\n",
    "X_train = X[:40] # first 40 are training samples ( 80 % of the data) --> training features\n",
    "# train_data =\n",
    "y_train = y[:40] # testing features\n",
    "\n",
    "X_test = X[40:] # last 10 are testing samples (20% of the data) --> training labels\n",
    "y_test = y[40:]  # test labels\n",
    "# test_data =  \n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the data\n",
    "# training and test set - visualize it\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7)) # setting figure beccause we have to plot two samples of data\n",
    "# plot training data in blue\n",
    "plt.scatter(X_train, y_train, c=\"b\", label = \"Training data\")  # our model will learn on this\n",
    "\n",
    "#plot test data in green\n",
    "plt.scatter(X_test, y_test, c=\"g\", label = \"Tesing data\")  # want our model to be able to predict this(given x, what's y)\n",
    "\n",
    "#shw a legend\n",
    "plt.legend();\n",
    "\n",
    "# to visualize your data, or model easier to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a neural network to take training data to leran the relationships, so that it can oredict our test data\n",
    "\n",
    "# creating model\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(1)  # one hidden layer --> has one hidden unit because we are using 1 X value to predict one Y value therfore dense layer has one unit \n",
    "])\n",
    "\n",
    "# compile model\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics =[\"mae\"])\n",
    "\n",
    "# fit\n",
    "\n",
    "# model.fit(X_train, y_train, epochs = 100)  # fit on training data only -> blue line in the graph -> want our model to learn patterns in training data to predict patterns  in the test data  \n",
    "\n",
    "\n",
    "# 1, 2--> instantiates the model here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-229-a16bb951c384>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# visualizing the model --> how model looks like before running it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   2519\u001b[0m     \"\"\"\n\u001b[0;32m   2520\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2521\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   2522\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2523\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "# visualizing the model --> how model looks like before running it\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You must provide an `input_shape` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-230-2f52417d930d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\saicharan\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    338\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'You must provide an `input_shape` argument.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_graph_network_for_inferred_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You must provide an `input_shape` argument."
     ]
    }
   ],
   "source": [
    "model.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([50]), TensorShape([]))"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X[0].shape  # ---> we want only one sample of X so did X[0].shape --> scalar value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=-100>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=-90>)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0], y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model which builds automatically by defining the input shape arguement in the first layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create model --> Sequential model runs from top to bottom\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1])  # one hidden layer --> has one hidden unit because we are using 1 X value to predict one Y value therfore dense layer has one unit \n",
    "])\n",
    "\n",
    "\n",
    "# input_shape = 1 because we are passing one no to predict another no\n",
    "\n",
    "\n",
    "# compile model\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics =[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summmary shows us the layers that it contains , the output shape, and the no of parameters of each layer\n",
    "\n",
    "# in above model --> layer is type dense\n",
    "# dense means fully connected --> all neurons in one layer are connected to all neurons in next layer\n",
    "\n",
    "# param --> parameters no \n",
    "\n",
    "\n",
    "# neural network creates tensors of diffferent values, patterns \n",
    "# total no of parameters -> is the different no of patterns our model is going to try and learn, relation bet X and y data\n",
    "\n",
    "# total params -->> total no of paramaters in the model -> these are the parameters that our model is going to learn\n",
    "# Trainable parameters --> these are the parameters(patterns) the model can update as it trains.\n",
    "# Non-trainabe parameters --> these parameters are'nt updated during training ( this is typical when we bring in already learned parameters or patterns from other models during transfer learning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to see actual parameters in a dense layer -->\n",
    "\n",
    "# will find weights matrix and a bias vector\n",
    "\n",
    "# within hidden layer --> we have a bunch of different parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for more about trainable parametres within a layer, check out MIT'S intro to deep learning module \n",
    "\n",
    "# Imp --> no of hidden units in the dense layer and see how it affects the no of parametrs -> total and trainable by using model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# get a summary of our model\n",
    "model.summary()  # here sequential_22 shows that we have created 22 sequential models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shpws that there are 2 trainable params per hidden unit in our dense layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2f2d2580>"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit our model to the training data\n",
    "model.fit(X_train, y_train, epochs = 100, verbose = 0)\n",
    "\n",
    "# verbose --> 0 --> will not get any output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4494 - mae: 7.4494\n",
      "Epoch 2/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2391 - mae: 9.2391\n",
      "Epoch 3/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6116 - mae: 9.6116\n",
      "Epoch 4/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.7602 - mae: 8.7602\n",
      "Epoch 5/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.7251 - mae: 9.7251\n",
      "Epoch 6/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9002 - mae: 8.9002\n",
      "Epoch 7/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0002 - mae: 8.0002\n",
      "Epoch 8/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.1138 - mae: 8.1138\n",
      "Epoch 9/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 19.0986 - mae: 19.0986\n",
      "Epoch 10/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.3698 - mae: 9.3698\n",
      "Epoch 11/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.5493 - mae: 7.5493\n",
      "Epoch 12/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.8866 - mae: 9.8866\n",
      "Epoch 13/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.9273 - mae: 8.9273\n",
      "Epoch 14/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 10.9891 - mae: 10.9891\n",
      "Epoch 15/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.6094 - mae: 12.6094\n",
      "Epoch 16/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.4175 - mae: 6.4175\n",
      "Epoch 17/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.6479 - mae: 7.6479\n",
      "Epoch 18/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.2152 - mae: 10.2152\n",
      "Epoch 19/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 18.3227 - mae: 18.3227\n",
      "Epoch 20/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0241 - mae: 15.0241\n",
      "Epoch 21/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.5285 - mae: 10.5285\n",
      "Epoch 22/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 7.0450 - mae: 7.0450\n",
      "Epoch 23/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.7253 - mae: 8.7253\n",
      "Epoch 24/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.5994 - mae: 7.5994\n",
      "Epoch 25/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1121 - mae: 10.1121\n",
      "Epoch 26/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 16.3869 - mae: 16.3869\n",
      "Epoch 27/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.5856 - mae: 12.5856\n",
      "Epoch 28/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.7632 - mae: 13.7632\n",
      "Epoch 29/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 9.0995 - mae: 9.0995\n",
      "Epoch 30/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.4324 - mae: 15.4324\n",
      "Epoch 31/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 23.7275 - mae: 23.7275\n",
      "Epoch 32/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.6583 - mae: 6.6583\n",
      "Epoch 33/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.3521 - mae: 9.3521\n",
      "Epoch 34/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.9275 - mae: 8.9275\n",
      "Epoch 35/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 7.0428 - mae: 7.0428\n",
      "Epoch 36/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.9966 - mae: 8.9966\n",
      "Epoch 37/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.7731 - mae: 8.7731\n",
      "Epoch 38/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.5648 - mae: 9.5648\n",
      "Epoch 39/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.0424 - mae: 15.0424\n",
      "Epoch 40/100\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 12.7918 - mae: 12.7918\n",
      "Epoch 41/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5636 - mae: 8.5636\n",
      "Epoch 42/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.4069 - mae: 10.4069\n",
      "Epoch 43/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.9575 - mae: 10.9575\n",
      "Epoch 44/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 15.4550 - mae: 15.4550\n",
      "Epoch 45/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.1913 - mae: 11.1913\n",
      "Epoch 46/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3175 - mae: 6.3175\n",
      "Epoch 47/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4750 - mae: 8.4750\n",
      "Epoch 48/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.0104 - mae: 8.0104\n",
      "Epoch 49/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.8868 - mae: 6.8868\n",
      "Epoch 50/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6688 - mae: 8.6688\n",
      "Epoch 51/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.6195 - mae: 8.6195\n",
      "Epoch 52/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 10.3668 - mae: 10.3668\n",
      "Epoch 53/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7298 - mae: 11.7298\n",
      "Epoch 54/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 17.4147 - mae: 17.4147\n",
      "Epoch 55/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.1775 - mae: 15.1775\n",
      "Epoch 56/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.3830 - mae: 10.3830\n",
      "Epoch 57/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.7312 - mae: 8.7312\n",
      "Epoch 58/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 8.0396 - mae: 8.0396\n",
      "Epoch 59/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.2555 - mae: 9.2555\n",
      "Epoch 60/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.4949 - mae: 7.4949\n",
      "Epoch 61/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.3574 - mae: 8.3574\n",
      "Epoch 62/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.3038 - mae: 6.3038\n",
      "Epoch 63/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 7.2954 - mae: 7.2954\n",
      "Epoch 64/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 12.0381 - mae: 12.0381\n",
      "Epoch 65/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.1088 - mae: 9.1088\n",
      "Epoch 66/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 15.5762 - mae: 15.5762\n",
      "Epoch 67/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.4988 - mae: 9.4988\n",
      "Epoch 68/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.3459 - mae: 7.3459\n",
      "Epoch 69/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 13.3723 - mae: 13.3723\n",
      "Epoch 70/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.1456 - mae: 6.1456\n",
      "Epoch 71/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 12.7084 - mae: 12.7084\n",
      "Epoch 72/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.6625 - mae: 8.6625\n",
      "Epoch 73/100\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 10.7664 - mae: 10.7664\n",
      "Epoch 74/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 11.6373 - mae: 11.6373\n",
      "Epoch 75/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.3771 - mae: 6.3771\n",
      "Epoch 76/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 10.1117 - mae: 10.1117\n",
      "Epoch 77/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 10.0869 - mae: 10.0869\n",
      "Epoch 78/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.7024 - mae: 11.7024\n",
      "Epoch 79/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 14.6771 - mae: 14.6771\n",
      "Epoch 80/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 11.0129 - mae: 11.0129\n",
      "Epoch 81/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 10.1555 - mae: 10.1555\n",
      "Epoch 82/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.1339 - mae: 7.1339\n",
      "Epoch 83/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 8.0773 - mae: 8.0773\n",
      "Epoch 84/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 6.7051 - mae: 6.7051\n",
      "Epoch 85/100\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 16.1770 - mae: 16.1770\n",
      "Epoch 86/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 11.5961 - mae: 11.5961\n",
      "Epoch 87/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 11.4826 - mae: 11.4826\n",
      "Epoch 88/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 9.5591 - mae: 9.5591\n",
      "Epoch 89/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 6.0280 - mae: 6.0280\n",
      "Epoch 90/100\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 12.9257 - mae: 12.9257\n",
      "Epoch 91/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 6.8810 - mae: 6.8810\n",
      "Epoch 92/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.1209 - mae: 7.1209\n",
      "Epoch 93/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.5510 - mae: 8.5510\n",
      "Epoch 94/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 7.8979 - mae: 7.8979\n",
      "Epoch 95/100\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 11.3865 - mae: 11.3865\n",
      "Epoch 96/100\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 8.4120 - mae: 8.4120\n",
      "Epoch 97/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 12.1666 - mae: 12.1666\n",
      "Epoch 98/100\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 7.4770 - mae: 7.4770\n",
      "Epoch 99/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 8.2216 - mae: 8.2216\n",
      "Epoch 100/100\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 9.6944 - mae: 9.6944\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2f713700>"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs = 100, verbose = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_32 (Dense)             (None, 10)                20        \n",
      "=================================================================\n",
      "Total params: 20\n",
      "Trainable params: 20\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(model=model, show_shapes=\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a model which builds automatically by defining the input shape arguement in the first layer\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# create model --> Sequential model runs from top to bottom\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, input_shape=[1], name=\"Input_layer\"),  # one hidden layer --> has one hidden unit because we are using 1 X value to predict one Y value therfore dense layer has one unit \n",
    "    tf.keras.layers.Dense(1, name=\"Output_layer\")\n",
    "], name =\"model_1\")\n",
    "\n",
    "\n",
    "# input_shape = 1 because we are passing one no to predict another no\n",
    "\n",
    "\n",
    "# compile model\n",
    "\n",
    "model.compile(loss = tf.keras.losses.mae,\n",
    "             optimizer = tf.keras.optimizers.SGD(),\n",
    "             metrics =[\"mae\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Input_layer (Dense)          (None, 10)                20        \n",
      "_________________________________________________________________\n",
      "Output_layer (Dense)         (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 31\n",
      "Trainable params: 31\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22f2f364e50>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train , y_train, epochs=100, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 70.552185],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72764 ],\n",
       "       [ 84.315346],\n",
       "       [ 88.90308 ],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07852 ],\n",
       "       [102.666245],\n",
       "       [107.253975],\n",
       "       [111.84169 ]], dtype=float32)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize model predictions\n",
    "\n",
    "# to visualize predictions, its a agood idea to plot them against the ground truth labels.\n",
    "# often we see this in form of y_test or y_true versus y_pred (ground truth versus your model predictions)\n",
    "\n",
    "# make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the comparison\n",
    "# if fwant to use a fuctionality in the future --> can use it in a function\n",
    "# creating a plotting function\n",
    "\n",
    "def plot_predictions(train_data=X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=y_pred):\n",
    "    # plots training data, tetst data, and compares predictions to ground truth labels\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    #training data in blue\n",
    "    plt.scatter(train_data, train_labels, c=\"b\", label=\"Training data\")\n",
    "    #test data in green\n",
    "    plt.scatter(test_data, test_labels, c=\"g\", label=\"Testing data\")\n",
    "    #model's prredictions in red and want to compare  them to the test data \n",
    "    plt.scatter(test_data, predictions, c=\"r\", label = \"Predictions\")\n",
    "    # show legend\n",
    "    plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_predictions(train_data =X_train, train_labels=y_train, test_data=X_test, test_labels=y_test, predictions=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the distance between the red and green dots could be a fairly large erroor depending on the scale\n",
    "# can figure this out by some regression evaluation metrics\n",
    "\n",
    "# Depending on the problem we work , there are different evaluation metrics to evaluate your model's performance\n",
    "# Since we work on a gregression problem, two main metrics are mae--mean absolute error--> on average, how wrong is each pf our model's predictions is\n",
    "# mse - mean square error --> square the average errors and then find the average  -> used when larger errors are more significant than smaller errors\n",
    "\n",
    "# abs(labels - predictions)\n",
    "# y with hat ---> is y_predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 230ms/step - loss: 3.1969 - mae: 3.1969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.1969382762908936, 3.1969382762908936]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the model on test set\n",
    "\n",
    "model.evaluate(X_test, y_test)  # in doc string --> return s the loss value and metrics values for the model in the test mode "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([17.558252 , 14.1160555, 11.708944 , 10.336931 , 10.       ,\n",
       "       10.698161 , 12.447113 , 15.332995 , 19.253975 , 23.84169  ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean absolute error\n",
    "# tf.keras.losses.MAE(y_test, y_pred)\n",
    "\n",
    "mae = tf.metrics.mean_absolute_error(y_true = y_test, y_pred = tf.constant(y_pred))\n",
    "mae\n",
    "# this gives us metric for each of the test labels and predictions --> maybe because y_pred is not a tensor --> turn y_pred into a rensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[ 70.552185],\n",
       "       [ 75.13991 ],\n",
       "       [ 79.72764 ],\n",
       "       [ 84.315346],\n",
       "       [ 88.90308 ],\n",
       "       [ 93.49081 ],\n",
       "       [ 98.07852 ],\n",
       "       [102.666245],\n",
       "       [107.253975],\n",
       "       [111.84169 ]], dtype=float32)>"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([ 70,  74,  78,  82,  86,  90,  94,  98, 102, 106])>,\n",
       " array([[ 70.552185],\n",
       "        [ 75.13991 ],\n",
       "        [ 79.72764 ],\n",
       "        [ 84.315346],\n",
       "        [ 88.90308 ],\n",
       "        [ 93.49081 ],\n",
       "        [ 98.07852 ],\n",
       "        [102.666245],\n",
       "        [107.253975],\n",
       "        [111.84169 ]], dtype=float32))"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test, y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# but y_pred and y_test are not in same shape\n",
    "# in comparison we have to the reshape the tensors for same format\n",
    "\n",
    "#y_pred = tf.reshape(tf.constant(y_pred), shape=(10))\n",
    "#y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.metrics.mean_absolute_error(y_true=y_test, y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       " array([ 70.552185,  75.13991 ,  79.72764 ,  84.315346,  88.90308 ,\n",
       "         93.49081 ,  98.07852 , 102.666245, 107.253975, 111.84169 ],\n",
       "       dtype=float32)>,\n",
       " array([[ 70.552185],\n",
       "        [ 75.13991 ],\n",
       "        [ 79.72764 ],\n",
       "        [ 84.315346],\n",
       "        [ 88.90308 ],\n",
       "        [ 93.49081 ],\n",
       "        [ 98.07852 ],\n",
       "        [102.666245],\n",
       "        [107.253975],\n",
       "        [111.84169 ]], dtype=float32))"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or can use the squueze method --> remove one dimension of y_pred tensor\n",
    "tf.squeeze(y_pred), y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.19694>"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate the mean absolute error\n",
    "mae = tf.metrics.mean_absolute_error(y_true=y_test, y_pred=tf.squeeze(y_pred))\n",
    "mae  # gives same result as evaluate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=13.070127>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calcullate the mean squared error\n",
    "mse = tf.metrics.mean_squared_error(y_true=y_test, y_pred=tf.squeeze(y_pred))  # tf.squeeze removes the single dimension from the y_pred \n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making function for mean_squared_error and mean_absolute_error\n",
    "def mae(y_true, y_pred):\n",
    "    return tf.metrics.mean_absolute_error(y_true=y_true, y_pred=y_pred)\n",
    "def mse(y_true, y_pred):\n",
    "    return tf.metrics.mean_squared_error(y_true=y_true, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to lower difference bet predictions and test labels\n",
    "# improve model --> build , fit, evaluate it, tweak it, fit, evaluate it, tweak it\n",
    "\n",
    "# some ways to improve --> 1 get some more data - get more examples for model to train on(more oppurtunities to learn patterns or relationships between labels and features)\n",
    "#2 . make your model lareger ( using a more complex model) - can add ore layers or more hidden units in each layer\n",
    "#3. train for longer - give model more chance to find patterns in the data"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "00_tensorflow_fund.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
