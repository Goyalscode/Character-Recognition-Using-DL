{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_Training.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMYlgwRhbRz7"
      },
      "source": [
        "\n",
        "#     **Building Model For Character Recognition Using Deep Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nagL4ZLJbYOY"
      },
      "source": [
        "\n",
        "######      Student Name --> Priyanshu Goyal\n",
        "\n",
        "######      Section --> A\n",
        "\n",
        "######      University Roll No --> 2014787"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qhjt3kfobee5"
      },
      "source": [
        "### **Importing the necessary libraries, packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcNSJq0ybS2X"
      },
      "source": [
        "import numpy as np                 # for scientific computation\n",
        "import pandas as pd                # to manipulate, analyse the dataset\n",
        "import tensorflow as tf            # to create deep learning models\n",
        "from tensorflow import keras       # for developing, evaluating models\n",
        "import matplotlib.pyplot as plt    # for graphical plotting and visualization                                                                     \n",
        "import seaborn as sb               # for different visualization of the data\n",
        "from keras.utils import np_utils   # to provide different utilities    "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33tqD2YPpIHw"
      },
      "source": [
        "### **Loading the csv digit and letter datasets into dataframes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YHSp8bEpI2K"
      },
      "source": [
        "# loading the csv datasets into dataframes\n",
        "train_digit_data = pd.read_csv(\"/content/drive/MyDrive/mnist_train.csv\")  # training data for digits  \n",
        "test_digit_data = pd.read_csv(\"/content/drive/MyDrive/mnist_test.csv\")    # testing data for digits\n",
        "letter_data = pd.read_csv(\"/content/drive/MyDrive/A_Z Handwritten Data.csv\")  # dataset of letters - have to split it "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qd8GqK_pUgb"
      },
      "source": [
        "### **Joining train and test data of digit dataset to get complete digit dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tb0zbublpNHU"
      },
      "source": [
        "digit_data = pd.concat([train_digit_data, test_digit_data], ignore_index = True)  # this combines digits - train and test data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDDuGXsVpZmW"
      },
      "source": [
        ""
      ],
      "execution_count": 7,
      "outputs": []
    }
  ]
}